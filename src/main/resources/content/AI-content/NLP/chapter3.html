<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第3章：词向量与文本表示 - 让机器理解语义</title>
    <meta name="description" content="从国王-男人+女人=？说起，深入理解词向量的魔法">

    <!-- KaTeX支持 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false}
                ]
            });"></script>

    <style>
        /* ===== CSS变量定义 ===== */
        :root {
            /* 渐变色 */
            --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            --hero-gradient: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
            --card-gradient: linear-gradient(135deg, rgba(99, 102, 241, 0.1), rgba(139, 92, 246, 0.05));

            /* 主题色 */
            --primary: #6366f1;
            --primary-light: #818cf8;
            --primary-dark: #4f46e5;
            --secondary: #ec4899;
            --accent: #10b981;

            /* 功能色 */
            --success: #10b981;
            --warning: #f59e0b;
            --danger: #ef4444;
            --info: #3b82f6;

            /* 背景色 */
            --bg-dark: #0f172a;
            --bg-section: #1e293b;
            --bg-card: #334155;
            --bg-code: #0d1117;

            /* 文字色 */
            --text-primary: #f1f5f9;
            --text-secondary: #cbd5e1;
            --text-muted: #94a3b8;

            /* 其他 */
            --border-color: rgba(255, 255, 255, 0.1);
            --shadow: 0 20px 50px rgba(0, 0, 0, 0.5);
            --shadow-lg: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
            --radius: 1rem;
            --transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }

        /* ===== 全局样式 ===== */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: var(--bg-dark);
            color: var(--text-primary);
            line-height: 1.7;
            font-size: 16px;
            overflow-x: hidden;
        }

        /* ===== 背景效果 ===== */
        .bg-pattern {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            opacity: 0.03;
            background-image:
                    repeating-linear-gradient(45deg, transparent, transparent 35px, rgba(255,255,255,.5) 35px, rgba(255,255,255,.5) 70px);
            pointer-events: none;
            z-index: 0;
        }

        .floating-shapes {
            position: fixed;
            width: 100%;
            height: 100%;
            overflow: hidden;
            z-index: 0;
        }

        .shape {
            position: absolute;
            opacity: 0.1;
            animation: float 20s infinite ease-in-out;
        }

        .shape:nth-child(1) {
            width: 80px;
            height: 80px;
            background: var(--primary);
            border-radius: 50%;
            left: 10%;
            top: 20%;
            animation-delay: 0s;
        }

        .shape:nth-child(2) {
            width: 120px;
            height: 120px;
            background: var(--secondary);
            border-radius: 38% 62% 63% 37% / 41% 44% 56% 59%;
            left: 70%;
            top: 60%;
            animation-delay: 2s;
        }

        .shape:nth-child(3) {
            width: 100px;
            height: 100px;
            background: var(--accent);
            border-radius: 63% 37% 54% 46% / 55% 48% 52% 45%;
            left: 40%;
            top: 80%;
            animation-delay: 4s;
        }

        @keyframes float {
            0%, 100% { transform: translateY(0) rotate(0deg); }
            33% { transform: translateY(-30px) rotate(120deg); }
            66% { transform: translateY(30px) rotate(240deg); }
        }

        /* ===== 布局 ===== */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 1.5rem;
            position: relative;
            z-index: 1;
        }

        /* ===== 导航栏 ===== */
        .nav-header {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(15, 23, 42, 0.85);
            backdrop-filter: blur(20px);
            z-index: 1000;
            border-bottom: 1px solid var(--border-color);
            transition: var(--transition);
        }

        .nav-content {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 1rem 0;
        }

        .nav-title {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .nav-title h1 {
            font-size: 1.25rem;
            font-weight: 600;
            background: var(--primary-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .nav-menu {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        /* 进度条 */
        .progress-container {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: rgba(255, 255, 255, 0.1);
        }

        .progress-bar {
            height: 100%;
            background: var(--primary-gradient);
            width: 0;
            transition: width 0.3s ease;
        }

        /* ===== 侧边栏 ===== */
        .sidebar {
            position: fixed;
            left: -300px;
            top: 60px;
            bottom: 0;
            width: 300px;
            background: var(--bg-section);
            border-right: 1px solid var(--border-color);
            padding: 2rem;
            overflow-y: auto;
            transition: transform 0.3s ease;
            z-index: 999;
            box-shadow: 5px 0 25px rgba(0, 0, 0, 0.5);
        }

        .sidebar.open {
            transform: translateX(300px);
        }

        .toc-title {
            color: var(--primary-light);
            margin-bottom: 1.5rem;
            font-size: 1.1rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-section {
            margin-bottom: 1.5rem;
        }

        .toc-section-title {
            color: var(--text-muted);
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.5rem;
            padding-left: 0.5rem;
        }

        .toc-item {
            display: block;
            padding: 0.75rem 1rem;
            color: var(--text-secondary);
            text-decoration: none;
            border-radius: 0.5rem;
            transition: all 0.3s ease;
            margin-bottom: 0.25rem;
            font-size: 0.95rem;
            position: relative;
            overflow: hidden;
        }

        .toc-item::before {
            content: '';
            position: absolute;
            left: 0;
            top: 0;
            bottom: 0;
            width: 3px;
            background: var(--primary);
            transform: translateX(-100%);
            transition: transform 0.3s ease;
        }

        .toc-item:hover {
            background: rgba(255, 255, 255, 0.05);
            color: var(--text-primary);
            padding-left: 1.5rem;
        }

        .toc-item.active {
            background: var(--card-gradient);
            color: var(--primary-light);
        }

        .toc-item.active::before {
            transform: translateX(0);
        }

        /* ===== 按钮样式 ===== */
        .btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            border-radius: 0.5rem;
            font-size: 0.95rem;
            font-weight: 500;
            text-decoration: none;
            transition: var(--transition);
            cursor: pointer;
            border: none;
            position: relative;
            overflow: hidden;
        }

        .btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 50%;
            transform: translate(-50%, -50%);
            transition: width 0.5s, height 0.5s;
        }

        .btn:hover::before {
            width: 300px;
            height: 300px;
        }

        .btn-primary {
            background: var(--primary-gradient);
            color: white;
        }

        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-primary);
            border: 1px solid var(--border-color);
        }

        .btn-icon {
            background: transparent;
            padding: 0.5rem;
            color: var(--text-secondary);
        }

        /* ===== 主内容 ===== */
        main {
            margin-top: 80px;
            padding-bottom: 4rem;
            position: relative;
            z-index: 1;
        }

        /* ===== 章节头部 ===== */
        .chapter-hero {
            background: var(--hero-gradient);
            padding: 6rem 0;
            margin-bottom: 3rem;
            position: relative;
            overflow: hidden;
        }

        .chapter-hero::before {
            content: '';
            position: absolute;
            top: -50%;
            right: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            animation: rotate 30s linear infinite;
        }

        @keyframes rotate {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }

        .chapter-hero-content {
            text-align: center;
            color: white;
            position: relative;
            z-index: 1;
        }

        .chapter-hero h1 {
            font-size: 3.5rem;
            margin-bottom: 1rem;
            font-weight: 800;
            letter-spacing: -0.02em;
            animation: fadeInUp 0.8s ease;
        }

        .chapter-hero p {
            font-size: 1.5rem;
            opacity: 0.95;
            animation: fadeInUp 0.8s ease 0.2s both;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* ===== 内容卡片 ===== */
        .section-card {
            background: var(--bg-section);
            border-radius: var(--radius);
            padding: 3rem;
            margin-bottom: 2rem;
            box-shadow: var(--shadow);
            position: relative;
            overflow: hidden;
        }

        .section-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: var(--primary-gradient);
            transform: scaleX(0);
            transform-origin: left;
            transition: transform 0.5s ease;
        }

        .section-card:hover::before {
            transform: scaleX(1);
        }

        .section-card h2 {
            color: var(--primary-light);
            margin-bottom: 2rem;
            font-size: 2.25rem;
            font-weight: 700;
        }

        .section-card h3 {
            color: var(--text-primary);
            margin: 2rem 0 1rem;
            font-size: 1.5rem;
            font-weight: 600;
        }

        /* ===== 故事卡片 ===== */
        .story-card {
            background: linear-gradient(135deg, rgba(250, 112, 154, 0.1), rgba(254, 225, 64, 0.1));
            border: 2px solid rgba(250, 112, 154, 0.3);
            border-radius: var(--radius);
            padding: 2.5rem;
            margin: 2rem 0;
            position: relative;
            overflow: hidden;
        }

        .story-card::after {
            content: '';
            position: absolute;
            top: -2px;
            left: -2px;
            right: -2px;
            bottom: -2px;
            background: var(--hero-gradient);
            z-index: -1;
            opacity: 0;
            transition: opacity 0.3s ease;
            border-radius: var(--radius);
        }

        .story-card:hover::after {
            opacity: 0.3;
        }

        .story-icon {
            font-size: 3rem;
            display: block;
            margin-bottom: 1rem;
            animation: pulse 2s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        /* ===== 代码块 ===== */
        .code-block {
            background: var(--bg-code);
            border: 1px solid #30363d;
            border-radius: 0.75rem;
            margin: 1.5rem 0;
            position: relative;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
        }

        .code-header {
            background: #161b22;
            padding: 1rem 1.5rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid #30363d;
        }

        .code-lang {
            color: var(--primary-light);
            font-size: 0.875rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .code-lang::before {
            content: '';
            width: 12px;
            height: 12px;
            background: var(--primary);
            border-radius: 50%;
            display: inline-block;
        }

        .code-actions {
            display: flex;
            gap: 0.5rem;
        }

        .code-btn {
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--text-secondary);
            padding: 0.375rem 0.875rem;
            border-radius: 0.375rem;
            font-size: 0.75rem;
            cursor: pointer;
            transition: all 0.2s;
            font-weight: 500;
        }

        .code-btn:hover {
            background: var(--primary);
            color: white;
            border-color: var(--primary);
            transform: translateY(-1px);
        }

        .code-content {
            padding: 1.5rem;
            overflow-x: auto;
            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Code', monospace;
            font-size: 0.875rem;
            line-height: 1.7;
        }

        .code-content pre {
            margin: 0;
            color: #e6edf3;
        }

        .code-content.collapsed {
            max-height: 300px;
            overflow: hidden;
            position: relative;
        }

        .code-content.collapsed::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 100px;
            background: linear-gradient(transparent, var(--bg-code));
        }

        /* 代码高亮 */
        .keyword { color: #ff79c6; }
        .string { color: #f1fa8c; }
        .comment { color: #6272a4; }
        .function { color: #50fa7b; }
        .number { color: #bd93f9; }

        /* ===== 卡片网格 ===== */
        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 2rem;
            margin: 2rem 0;
        }

        .info-card {
            background: var(--bg-card);
            border-radius: var(--radius);
            padding: 2rem;
            border: 1px solid var(--border-color);
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .info-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: var(--primary-gradient);
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .info-card:hover {
            transform: translateY(-5px);
            box-shadow: var(--shadow-lg);
            border-color: var(--primary);
        }

        .info-card:hover::before {
            opacity: 0.05;
        }

        .card-icon {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            display: block;
        }

        .card-title {
            color: var(--primary-light);
            margin-bottom: 1rem;
            font-size: 1.25rem;
            font-weight: 600;
        }

        /* ===== 互动演示 ===== */
        .demo-container {
            background: linear-gradient(135deg, rgba(59, 130, 246, 0.1), rgba(139, 92, 246, 0.1));
            border: 2px solid rgba(59, 130, 246, 0.3);
            border-radius: var(--radius);
            padding: 2.5rem;
            margin: 2rem 0;
            position: relative;
            overflow: hidden;
        }

        .demo-container::before {
            content: '🧪';
            position: absolute;
            top: -20px;
            right: 20px;
            font-size: 4rem;
            opacity: 0.1;
        }

        .demo-input {
            width: 100%;
            padding: 1rem 1.5rem;
            background: var(--bg-dark);
            border: 2px solid var(--border-color);
            border-radius: 0.5rem;
            color: var(--text-primary);
            font-size: 1.1rem;
            margin-bottom: 1rem;
            transition: all 0.3s;
        }

        .demo-input:focus {
            outline: none;
            border-color: var(--primary);
            box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
        }

        .demo-button {
            background: var(--primary-gradient);
            color: white;
            border: none;
            padding: 1rem 2.5rem;
            border-radius: 0.5rem;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            position: relative;
            overflow: hidden;
        }

        .demo-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(99, 102, 241, 0.3);
        }

        .demo-result {
            margin-top: 2rem;
            padding: 1.5rem;
            background: var(--bg-dark);
            border-radius: 0.75rem;
            min-height: 120px;
            border: 1px solid var(--border-color);
        }

        /* ===== 向量可视化 ===== */
        .vector-display {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin: 1rem 0;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 0.5rem;
        }

        .vector-label {
            font-weight: 600;
            color: var(--primary-light);
            min-width: 80px;
        }

        .vector-values {
            display: flex;
            gap: 0.5rem;
            flex-wrap: wrap;
        }

        .vector-value {
            background: var(--bg-card);
            padding: 0.25rem 0.75rem;
            border-radius: 0.25rem;
            font-family: monospace;
            font-size: 0.875rem;
            border: 1px solid var(--border-color);
        }

        /* ===== 3D可视化容器 ===== */
        .visualization-3d {
            background: var(--bg-card);
            border-radius: var(--radius);
            padding: 2rem;
            margin: 2rem 0;
            height: 500px;
            position: relative;
            overflow: hidden;
        }

        #vector-space {
            width: 100%;
            height: 100%;
            border-radius: 0.5rem;
            cursor: grab;
        }

        #vector-space:active {
            cursor: grabbing;
        }

        /* ===== 相似度热力图 ===== */
        .heatmap {
            background: var(--bg-card);
            border-radius: var(--radius);
            padding: 2rem;
            margin: 2rem 0;
            overflow-x: auto;
        }

        .heatmap-grid {
            display: inline-block;
            min-width: 600px;
        }

        .heatmap-row {
            display: flex;
            gap: 2px;
        }

        .heatmap-cell {
            width: 60px;
            height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.875rem;
            font-weight: 500;
            border-radius: 0.25rem;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .heatmap-cell:hover {
            transform: scale(1.1);
            z-index: 10;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }

        .heatmap-label {
            background: var(--bg-dark);
            font-weight: 600;
            color: var(--text-secondary);
        }

        /* ===== 流程图 ===== */
        .flow-diagram {
            background: var(--bg-card);
            border-radius: var(--radius);
            padding: 2.5rem;
            margin: 2rem 0;
            overflow-x: auto;
        }

        .flow-container {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 2rem;
            min-width: 800px;
            padding: 2rem 0;
        }

        .flow-step {
            background: var(--bg-section);
            border: 2px solid var(--border-color);
            border-radius: var(--radius);
            padding: 2rem;
            text-align: center;
            min-width: 150px;
            transition: all 0.3s ease;
            position: relative;
        }

        .flow-step:hover {
            transform: translateY(-5px);
            border-color: var(--primary);
            box-shadow: var(--shadow);
        }

        .flow-step-icon {
            font-size: 3rem;
            margin-bottom: 1rem;
            display: block;
        }

        .flow-step-title {
            font-weight: 600;
            color: var(--primary-light);
            margin-bottom: 0.5rem;
        }

        .flow-arrow {
            font-size: 2rem;
            color: var(--primary);
            animation: arrow-move 1.5s ease-in-out infinite;
        }

        @keyframes arrow-move {
            0%, 100% { transform: translateX(0); }
            50% { transform: translateX(10px); }
        }

        /* ===== 提示框 ===== */
        .tip {
            padding: 1.5rem 2rem;
            border-radius: var(--radius);
            margin: 2rem 0;
            border-left: 4px solid;
            position: relative;
            overflow: hidden;
        }

        .tip::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            opacity: 0.05;
            background: currentColor;
        }

        .tip-icon {
            font-size: 1.5rem;
            margin-right: 1rem;
            vertical-align: middle;
        }

        .tip.info {
            background: rgba(59, 130, 246, 0.1);
            border-color: var(--info);
            color: var(--text-primary);
        }

        .tip.warning {
            background: rgba(245, 158, 11, 0.1);
            border-color: var(--warning);
            color: var(--text-primary);
        }

        .tip.success {
            background: rgba(16, 185, 129, 0.1);
            border-color: var(--success);
            color: var(--text-primary);
        }

        .tip.danger {
            background: rgba(239, 68, 68, 0.1);
            border-color: var(--danger);
            color: var(--text-primary);
        }

        /* ===== 对比表格 ===== */
        .comparison-table {
            background: var(--bg-card);
            border-radius: var(--radius);
            overflow: hidden;
            margin: 2rem 0;
            box-shadow: var(--shadow);
        }

        .comparison-table table {
            width: 100%;
            border-collapse: collapse;
        }

        .comparison-table th {
            background: var(--primary-gradient);
            color: white;
            padding: 1.25rem;
            text-align: left;
            font-weight: 600;
            font-size: 0.95rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .comparison-table td {
            padding: 1.25rem;
            border-bottom: 1px solid var(--border-color);
            transition: all 0.3s ease;
        }

        .comparison-table tr:hover td {
            background: rgba(99, 102, 241, 0.05);
        }

        .comparison-table tr:last-child td {
            border-bottom: none;
        }

        /* ===== 算法步骤 ===== */
        .algorithm-steps {
            background: linear-gradient(135deg, rgba(139, 92, 246, 0.1), rgba(167, 139, 250, 0.05));
            border: 2px solid rgba(139, 92, 246, 0.3);
            border-radius: var(--radius);
            padding: 2.5rem;
            margin: 2rem 0;
        }

        .step-item {
            display: flex;
            align-items: flex-start;
            margin-bottom: 2rem;
            position: relative;
        }

        .step-item:not(:last-child)::after {
            content: '';
            position: absolute;
            left: 24px;
            top: 50px;
            bottom: -30px;
            width: 2px;
            background: linear-gradient(to bottom, var(--primary), transparent);
        }

        .step-number {
            width: 48px;
            height: 48px;
            background: var(--primary-gradient);
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 1.25rem;
            margin-right: 1.5rem;
            flex-shrink: 0;
            position: relative;
            z-index: 1;
        }

        .step-content h5 {
            color: var(--primary-light);
            margin-bottom: 0.5rem;
            font-size: 1.25rem;
        }

        /* ===== 数学公式 ===== */
        .math-display {
            background: linear-gradient(135deg, rgba(139, 92, 246, 0.05), rgba(99, 102, 241, 0.05));
            border: 2px solid rgba(139, 92, 246, 0.2);
            border-radius: var(--radius);
            padding: 2rem;
            margin: 2rem 0;
            text-align: center;
            font-size: 1.2rem;
            overflow-x: auto;
        }

        .math-formula {
            font-family: 'KaTeX_Math', 'Times New Roman', serif;
            font-style: italic;
            color: var(--primary-light);
            font-size: 1.3rem;
            margin: 1rem 0;
        }

        /* ===== 词云效果 ===== */
        .word-cloud {
            background: var(--bg-card);
            border-radius: var(--radius);
            padding: 3rem;
            margin: 2rem 0;
            text-align: center;
            position: relative;
            min-height: 400px;
        }

        .word-item {
            position: absolute;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            animation: float-word 20s infinite ease-in-out;
        }

        .word-item:hover {
            transform: scale(1.2) !important;
            color: var(--primary-light) !important;
            z-index: 10;
        }

        @keyframes float-word {
            0%, 100% { transform: translateY(0); }
            50% { transform: translateY(-10px); }
        }

        /* ===== 快速导航 ===== */
        .quick-nav {
            position: fixed;
            right: 2rem;
            top: 50%;
            transform: translateY(-50%);
            z-index: 100;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .quick-nav-item {
            width: 12px;
            height: 12px;
            background: var(--text-muted);
            border-radius: 50%;
            transition: all 0.3s;
            position: relative;
            cursor: pointer;
        }

        .quick-nav-item:hover,
        .quick-nav-item.active {
            background: var(--primary);
            transform: scale(1.5);
        }

        .quick-nav-tooltip {
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            background: var(--bg-dark);
            padding: 0.5rem 1rem;
            border-radius: 0.5rem;
            white-space: nowrap;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.3s;
            border: 1px solid var(--border-color);
            font-size: 0.875rem;
        }

        .quick-nav-item:hover .quick-nav-tooltip {
            opacity: 1;
        }

        /* ===== 思考框 ===== */
        .think-box {
            background: linear-gradient(135deg, rgba(251, 191, 36, 0.1), rgba(245, 158, 11, 0.1));
            border: 2px solid rgba(251, 191, 36, 0.3);
            border-radius: var(--radius);
            padding: 2rem;
            margin: 2rem 0;
            position: relative;
        }

        .think-box::before {
            content: '🤔';
            position: absolute;
            top: -15px;
            left: 25px;
            font-size: 2rem;
            background: var(--bg-section);
            padding: 0 0.5rem;
        }

        .think-box h4 {
            color: var(--warning);
            margin-bottom: 1rem;
        }

        .think-box ul {
            list-style: none;
            padding: 0;
        }

        .think-box li {
            margin-bottom: 0.5rem;
            padding-left: 1.5rem;
            position: relative;
        }

        .think-box li::before {
            content: '💭';
            position: absolute;
            left: 0;
        }

        /* KaTeX样式调整 */
        .katex-display {
            margin: 1.5rem 0 !important;
        }

        .katex {
            font-size: 1.1em;
            color: var(--primary-light);
        }

        /* ===== 响应式设计 ===== */
        @media (max-width: 768px) {
            .chapter-hero h1 {
                font-size: 2.5rem;
            }

            .section-card {
                padding: 2rem;
            }

            .quick-nav {
                display: none;
            }

            .card-grid {
                grid-template-columns: 1fr;
            }

            .flow-container {
                flex-direction: column;
                min-width: auto;
            }

            .flow-arrow {
                transform: rotate(90deg);
            }
        }

        /* ===== 加载动画 ===== */
        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: white;
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* ===== 数学公式解释样式 ===== */
        .formula-explanation {
            background: rgba(99, 102, 241, 0.05);
            border: 1px solid rgba(99, 102, 241, 0.2);
            border-radius: 0.5rem;
            padding: 1.5rem;
            margin-top: 1.5rem;
        }

        .formula-explanation h5 {
            color: var(--primary-light);
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .formula-table {
            width: 100%;
            margin: 1rem 0;
        }

        .formula-table td {
            padding: 0.75rem;
            vertical-align: middle;
        }

        .formula-table .formula-part {
            font-family: 'KaTeX_Math', serif;
            font-size: 1.2rem;
            color: var(--primary);
            white-space: nowrap;
            width: 30%;
        }

        .formula-table .formula-meaning {
            color: var(--text-primary);
            font-size: 0.95rem;
            line-height: 1.6;
        }

        .code-from-math {
            background: var(--bg-code);
            border: 1px solid #30363d;
            border-radius: 0.5rem;
            padding: 1rem;
            margin-top: 1rem;
        }

        .code-from-math h6 {
            color: var(--success);
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
        }

        .training-example {
            background: rgba(59, 130, 246, 0.05);
            border-radius: var(--radius);
            padding: 2rem;
            margin-top: 1.5rem;
        }

        .training-step {
            background: var(--bg-dark);
            border-radius: 0.5rem;
            padding: 1.5rem;
            border-left: 3px solid var(--primary);
        }

        .training-step h5 {
            color: var(--primary-light);
            margin-bottom: 1rem;
        }

        /* ===== 工具类 ===== */
        .text-center { text-align: center; }
        .text-muted { color: var(--text-muted); }
        .mt-1 { margin-top: 0.5rem; }
        .mt-2 { margin-top: 1rem; }
        .mt-3 { margin-top: 1.5rem; }
        .mt-4 { margin-top: 2rem; }
        .mb-1 { margin-bottom: 0.5rem; }
        .mb-2 { margin-bottom: 1rem; }
        .mb-3 { margin-bottom: 1.5rem; }
        .mb-4 { margin-bottom: 2rem; }
        .flex { display: flex; }
        .items-center { align-items: center; }
        .justify-between { justify-content: space-between; }
        .gap-1 { gap: 0.5rem; }
        .gap-2 { gap: 1rem; }
    </style>
</head>
<body>

<!-- 背景效果 -->
<div class="bg-pattern"></div>
<div class="floating-shapes">
    <div class="shape"></div>
    <div class="shape"></div>
    <div class="shape"></div>
</div>

<!-- 导航栏 -->
<nav class="nav-header">
    <div class="container">
        <div class="nav-content">
            <div class="nav-title">
                <button id="toggle-sidebar" class="btn btn-icon">
                    <svg width="20" height="20" fill="currentColor">
                        <path d="M3 5h14M3 10h14M3 15h14" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                    </svg>
                </button>
                <h1>第3章：词向量与文本表示</h1>
            </div>
            <div class="nav-menu">
                <button class="btn btn-icon" id="theme-toggle">🌙</button>
                <a href="#summary" class="btn btn-secondary">章节总结</a>
            </div>
        </div>
        <div class="progress-container">
            <div class="progress-bar" id="progress-bar"></div>
        </div>
    </div>
</nav>

<!-- 侧边栏 -->
<aside class="sidebar" id="sidebar">
    <h3 class="toc-title">
        <span>📚</span>
        <span>本章导航</span>
    </h3>

    <div class="toc-section">
        <div class="toc-section-title">开篇</div>
        <a href="#intro" class="toc-item active">序言：国王-男人+女人=？</a>
        <a href="#why-vectors" class="toc-item">为什么需要词向量</a>
    </div>

    <div class="toc-section">
        <div class="toc-section-title">词向量基础</div>
        <a href="#one-hot" class="toc-item">独热编码：最简单的尝试</a>
        <a href="#distributed" class="toc-item">分布式表示：语义的密码</a>
        <a href="#word2vec" class="toc-item">Word2Vec：开创性的突破</a>
        <a href="#visualization" class="toc-item">词向量可视化</a>
    </div>

    <div class="toc-section">
        <div class="toc-section-title">进阶技术</div>
        <a href="#glove" class="toc-item">GloVe：全局视角</a>
        <a href="#fasttext" class="toc-item">FastText：子词的力量</a>
        <a href="#contextual" class="toc-item">上下文词向量</a>
    </div>

    <div class="toc-section">
        <div class="toc-section-title">实践应用</div>
        <a href="#similarity" class="toc-item">相似度计算</a>
        <a href="#document-vectors" class="toc-item">文档向量</a>
        <a href="#applications" class="toc-item">实际应用案例</a>
    </div>

    <div class="toc-section">
        <div class="toc-section-title">总结展望</div>
        <a href="#summary" class="toc-item">本章总结</a>
        <a href="#exercises" class="toc-item">练习题</a>
    </div>
</aside>

<!-- 快速导航 -->
<div class="quick-nav" id="quick-nav">
    <div class="quick-nav-item active" data-section="intro">
        <span class="quick-nav-tooltip">开篇故事</span>
    </div>
    <div class="quick-nav-item" data-section="one-hot">
        <span class="quick-nav-tooltip">独热编码</span>
    </div>
    <div class="quick-nav-item" data-section="word2vec">
        <span class="quick-nav-tooltip">Word2Vec</span>
    </div>
    <div class="quick-nav-item" data-section="applications">
        <span class="quick-nav-tooltip">实际应用</span>
    </div>
    <div class="quick-nav-item" data-section="summary">
        <span class="quick-nav-tooltip">章节总结</span>
    </div>
</div>

<!-- 主内容 -->
<main>
    <!-- 章节标题 -->
    <section class="chapter-hero">
        <div class="container">
            <div class="chapter-hero-content">
                <h1>词向量与文本表示</h1>
                <p>让机器理解语义的魔法</p>
            </div>
        </div>
    </section>

    <div class="container">
        <!-- 序言 -->
        <section id="intro" class="section-card">
            <h2>👑 序言：国王 - 男人 + 女人 = ？</h2>

            <div class="story-card">
                <span class="story-icon">🧙</span>
                <p><strong>2013年，Google研究院，一个改变NLP历史的下午。</strong></p>
                <p class="mt-2">
                    Tomas Mikolov盯着屏幕上的结果，简直不敢相信自己的眼睛。他刚刚让计算机做了一道"词汇算术题"：
                </p>
                <div class="math-display mt-3">
                    <p class="math-formula" style="font-size: 1.8rem;">
                        $\vec{v}_{\text{国王}} - \vec{v}_{\text{男人}} + \vec{v}_{\text{女人}} = \vec{v}_{\text{女王}}$
                    </p>
                    <div class="formula-explanation">
                        <h5>📖 公式解读：</h5>
                        <table class="formula-table">
                            <tr>
                                <td class="formula-part">$\vec{v}_{\text{国王}}$</td>
                                <td class="formula-meaning">国王的词向量（比如300维的数组）</td>
                            </tr>
                            <tr>
                                <td class="formula-part">$-\vec{v}_{\text{男人}}$</td>
                                <td class="formula-meaning">减去"男人"的向量，去除男性特征</td>
                            </tr>
                            <tr>
                                <td class="formula-part">$+\vec{v}_{\text{女人}}$</td>
                                <td class="formula-meaning">加上"女人"的向量，添加女性特征</td>
                            </tr>
                            <tr>
                                <td class="formula-part">$=\vec{v}_{\text{女王}}$</td>
                                <td class="formula-meaning">结果接近"女王"的向量</td>
                            </tr>
                        </table>
                        <p class="mt-2"><strong>💡 原理：</strong>词向量空间中，语义关系对应几何关系。"国王→女王"的变化等于"男人→女人"的变化。</p>
                        <div class="demo-container mt-4">
                            <h3 class="text-center mb-3" style="color: var(--primary-light);">🧮 为什么词向量能做"算术题"？</h3>

                            <div class="training-example">
                                <h4>深入理解：向量运算背后的几何意义</h4>

                                <div class="training-step">
                                    <h5>以"国王-男人+女人=女王"为例</h5>
                                    <p>假设词向量只有2维（方便理解）：</p>
                                    <pre style="background: var(--bg-code); padding: 1rem; border-radius: 0.5rem;">
国王 = [3.0, 2.0]  <span class="comment"># 位置：既有王权(x轴)，又偏男性(y轴)</span>
男人 = [1.0, 2.0]  <span class="comment"># 位置：普通人，偏男性</span>
女人 = [1.0, -2.0] <span class="comment"># 位置：普通人，偏女性</span>
女王 = [3.0, -2.0] <span class="comment"># 位置：有王权，偏女性</span>

<span class="comment"># 计算过程</span>
国王 - 男人 = [3.0, 2.0] - [1.0, 2.0] = [2.0, 0.0]  <span class="comment"># 得到"王权向量"</span>
结果 + 女人 = [2.0, 0.0] + [1.0, -2.0] = [3.0, -2.0] <span class="comment"># 正好是女王！</span></pre>
                                </div>

                                <div class="training-step mt-3">
                                    <h5>几何解释</h5>
                                    <svg width="400" height="300" viewBox="0 0 400 300" style="background: var(--bg-dark); border-radius: 0.5rem; margin: 1rem auto; display: block;">
                                        <!-- 坐标轴 -->
                                        <line x1="50" y1="150" x2="350" y2="150" stroke="#475569" stroke-width="2"/>
                                        <line x1="200" y1="50" x2="200" y2="250" stroke="#475569" stroke-width="2"/>

                                        <!-- 坐标轴标签 -->
                                        <text x="360" y="155" fill="#94a3b8" font-size="12">王权维度</text>
                                        <text x="205" y="45" fill="#94a3b8" font-size="12">性别维度</text>

                                        <!-- 词向量点 -->
                                        <circle cx="250" cy="100" r="6" fill="#6366f1"/>
                                        <text x="260" y="95" fill="#f1f5f9" font-size="14">国王</text>

                                        <circle cx="150" cy="100" r="6" fill="#3b82f6"/>
                                        <text x="110" y="95" fill="#f1f5f9" font-size="14">男人</text>

                                        <circle cx="150" cy="200" r="6" fill="#ec4899"/>
                                        <text x="110" y="220" fill="#f1f5f9" font-size="14">女人</text>

                                        <circle cx="250" cy="200" r="6" fill="#f472b6"/>
                                        <text x="260" y="220" fill="#f1f5f9" font-size="14">女王</text>

                                        <!-- 向量箭头 -->
                                        <defs>
                                            <marker id="arrowhead3" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                                <polygon points="0 0, 10 3.5, 0 7" fill="#f59e0b"/>
                                            </marker>
                                        </defs>

                                        <!-- 国王-男人 -->
                                        <path d="M 250 100 L 150 100" stroke="#f59e0b" stroke-width="2" stroke-dasharray="5,5" opacity="0.6"/>
                                        <text x="200" y="90" fill="#f59e0b" font-size="12">-男人</text>

                                        <!-- 结果+女人 -->
                                        <path d="M 150 200 L 250 200" stroke="#10b981" stroke-width="2" marker-end="url(#arrowhead3)"/>
                                        <text x="200" y="195" fill="#10b981" font-size="12">+女人</text>
                                    </svg>

                                    <p class="mt-3"><strong>💡 关键洞察：</strong></p>
                                    <ul>
                                        <li>"国王→女王"的变化 = "男人→女人"的变化</li>
                                        <li>性别转换在向量空间中是一个固定的方向</li>
                                        <li>这个规律是模型从大量文本中自动学到的！</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <p class="mt-3">
                    "这怎么可能？"他的同事凑过来看，"计算机怎么会知道国王和女王的关系？"
                </p>
                <p class="mt-2">
                    Mikolov微笑着说："因为我们找到了一种方法，让每个词都变成了空间中的一个点。在这个空间里，语义关系变成了几何关系。"
                </p>
                <p class="mt-3 text-center" style="font-size: 1.25rem; color: var(--warning);">
                    💡 这就是词向量的魔法——把语言变成数学，把意义变成向量！
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>为什么"国王-男人+女人"会等于"女王"？这背后的数学原理是什么？</li>
                    <li>如果用同样的方法，"北京-中国+日本"会等于什么？</li>
                    <li>这种向量运算真的理解了词的含义，还是只是巧合？</li>
                </ul>
            </div>

            <div class="demo-container">
                <h3 class="text-center mb-3" style="color: var(--primary-light);">🎯 更多神奇的词向量运算</h3>

                <div class="card-grid">
                    <div class="info-card">
                        <span class="card-icon">🏙️</span>
                        <h4 class="card-title">地理关系</h4>
                        <p class="math-formula">
                            $$\vec{v}_{\text{北京}} - \vec{v}_{\text{中国}} + \vec{v}_{\text{日本}} = \vec{v}_{\text{东京}}$$
                        </p>
                        <p class="mt-2 text-muted">首都之于国家的关系被完美捕获</p>
                    </div>

                    <div class="info-card">
                        <span class="card-icon">⏰</span>
                        <h4 class="card-title">动词时态</h4>
                        <p class="math-formula">
                            $$\vec{v}_{\text{走}} - \vec{v}_{\text{走路}} + \vec{v}_{\text{跑步}} = \vec{v}_{\text{跑}}$$
                        </p>
                        <p class="mt-2 text-muted">动词形态的规律被向量编码</p>
                    </div>

                    <div class="info-card">
                        <span class="card-icon">📐</span>
                        <h4 class="card-title">大小关系</h4>
                        <p class="math-formula">
                            $$\vec{v}_{\text{最大}} - \vec{v}_{\text{大}} + \vec{v}_{\text{小}} = \vec{v}_{\text{最小}}$$
                        </p>
                        <p class="mt-2 text-muted">程度关系的语义规律</p>
                    </div>
                </div>

                <div class="tip info mt-4">
                    <span class="tip-icon">🤯</span>
                    <strong>令人震惊的发现</strong>
                    <p class="mt-2">
                        这些关系不是人为编程的，而是模型从海量文本中自动学到的！就像孩子通过大量阅读自然理解了语言规律。
                    </p>
                </div>
            </div>

            <div class="visualization-3d">
                <h4 class="text-center mb-3" style="color: var(--primary-light);">📊 词向量空间可视化</h4>
                <canvas id="vector-space"></canvas>
            </div>
        </section>

        <!-- 为什么需要词向量 -->
        <section id="why-vectors" class="section-card">
            <h2>🎯 为什么需要词向量？</h2>

            <div class="story-card">
                <span class="story-icon">🤖</span>
                <p><strong>机器眼中的文字：从混沌到秩序</strong></p>
                <p class="mt-2">
                    想象你是一个刚被创造出来的AI，第一次"看到"人类的文字：
                </p>
                <div class="code-block mt-3">
                    <div class="code-header">
                        <span class="code-lang">机器视角</span>
                    </div>
                    <div class="code-content">
                        <pre>人类说："小猫喜欢喝牛奶"
机器看到：[0x5C0F, 0x732B, 0x559C, 0x6B22, 0x5403, 0x725B, 0x5976]

人类说："小狗喜欢吃骨头"
机器看到：[0x5C0F, 0x72D7, 0x559C, 0x6B22, 0x5403, 0x9AA8, 0x5934]

机器的困惑：0x732B（猫）和 0x72D7（狗）有什么关系？
            0x5976（牛奶）和 0x9AA8（骨头）又有什么联系？</pre>
                    </div>
                </div>
                <p class="mt-3">
                    对机器来说，"猫"和"狗"只是两个毫无关联的符号，就像"😺"和"🚗"一样随机。
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>如果你要教一个完全不懂中文的外国人理解"猫"和"狗"的关系，你会怎么做？</li>
                    <li>为什么人类能轻易理解"小猫"和"小狗"都是宠物，而机器却不能？</li>
                    <li>符号和意义之间的鸿沟该如何跨越？</li>
                </ul>
            </div>

            <h3>从符号到意义的三次飞跃</h3>

            <div class="algorithm-steps">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>符号化：给每个词一个身份证</h5>
                        <p>最原始的方法：词典编号</p>
                        <div class="code-block mt-3">
                            <div class="code-header">
                                <span class="code-lang">词典映射</span>
                            </div>
                            <div class="code-content">
                                <pre>word_to_id = {
    "小猫": 1,
    "小狗": 2,
    "牛奶": 3,
    "骨头": 4,
    "喜欢": 5,
    "吃": 6,
    "喝": 7
}

# 句子变成了数字序列
"小猫喜欢喝牛奶" → [1, 5, 7, 3]
"小狗喜欢吃骨头" → [2, 5, 6, 4]</pre>
                            </div>
                        </div>
                        <p class="mt-2" style="color: var(--danger);">
                            ❌ 问题：1和2之间的距离等于2和100之间的距离吗？数字大小有意义吗？
                        </p>

                        <div class="think-box mt-3">
                            <h4>🤔 深入思考</h4>
                            <ul>
                                <li>如果"小猫"是1，"小狗"是2，那"大象"是3，这样的编号合理吗？</li>
                                <li>词典编号能体现出"小猫"和"小狗"都是动物这个信息吗？</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>离散化：独热编码（One-Hot）</h5>
                        <p>每个词用一个只有一个1的向量表示</p>
                        <div class="vector-display">
                            <span class="vector-label">小猫：</span>
                            <div class="vector-values">
                                <span class="vector-value" style="background: var(--success);">1</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                            </div>
                        </div>
                        <div class="vector-display">
                            <span class="vector-label">小狗：</span>
                            <div class="vector-values">
                                <span class="vector-value">0</span>
                                <span class="vector-value" style="background: var(--success);">1</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                                <span class="vector-value">0</span>
                            </div>
                        </div>
                        <p class="mt-2" style="color: var(--danger);">
                            ❌ 问题：所有词之间的距离都相等，"小猫"和"小狗"的距离 = "小猫"和"民主"的距离
                        </p>

                        <div class="math-display mt-3">
                            <p>余弦相似度计算：</p>
                            <p class="math-formula">
                                $\cos(\vec{v}_{\text{小猫}}, \vec{v}_{\text{小狗}}) = \frac{\vec{v}_{\text{小猫}} \cdot \vec{v}_{\text{小狗}}}{||\vec{v}_{\text{小猫}}|| \times ||\vec{v}_{\text{小狗}}||} = 0$
                            </p>
                            <div class="formula-explanation">
                                <h5>📖 为什么结果是0？</h5>
                                <p>独热编码下，小猫=[1,0,0,0,0]，小狗=[0,1,0,0,0]</p>
                                <table class="formula-table">
                                    <tr>
                                        <td class="formula-part">分子：点积</td>
                                        <td class="formula-meaning">1×0 + 0×1 + 0×0 + ... = 0（没有相同位置都是1）</td>
                                    </tr>
                                    <tr>
                                        <td class="formula-part">分母：长度乘积</td>
                                        <td class="formula-meaning">1 × 1 = 1（两个向量长度都是1）</td>
                                    </tr>
                                    <tr>
                                        <td class="formula-part">结果</td>
                                        <td class="formula-meaning">0 ÷ 1 = 0（完全不相似）</td>
                                    </tr>
                                </table>
                            </div>
                            <p class="mt-2 text-muted">所有不同词之间的相似度都是0！</p>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>连续化：分布式表示（词向量）</h5>
                        <p>每个词用一个稠密的实数向量表示</p>
                        <div class="vector-display">
                            <span class="vector-label">小猫：</span>
                            <div class="vector-values">
                                <span class="vector-value">0.21</span>
                                <span class="vector-value">-0.45</span>
                                <span class="vector-value">0.83</span>
                                <span class="vector-value">-0.12</span>
                                <span class="vector-value">0.67</span>
                                <span class="vector-value">...</span>
                            </div>
                        </div>
                        <div class="vector-display">
                            <span class="vector-label">小狗：</span>
                            <div class="vector-values">
                                <span class="vector-value">0.19</span>
                                <span class="vector-value">-0.41</span>
                                <span class="vector-value">0.79</span>
                                <span class="vector-value">-0.15</span>
                                <span class="vector-value">0.71</span>
                                <span class="vector-value">...</span>
                            </div>
                        </div>
                        <p class="mt-2" style="color: var(--success);">
                            ✅ 优势：相似的词有相似的向量，可以计算语义距离！
                        </p>

                        <div class="math-display mt-3">
                            <p>现在的余弦相似度：</p>
                            <p class="math-formula">
                                $\cos(\vec{v}_{\text{小猫}}, \vec{v}_{\text{小狗}}) \approx 0.95$
                            </p>
                            <div class="formula-explanation">
                                <h5>📖 为什么相似度这么高？</h5>
                                <p>因为"小猫"和"小狗"的词向量在很多维度上都相似：</p>
                                <pre style="background: var(--bg-code); padding: 1rem; border-radius: 0.5rem; color: #e6edf3;">
小猫 = [0.21, -0.45, 0.83, -0.12, 0.67, ...]
小狗 = [0.19, -0.41, 0.79, -0.15, 0.71, ...]
       ↑相近  ↑相近  ↑相近  ↑相近  ↑相近

<span class="comment"># 计算过程</span>
点积 = 0.21×0.19 + (-0.45)×(-0.41) + 0.83×0.79 + ... ≈ 0.92
长度_小猫 = √(0.21² + (-0.45)² + 0.83² + ...) ≈ 0.98
长度_小狗 = √(0.19² + (-0.41)² + 0.79² + ...) ≈ 0.99

余弦相似度 = 0.92 / (0.98 × 0.99) ≈ 0.95</pre>
                                <p class="mt-2"><strong>💡 这意味着：</strong>两个词在语义空间中的方向几乎相同，都是"小型宠物动物"</p>
                            </div>
                            <p class="mt-2 text-muted">语义相似的词有高相似度！</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="tip success mt-4">
                <span class="tip-icon">🎨</span>
                <strong>词向量的艺术</strong>
                <p class="mt-2">
                    词向量就像给每个词画了一幅"语义肖像"。不是用颜色和线条，而是用数字。这幅肖像捕捉了词的本质特征：
                </p>
                <ul class="mt-2">
                    <li><strong>语法特征：</strong>名词、动词、形容词...</li>
                    <li><strong>语义特征：</strong>生物、食物、情感...</li>
                    <li><strong>关联特征：</strong>常一起出现的词...</li>
                    <li><strong>文化特征：</strong>褒义、贬义、中性...</li>
                </ul>
            </div>
        </section>

        <!-- 独热编码 -->
        <section id="one-hot" class="section-card">
            <h2>🎯 独热编码：最简单的尝试</h2>

            <div class="story-card">
                <span class="story-icon">🏢</span>
                <p><strong>酒店房间的比喻</strong></p>
                <p class="mt-2">
                    想象一个有10000个房间的巨型酒店，每个词是一个客人：
                </p>
                <ul class="mt-2">
                    <li>"小猫"住在2341号房</li>
                    <li>"小狗"住在3782号房</li>
                    <li>"爱情"住在520号房（这个巧合很有趣！）</li>
                </ul>
                <p class="mt-2">
                    独热编码就是：每个客人独占一个房间，其他房间都空着。这很浪费，而且房间号告诉不了我们客人之间的关系。
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>如果中文词汇有5万个，独热编码需要多长的向量？</li>
                    <li>这种编码方式下，"美丽"和"漂亮"的关系是什么？</li>
                    <li>为什么说独热编码是"最懒"的编码方式？</li>
                </ul>
            </div>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-lang">Python - 独热编码实现</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content">
                    <pre><span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="keyword">class</span> <span class="function">OneHotEncoder</span>:
    <span class="string">"""独热编码器"""</span>

    <span class="keyword">def</span> <span class="function">__init__</span>(self):
        self.word_to_id = {}
        self.id_to_word = {}
        self.vocab_size = <span class="number">0</span>

    <span class="keyword">def</span> <span class="function">fit</span>(self, words):
        <span class="string">"""构建词汇表"""</span>
        unique_words = sorted(set(words))
        <span class="keyword">for</span> idx, word <span class="keyword">in</span> enumerate(unique_words):
            self.word_to_id[word] = idx
            self.id_to_word[idx] = word
        self.vocab_size = len(unique_words)

    <span class="keyword">def</span> <span class="function">encode</span>(self, word):
        <span class="string">"""将词编码为独热向量"""</span>
        vector = np.zeros(self.vocab_size)
        <span class="keyword">if</span> word <span class="keyword">in</span> self.word_to_id:
            vector[self.word_to_id[word]] = <span class="number">1</span>
        <span class="keyword">return</span> vector

    <span class="keyword">def</span> <span class="function">decode</span>(self, vector):
        <span class="string">"""将独热向量解码为词"""</span>
        idx = np.argmax(vector)
        <span class="keyword">return</span> self.id_to_word.get(idx, <span class="string">'<UNK>'</span>)

<span class="comment"># 使用示例</span>
words = [<span class="string">'小猫'</span>, <span class="string">'小狗'</span>, <span class="string">'牛奶'</span>, <span class="string">'骨头'</span>, <span class="string">'喜欢'</span>, <span class="string">'吃'</span>, <span class="string">'喝'</span>]
encoder = OneHotEncoder()
encoder.fit(words)

<span class="comment"># 编码</span>
cat_vector = encoder.encode(<span class="string">'小猫'</span>)
dog_vector = encoder.encode(<span class="string">'小狗'</span>)

print(<span class="string">f"'小猫'的独热编码: {cat_vector}"</span>)
print(<span class="string">f"'小狗'的独热编码: {dog_vector}"</span>)

<span class="comment"># 计算相似度（余弦相似度）</span>
<span class="keyword">def</span> <span class="function">cosine_similarity</span>(v1, v2):
    <span class="keyword">return</span> np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

similarity = cosine_similarity(cat_vector, dog_vector)
print(<span class="string">f"\n'小猫'和'小狗'的相似度: {similarity}"</span>)  <span class="comment"># 结果是0！</span></pre>
                </div>
            </div>

            <div class="demo-container">
                <h3 class="mb-3">独热编码的问题可视化</h3>

                <div class="heatmap">
                    <h4 class="text-center mb-3" style="color: var(--primary-light);">词汇相似度矩阵（独热编码）</h4>
                    <div class="heatmap-grid">
                        <div class="heatmap-row">
                            <div class="heatmap-cell heatmap-label"></div>
                            <div class="heatmap-cell heatmap-label">小猫</div>
                            <div class="heatmap-cell heatmap-label">小狗</div>
                            <div class="heatmap-cell heatmap-label">汽车</div>
                            <div class="heatmap-cell heatmap-label">飞机</div>
                        </div>
                        <div class="heatmap-row">
                            <div class="heatmap-cell heatmap-label">小猫</div>
                            <div class="heatmap-cell" style="background: #10b981;">1.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                        </div>
                        <div class="heatmap-row">
                            <div class="heatmap-cell heatmap-label">小狗</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #10b981;">1.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                        </div>
                        <div class="heatmap-row">
                            <div class="heatmap-cell heatmap-label">汽车</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #10b981;">1.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                        </div>
                        <div class="heatmap-row">
                            <div class="heatmap-cell heatmap-label">飞机</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #1e293b;">0.0</div>
                            <div class="heatmap-cell" style="background: #10b981;">1.0</div>
                        </div>
                    </div>
                    <p class="text-center mt-3 text-muted">
                        独热编码下，所有不同的词之间的相似度都是0
                    </p>
                </div>
            </div>

            <div class="tip danger mt-4">
                <span class="tip-icon">⚠️</span>
                <strong>独热编码的致命缺陷</strong>
                <ul class="mt-2">
                    <li><strong>维度灾难：</strong>词汇表有多大，向量就有多长（想象50000维！）</li>
                    <li><strong>稀疏性：</strong>99.99%的位置都是0，极度浪费</li>
                    <li><strong>语义鸿沟：</strong>无法表示词之间的任何关系</li>
                    <li><strong>泛化困难：</strong>没见过的词完全无法处理</li>
                </ul>
            </div>
        </section>

        <!-- 分布式表示 -->
        <section id="distributed" class="section-card">
            <h2>🌟 分布式表示：语义的密码</h2>

            <div class="story-card">
                <span class="story-icon">🎨</span>
                <p><strong>从黑白到彩色的世界</strong></p>
                <p class="mt-2">
                    如果独热编码是黑白照片（非0即1），那么分布式表示就是彩色照片——用连续的数值描绘出词语的丰富内涵。
                </p>
                <p class="mt-2">
                    语言学家J.R. Firth在1957年说过一句名言：
                </p>
                <blockquote class="mt-3" style="font-size: 1.2rem; font-style: italic; border-left: 4px solid var(--primary); padding-left: 1rem; color: var(--primary-light);">
                    "You shall know a word by the company it keeps."<br>
                    <small style="color: var(--text-muted);">（通过一个词的朋友圈，就能了解这个词）</small>
                </blockquote>
            </div>

            <h3>分布假设：上下文决定语义</h3>

            <div class="demo-container">
                <p class="mb-3"><strong>观察下面的句子，猜猜"咪咪"是什么：</strong></p>

                <div class="card-grid">
                    <div class="info-card">
                        <p>"咪咪喜欢吃鱼"</p>
                        <p>"咪咪在沙发上睡觉"</p>
                        <p>"咪咪追着老鼠跑"</p>
                        <p>"我家的咪咪很可爱"</p>
                        <p class="mt-3 text-center" style="color: var(--success); font-size: 1.2rem;">
                            💡 咪咪 ≈ 猫
                        </p>
                    </div>

                    <div class="info-card">
                        <p>"汪汪喜欢啃骨头"</p>
                        <p>"汪汪摇着尾巴"</p>
                        <p>"汪汪对陌生人叫"</p>
                        <p>"带汪汪去散步"</p>
                        <p class="mt-3 text-center" style="color: var(--success); font-size: 1.2rem;">
                            💡 汪汪 ≈ 狗
                        </p>
                    </div>
                </div>

                <p class="mt-3 text-center" style="color: var(--primary-light); font-size: 1.1rem;">
                    即使你从没见过"咪咪"和"汪汪"这两个词，通过上下文也能推断出它们的意思！
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 深入思考</h4>
                <ul>
                    <li>为什么说"物以类聚，人以群分"也适用于词汇？</li>
                    <li>如果一个词总是和"美味"、"香甜"、"营养"一起出现，你觉得它是什么类型的词？</li>
                    <li>这种通过上下文学习的方法，和人类学习语言有什么相似之处？</li>
                </ul>
            </div>

            <div class="algorithm-steps">
                <h4 class="mb-4" style="color: var(--primary-light);">🔍 如何学习分布式表示</h4>

                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>收集上下文</h5>
                        <p>统计每个词周围经常出现的词</p>
                        <div class="code-block mt-3">
                            <div class="code-header">
                                <span class="code-lang">上下文窗口示例</span>
                            </div>
                            <div class="code-content">
                                <pre>句子：小猫 [喜欢] 喝 牛奶 和 睡觉

对于"喜欢"，窗口大小=2时：
左侧上下文：[小猫]
右侧上下文：[喝, 牛奶]

收集到的上下文词：{小猫, 喝, 牛奶}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>构建共现矩阵</h5>
                        <p>统计词与词共同出现的频率</p>
                        <div class="comparison-table">
                            <table style="font-size: 0.9rem;">
                                <thead>
                                <tr>
                                    <th></th>
                                    <th>小猫</th>
                                    <th>小狗</th>
                                    <th>喝</th>
                                    <th>吃</th>
                                    <th>牛奶</th>
                                    <th>骨头</th>
                                </tr>
                                </thead>
                                <tbody>
                                <tr>
                                    <td><strong>小猫</strong></td>
                                    <td>0</td>
                                    <td>2</td>
                                    <td>15</td>
                                    <td>8</td>
                                    <td>20</td>
                                    <td>1</td>
                                </tr>
                                <tr>
                                    <td><strong>小狗</strong></td>
                                    <td>2</td>
                                    <td>0</td>
                                    <td>3</td>
                                    <td>18</td>
                                    <td>2</td>
                                    <td>25</td>
                                </tr>
                                <tr>
                                    <td><strong>喝</strong></td>
                                    <td>15</td>
                                    <td>3</td>
                                    <td>0</td>
                                    <td>1</td>
                                    <td>30</td>
                                    <td>0</td>
                                </tr>
                                </tbody>
                            </table>
                        </div>

                        <div class="think-box mt-3">
                            <h4>🤔 观察矩阵</h4>
                            <ul>
                                <li>为什么"小猫"和"牛奶"的共现次数比"小猫"和"骨头"多？</li>
                                <li>这个矩阵反映了什么样的语义关系？</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>降维压缩</h5>
                        <p>将高维稀疏矩阵压缩成低维稠密向量</p>
                        <div class="flow-container" style="justify-content: space-around;">
                            <div class="flow-step">
                                <span class="flow-step-icon">📊</span>
                                <div class="flow-step-title">共现矩阵</div>
                                <div class="text-muted" style="font-size: 0.875rem;">
                                    50000 × 50000<br>
                                    稀疏、高维
                                </div>
                            </div>
                            <div class="flow-arrow">→</div>
                            <div class="flow-step">
                                <span class="flow-step-icon">🔮</span>
                                <div class="flow-step-title">SVD/神经网络</div>
                                <div class="text-muted" style="font-size: 0.875rem;">
                                    降维算法<br>
                                    保留主要信息
                                </div>
                            </div>
                            <div class="flow-arrow">→</div>
                            <div class="flow-step">
                                <span class="flow-step-icon">✨</span>
                                <div class="flow-step-title">词向量</div>
                                <div class="text-muted" style="font-size: 0.875rem;">
                                    50000 × 300<br>
                                    稠密、低维
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="tip info mt-4">
                <span class="tip-icon">🧠</span>
                <strong>维度的含义：词向量在编码什么？</strong>
                <p class="mt-2">
                    300维的词向量，每一维都在编码某种语义或语法特征。虽然单个维度难以解释，但它们共同捕获了：
                </p>
                <ul class="mt-2">
                    <li><strong>语法信息：</strong>词性、时态、单复数...</li>
                    <li><strong>语义类别：</strong>生物/非生物、具体/抽象...</li>
                    <li><strong>情感色彩：</strong>积极/消极、强烈/温和...</li>
                    <li><strong>主题相关：</strong>科技、艺术、体育...</li>
                </ul>
            </div>
        </section>

        <!-- Word2Vec -->
        <section id="word2vec" class="section-card">
            <h2>⚡ Word2Vec：开创性的突破</h2>

            <div class="story-card">
                <span class="story-icon">🚀</span>
                <p><strong>2013年，改变游戏规则的算法</strong></p>
                <p class="mt-2">
                    在Word2Vec之前，训练词向量需要几周时间。Mikolov的新算法将这个时间缩短到几小时，而且效果更好！
                </p>
                <p class="mt-2">
                    秘诀是什么？他抛弃了复杂的语言模型，设计了两个极其简单但有效的任务：
                </p>
                <ul class="mt-2">
                    <li><strong>CBOW：</strong>看到"小猫 [?] 牛奶"，预测中间是"喝"</li>
                    <li><strong>Skip-gram：</strong>看到"喝"，预测周围是"小猫"和"牛奶"</li>
                </ul>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>为什么预测上下文的任务能学到语义？</li>
                    <li>CBOW和Skip-gram哪个更适合处理稀有词？为什么？</li>
                    <li>这种自监督学习的思想对后来的BERT有什么启发？</li>
                </ul>
            </div>

            <div class="flow-diagram">
                <h4 class="text-center mb-4" style="color: var(--primary-light);">🎯 Word2Vec的两种架构</h4>

                <div class="card-grid">
                    <div class="info-card">
                        <h4 class="text-center mb-3" style="color: var(--info);">CBOW（连续词袋）</h4>
                        <div class="text-center">
                            <svg width="300" height="200" viewBox="0 0 300 200">
                                <!-- 输入词 -->
                                <rect x="20" y="20" width="60" height="30" fill="#3b82f6" rx="5"/>
                                <text x="50" y="40" text-anchor="middle" fill="white" font-size="12">小猫</text>

                                <rect x="20" y="60" width="60" height="30" fill="#3b82f6" rx="5"/>
                                <text x="50" y="80" text-anchor="middle" fill="white" font-size="12">喜欢</text>

                                <rect x="20" y="100" width="60" height="30" fill="#3b82f6" rx="5"/>
                                <text x="50" y="120" text-anchor="middle" fill="white" font-size="12">[?]</text>

                                <rect x="20" y="140" width="60" height="30" fill="#3b82f6" rx="5"/>
                                <text x="50" y="160" text-anchor="middle" fill="white" font-size="12">牛奶</text>

                                <!-- 箭头 -->
                                <path d="M 80 35 L 120 85" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead)"/>
                                <path d="M 80 75 L 120 85" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead)"/>
                                <path d="M 80 155 L 120 85" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead)"/>

                                <!-- 隐藏层 -->
                                <circle cx="150" cy="85" r="30" fill="#8b5cf6"/>
                                <text x="150" y="90" text-anchor="middle" fill="white" font-size="12">平均</text>

                                <!-- 输出 -->
                                <path d="M 180 85 L 220 85" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead)"/>
                                <rect x="220" y="70" width="60" height="30" fill="#10b981" rx="5"/>
                                <text x="250" y="90" text-anchor="middle" fill="white" font-size="12">喝</text>

                                <!-- 箭头标记 -->
                                <defs>
                                    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                        <polygon points="0 0, 10 3.5, 0 7" fill="#64748b"/>
                                    </marker>
                                </defs>
                            </svg>
                        </div>
                        <p class="mt-3 text-center text-muted">
                            用上下文预测中心词<br>
                            适合：频繁词、小数据集
                        </p>
                    </div>

                    <div class="info-card">
                        <h4 class="text-center mb-3" style="color: var(--secondary);">Skip-gram</h4>
                        <div class="text-center">
                            <svg width="300" height="200" viewBox="0 0 300 200">
                                <!-- 输入词 -->
                                <rect x="20" y="70" width="60" height="30" fill="#ec4899" rx="5"/>
                                <text x="50" y="90" text-anchor="middle" fill="white" font-size="12">喝</text>

                                <!-- 隐藏层 -->
                                <circle cx="150" cy="85" r="30" fill="#8b5cf6"/>
                                <text x="150" y="90" text-anchor="middle" fill="white" font-size="12">投影</text>

                                <!-- 箭头 -->
                                <path d="M 80 85 L 120 85" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead2)"/>

                                <!-- 输出词 -->
                                <path d="M 180 85 L 220 35" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead2)"/>
                                <rect x="220" y="20" width="60" height="30" fill="#f59e0b" rx="5"/>
                                <text x="250" y="40" text-anchor="middle" fill="white" font-size="12">小猫</text>

                                <path d="M 180 85 L 220 75" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead2)"/>
                                <rect x="220" y="60" width="60" height="30" fill="#f59e0b" rx="5"/>
                                <text x="250" y="80" text-anchor="middle" fill="white" font-size="12">喜欢</text>

                                <path d="M 180 85 L 220 115" stroke="#64748b" stroke-width="2" marker-end="url(#arrowhead2)"/>
                                <rect x="220" y="100" width="60" height="30" fill="#f59e0b" rx="5"/>
                                <text x="250" y="120" text-anchor="middle" fill="white" font-size="12">牛奶</text>

                                <!-- 箭头标记 -->
                                <defs>
                                    <marker id="arrowhead2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                        <polygon points="0 0, 10 3.5, 0 7" fill="#64748b"/>
                                    </marker>
                                </defs>
                            </svg>
                        </div>
                        <p class="mt-3 text-center text-muted">
                            用中心词预测上下文<br>
                            适合：稀有词、大数据集
                        </p>
                    </div>
                </div>
            </div>

            <div class="math-display">
                <h4 class="mb-3" style="color: var(--primary-light);">Skip-gram的数学原理</h4>

                <p>给定中心词 $w_c$ 和上下文词 $w_o$，目标是最大化：</p>

                <p class="math-formula">
                    $P(w_o|w_c) = \frac{\exp(\vec{u}_o^T \vec{v}_c)}{\sum_{w \in V} \exp(\vec{u}_w^T \vec{v}_c)}$
                </p>

                <div class="formula-explanation">
                    <h5>📖 公式解读：如何计算一个词出现的概率？</h5>
                    <table class="formula-table">
                        <tr>
                            <td class="formula-part">$\vec{v}_c$</td>
                            <td class="formula-meaning">中心词的输入向量（如"喝"的向量）</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$\vec{u}_o$</td>
                            <td class="formula-meaning">上下文词的输出向量（如"牛奶"的向量）</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$\vec{u}_o^T \vec{v}_c$</td>
                            <td class="formula-meaning">两个向量的点积，越大表示越可能一起出现</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$\exp(...)$</td>
                            <td class="formula-meaning">指数函数，把点积转换为正数</td>
                        </tr>
                        <tr>
                            <td class="formula-part">分母</td>
                            <td class="formula-meaning">所有词的得分总和，用于归一化成概率</td>
                        </tr>
                    </table>

                    <div class="code-from-math">
                        <h6>💻 代码实现：</h6>
                        <pre style="color: #e6edf3; margin: 0;">
<span class="comment"># 假设已有中心词向量v_c和所有词的输出向量U</span>
scores = np.dot(U, v_c)          <span class="comment"># 计算所有词的得分</span>
exp_scores = np.exp(scores)      <span class="comment"># 转换为正数</span>
probabilities = exp_scores / np.sum(exp_scores)  <span class="comment"># 归一化</span></pre>
                    </div>

                    <p class="mt-3"><strong>💡 目标：</strong>让经常一起出现的词对有高概率，不常一起出现的词对有低概率。</p>
                </div>
            </div>

            <div class="demo-container mt-4">
                <h3 class="mb-3">🎓 从零理解：词向量是怎么训练出来的？</h3>

                <div class="training-example">
                    <h4>假设我们只有3个词：猫、喝、牛奶</h4>
                    <p>训练句子："猫喝牛奶"</p>

                    <div class="step-by-step">
                        <div class="training-step">
                            <h5>第1步：随机初始化词向量</h5>
                            <pre style="background: var(--bg-code); padding: 1rem; border-radius: 0.5rem;">
猫   = [0.2, -0.5]  <span class="comment"># 随机的2维向量</span>
喝   = [-0.1, 0.3]
牛奶 = [0.4, -0.2]</pre>
                        </div>

                        <div class="training-step mt-3">
                            <h5>第2步：用Skip-gram预测</h5>
                            <p>输入"喝"，预测周围应该出现什么词</p>
                            <pre style="background: var(--bg-code); padding: 1rem; border-radius: 0.5rem;">
<span class="comment"># 计算"喝"预测其他词的得分</span>
score(喝→猫) = 喝·猫 = (-0.1)×0.2 + 0.3×(-0.5) = -0.17
score(喝→牛奶) = 喝·牛奶 = (-0.1)×0.4 + 0.3×(-0.2) = -0.1

<span class="comment"># 转换成概率（softmax）</span>
P(猫|喝) = exp(-0.17) / (exp(-0.17) + exp(-0.1)) = 0.47
P(牛奶|喝) = exp(-0.1) / (exp(-0.17) + exp(-0.1)) = 0.53</pre>
                        </div>

                        <div class="training-step mt-3">
                            <h5>第3步：计算误差并更新</h5>
                            <p>实际上"猫"和"牛奶"都应该是100%（因为它们确实出现了）</p>
                            <pre style="background: var(--bg-code); padding: 1rem; border-radius: 0.5rem;">
<span class="comment"># 误差 = 实际 - 预测</span>
error(猫) = 1.0 - 0.47 = 0.53    <span class="comment"># 预测太低了</span>
error(牛奶) = 1.0 - 0.53 = 0.47  <span class="comment"># 预测太低了</span>

<span class="comment"># 更新向量（简化版）</span>
喝_new = 喝 + learning_rate × (error(猫)×猫 + error(牛奶)×牛奶)
猫_new = 猫 + learning_rate × error(猫)×喝
牛奶_new = 牛奶 + learning_rate × error(牛奶)×喝</pre>
                        </div>

                        <div class="training-step mt-3">
                            <h5>第4步：重复多次后...</h5>
                            <p>经过成千上万次这样的更新，词向量会调整到：</p>
                            <ul>
                                <li>经常一起出现的词（如"猫"和"牛奶"）向量会比较相似</li>
                                <li>很少一起出现的词向量会比较不同</li>
                                <li>最终形成一个合理的语义空间</li>
                            </ul>
                        </div>
                    </div>

                    <div class="tip success mt-3">
                        <span class="tip-icon">💡</span>
                        <strong>关键洞察</strong>
                        <p class="mt-2">
                            词向量不是人工设计的，而是通过预测任务自动学习出来的。模型通过不断调整向量，让经常一起出现的词有相似的向量，从而捕获了语义信息。
                        </p>
                    </div>
                </div>
            </div>

            <div class="code-block mt-4">
                <div class="code-header">
                    <span class="code-lang">Python - 简化版Skip-gram实现</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content collapsed">
                    <pre><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn
<span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim

<span class="keyword">class</span> <span class="function">SkipGram</span>(nn.Module):
    <span class="string">"""Skip-gram模型"""</span>

    <span class="keyword">def</span> <span class="function">__init__</span>(self, vocab_size, embedding_dim):
        <span class="keyword">super</span>(SkipGram, self).__init__()

        <span class="comment"># 词嵌入层（这就是我们要的词向量！）</span>
        self.embeddings = nn.Embedding(vocab_size, embedding_dim)

        <span class="comment"># 输出层（预测上下文）</span>
        self.output_layer = nn.Linear(embedding_dim, vocab_size)

        <span class="comment"># 初始化权重</span>
        self.embeddings.weight.data.uniform_(-<span class="number">0.5</span>, <span class="number">0.5</span>)
        self.output_layer.weight.data.uniform_(-<span class="number">0.5</span>, <span class="number">0.5</span>)

    <span class="keyword">def</span> <span class="function">forward</span>(self, center_word):
        <span class="string">"""前向传播"""</span>
        <span class="comment"># 获取中心词的词向量</span>
        center_embedding = self.embeddings(center_word)

        <span class="comment"># 预测上下文词的概率分布</span>
        output = self.output_layer(center_embedding)
        log_probs = torch.log_softmax(output, dim=<span class="number">1</span>)

        <span class="keyword">return</span> log_probs

    <span class="keyword">def</span> <span class="function">get_word_vector</span>(self, word_idx):
        <span class="string">"""获取词向量"""</span>
        <span class="keyword">return</span> self.embeddings.weight[word_idx].detach().numpy()

<span class="comment"># 训练示例</span>
<span class="keyword">def</span> <span class="function">train_word2vec</span>(sentences, vocab_size, embedding_dim=<span class="number">100</span>,
                     window_size=<span class="number">2</span>, epochs=<span class="number">10</span>):
    <span class="string">"""训练Word2Vec模型"""</span>
    model = SkipGram(vocab_size, embedding_dim)
    optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)

    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):
        total_loss = <span class="number">0</span>

        <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:
            <span class="comment"># 对每个句子生成训练样本</span>
            <span class="keyword">for</span> center_pos <span class="keyword">in</span> range(len(sentence)):
                center_word = sentence[center_pos]

                <span class="comment"># 获取上下文词</span>
                context_words = []
                <span class="keyword">for</span> offset <span class="keyword">in</span> range(-window_size, window_size + <span class="number">1</span>):
                    <span class="keyword">if</span> offset != <span class="number">0</span>:
                        context_pos = center_pos + offset
                        <span class="keyword">if</span> <span class="number">0</span> <= context_pos < len(sentence):
                            context_words.append(sentence[context_pos])

                <span class="keyword">if</span> context_words:
                    <span class="comment"># 前向传播</span>
                    log_probs = model(torch.tensor([center_word]))

                    <span class="comment"># 计算损失（负对数似然）</span>
                    loss = <span class="number">0</span>
                    <span class="keyword">for</span> context_word <span class="keyword">in</span> context_words:
                        loss -= log_probs[<span class="number">0</span>, context_word]
                    loss /= len(context_words)

                    <span class="comment"># 反向传播</span>
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()

        <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:
            print(<span class="string">f"Epoch {epoch}, Loss: {total_loss:.4f}"</span>)

    <span class="keyword">return</span> model

<span class="comment"># 使用gensim训练中文Word2Vec</span>
<span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec

sentences = [
    [<span class="string">'小猫'</span>, <span class="string">'喜欢'</span>, <span class="string">'喝'</span>, <span class="string">'牛奶'</span>],
    [<span class="string">'小狗'</span>, <span class="string">'喜欢'</span>, <span class="string">'吃'</span>, <span class="string">'骨头'</span>],
    [<span class="string">'小猫'</span>, <span class="string">'和'</span>, <span class="string">'小狗'</span>, <span class="string">'都是'</span>, <span class="string">'宠物'</span>],
    [<span class="string">'牛奶'</span>, <span class="string">'是'</span>, <span class="string">'白色'</span>, <span class="string">'的'</span>],
    [<span class="string">'骨头'</span>, <span class="string">'很'</span>, <span class="string">'硬'</span>]
]

<span class="comment"># 训练模型</span>
w2v_model = Word2Vec(sentences, vector_size=<span class="number">100</span>, window=<span class="number">2</span>,
                     min_count=<span class="number">1</span>, sg=<span class="number">1</span>)  <span class="comment"># sg=1表示Skip-gram</span>

<span class="comment"># 获取词向量</span>
cat_vector = w2v_model.wv[<span class="string">'小猫'</span>]
dog_vector = w2v_model.wv[<span class="string">'小狗'</span>]

<span class="comment"># 计算相似度</span>
similarity = w2v_model.wv.similarity(<span class="string">'小猫'</span>, <span class="string">'小狗'</span>)
print(<span class="string">f"'小猫'和'小狗'的相似度: {similarity:.3f}"</span>)

<span class="comment"># 找最相似的词</span>
similar_words = w2v_model.wv.most_similar(<span class="string">'小猫'</span>, topn=<span class="number">3</span>)
print(<span class="string">f"与'小猫'最相似的词: {similar_words}"</span>)</pre>
                </div>
            </div>

            <div class="tip success mt-4">
                <span class="tip-icon">💡</span>
                <strong>Word2Vec的关键创新</strong>
                <ul class="mt-2">
                    <li><strong>简单高效：</strong>只需要预测上下文，不需要复杂的语言模型</li>
                    <li><strong>负采样：</strong>不计算所有词的概率，只采样少量负例</li>
                    <li><strong>层次softmax：</strong>用二叉树加速大词表的计算</li>
                    <li><strong>子采样：</strong>降低高频词（如"的"、"是"）的权重</li>
                </ul>
            </div>
        </section>

        <!-- 词向量可视化 -->
        <section id="visualization" class="section-card">
            <h2>📊 词向量可视化：看见语义空间</h2>

            <div class="story-card">
                <span class="story-icon">🔭</span>
                <p><strong>语义的星空</strong></p>
                <p class="mt-2">
                    如果把每个词向量想象成夜空中的一颗星星，相似的词就像星座一样聚集在一起。让我们用降维技术把这个高维空间投影到2D平面上。
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>为什么需要把300维的向量降到2维？损失了什么信息？</li>
                    <li>t-SNE和PCA降维有什么区别？各自适合什么场景？</li>
                    <li>在词向量空间中，反义词是相近还是相远？为什么？</li>
                </ul>
            </div>

            <div class="demo-container">
                <h3 class="mb-3">词向量降维可视化</h3>

                <div class="word-cloud" id="word-embedding-viz">
                    <!-- 动态生成的词云 -->
                </div>

                <div class="mt-3 text-center">
                    <button class="btn btn-primary" onclick="updateWordCloud('animals')">动物世界</button>
                    <button class="btn btn-secondary" onclick="updateWordCloud('food')">美食天地</button>
                    <button class="btn btn-secondary" onclick="updateWordCloud('tech')">科技前沿</button>
                    <button class="btn btn-secondary" onclick="updateWordCloud('emotion')">情感表达</button>
                </div>
            </div>

            <div class="code-block mt-4">
                <div class="code-header">
                    <span class="code-lang">Python - t-SNE可视化词向量</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content collapsed">
                    <pre><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt
<span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE
<span class="keyword">import</span> seaborn <span class="keyword">as</span> sns
<span class="comment"># 设置中文字体</span>
plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]
plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="keyword">False</span>

<span class="keyword">def</span> <span class="function">visualize_word_vectors</span>(word_vectors, words, categories=None):
    <span class="string">"""使用t-SNE可视化词向量"""</span>

    <span class="comment"># 1. 降维到2D</span>
    tsne = TSNE(n_components=<span class="number">2</span>, random_state=<span class="number">42</span>,
                perplexity=<span class="number">30</span>, n_iter=<span class="number">1000</span>)
    embeddings_2d = tsne.fit_transform(word_vectors)

    <span class="comment"># 2. 创建图表</span>
    plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))

    <span class="comment"># 3. 如果有类别，用不同颜色</span>
    <span class="keyword">if</span> categories:
        unique_categories = list(set(categories))
        colors = sns.color_palette(<span class="string">"husl"</span>, len(unique_categories))

        <span class="keyword">for</span> i, category <span class="keyword">in</span> enumerate(unique_categories):
            mask = [c == category <span class="keyword">for</span> c <span class="keyword">in</span> categories]
            points = embeddings_2d[mask]
            plt.scatter(points[:, <span class="number">0</span>], points[:, <span class="number">1</span>],
                       c=[colors[i]], label=category, s=<span class="number">100</span>, alpha=<span class="number">0.7</span>)
    <span class="keyword">else</span>:
        plt.scatter(embeddings_2d[:, <span class="number">0</span>], embeddings_2d[:, <span class="number">1</span>],
                   s=<span class="number">100</span>, alpha=<span class="number">0.7</span>)

    <span class="comment"># 4. 添加词标签</span>
    <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(words):
        plt.annotate(word,
                    xy=(embeddings_2d[i, <span class="number">0</span>], embeddings_2d[i, <span class="number">1</span>]),
                    xytext=(<span class="number">5</span>, <span class="number">2</span>),
                    textcoords=<span class="string">'offset points'</span>,
                    fontsize=<span class="number">12</span>)

    plt.title(<span class="string">'词向量可视化 (t-SNE)'</span>, fontsize=<span class="number">16</span>)
    plt.xlabel(<span class="string">'维度 1'</span>)
    plt.ylabel(<span class="string">'维度 2'</span>)
    plt.legend()
    plt.grid(<span class="keyword">True</span>, alpha=<span class="number">0.3</span>)
    plt.tight_layout()
    plt.show()

<span class="comment"># 示例：可视化不同类别的词</span>
words = [
    <span class="comment"># 动物</span>
    <span class="string">'小猫'</span>, <span class="string">'小狗'</span>, <span class="string">'兔子'</span>, <span class="string">'老虎'</span>, <span class="string">'狮子'</span>,
    <span class="comment"># 食物</span>
    <span class="string">'苹果'</span>, <span class="string">'香蕉'</span>, <span class="string">'米饭'</span>, <span class="string">'面包'</span>, <span class="string">'牛奶'</span>,
    <span class="comment"># 交通工具</span>
    <span class="string">'汽车'</span>, <span class="string">'自行车'</span>, <span class="string">'飞机'</span>, <span class="string">'火车'</span>, <span class="string">'轮船'</span>,
    <span class="comment"># 情感</span>
    <span class="string">'快乐'</span>, <span class="string">'悲伤'</span>, <span class="string">'愤怒'</span>, <span class="string">'恐惧'</span>, <span class="string">'惊喜'</span>
]

categories = [
    <span class="string">'动物'</span>, <span class="string">'动物'</span>, <span class="string">'动物'</span>, <span class="string">'动物'</span>, <span class="string">'动物'</span>,
    <span class="string">'食物'</span>, <span class="string">'食物'</span>, <span class="string">'食物'</span>, <span class="string">'食物'</span>, <span class="string">'食物'</span>,
    <span class="string">'交通'</span>, <span class="string">'交通'</span>, <span class="string">'交通'</span>, <span class="string">'交通'</span>, <span class="string">'交通'</span>,
    <span class="string">'情感'</span>, <span class="string">'情感'</span>, <span class="string">'情感'</span>, <span class="string">'情感'</span>, <span class="string">'情感'</span>
]

<span class="comment"># 分析词向量的性质</span>
<span class="keyword">def</span> <span class="function">analyze_word_vectors</span>(model):
    <span class="string">"""分析词向量的有趣性质"""</span>

    print(<span class="string">"=== 词向量算术 ==="</span>)

    <span class="comment"># 类比关系</span>
    result = model.wv.most_similar(
        positive=[<span class="string">'北京'</span>, <span class="string">'日本'</span>],
        negative=[<span class="string">'中国'</span>],
        topn=<span class="number">3</span>
    )
    print(<span class="string">"北京 - 中国 + 日本 ="</span>, result)

    <span class="comment"># 找不属于同类的词</span>
    outlier = model.wv.doesnt_match([<span class="string">'早餐'</span>, <span class="string">'午餐'</span>, <span class="string">'晚餐'</span>, <span class="string">'汽车'</span>])
    print(<span class="string">f"\n不属于同类的词: {outlier}"</span>)

    <span class="comment"># 探索有趣的语义关系</span>
    print(<span class="string">"\n=== 有趣的语义关系 ==="</span>)

    <span class="comment"># 反义词往往也很相似（因为出现在相似上下文）</span>
    sim = model.wv.similarity(<span class="string">'热'</span>, <span class="string">'冷'</span>)
    print(<span class="string">f"'热'和'冷'的相似度: {sim:.3f}"</span>)

    <span class="comment"># 同义词相似度更高</span>
    sim = model.wv.similarity(<span class="string">'美丽'</span>, <span class="string">'漂亮'</span>)
    print(<span class="string">f"'美丽'和'漂亮'的相似度: {sim:.3f}"</span>)</pre>
                </div>
            </div>

            <div class="heatmap">
                <h4 class="text-center mb-3" style="color: var(--primary-light);">词向量相似度热力图</h4>
                <div class="heatmap-grid">
                    <div class="heatmap-row">
                        <div class="heatmap-cell heatmap-label"></div>
                        <div class="heatmap-cell heatmap-label">小猫</div>
                        <div class="heatmap-cell heatmap-label">小狗</div>
                        <div class="heatmap-cell heatmap-label">汽车</div>
                        <div class="heatmap-cell heatmap-label">飞机</div>
                    </div>
                    <div class="heatmap-row">
                        <div class="heatmap-cell heatmap-label">小猫</div>
                        <div class="heatmap-cell" style="background: #10b981;">1.00</div>
                        <div class="heatmap-cell" style="background: #22c55e;">0.85</div>
                        <div class="heatmap-cell" style="background: #475569;">0.12</div>
                        <div class="heatmap-cell" style="background: #475569;">0.08</div>
                    </div>
                    <div class="heatmap-row">
                        <div class="heatmap-cell heatmap-label">小狗</div>
                        <div class="heatmap-cell" style="background: #22c55e;">0.85</div>
                        <div class="heatmap-cell" style="background: #10b981;">1.00</div>
                        <div class="heatmap-cell" style="background: #475569;">0.15</div>
                        <div class="heatmap-cell" style="background: #475569;">0.11</div>
                    </div>
                    <div class="heatmap-row">
                        <div class="heatmap-cell heatmap-label">汽车</div>
                        <div class="heatmap-cell" style="background: #475569;">0.12</div>
                        <div class="heatmap-cell" style="background: #475569;">0.15</div>
                        <div class="heatmap-cell" style="background: #10b981;">1.00</div>
                        <div class="heatmap-cell" style="background: #22c55e;">0.82</div>
                    </div>
                    <div class="heatmap-row">
                        <div class="heatmap-cell heatmap-label">飞机</div>
                        <div class="heatmap-cell" style="background: #475569;">0.08</div>
                        <div class="heatmap-cell" style="background: #475569;">0.11</div>
                        <div class="heatmap-cell" style="background: #22c55e;">0.82</div>
                        <div class="heatmap-cell" style="background: #10b981;">1.00</div>
                    </div>
                </div>
                <p class="text-center mt-3 text-muted">
                    词向量捕获了语义相似性：同类词聚集在一起
                </p>
            </div>
        </section>

        <!-- GloVe -->
        <section id="glove" class="section-card">
            <h2>🌍 GloVe：全局视角的词向量</h2>

            <div class="story-card">
                <span class="story-icon">🔬</span>
                <p><strong>斯坦福的新思路</strong></p>
                <p class="mt-2">
                    2014年，斯坦福的研究者提出了一个问题："Word2Vec只看局部上下文，会不会错过了全局的统计信息？"
                </p>
                <p class="mt-2">
                    他们设计了GloVe（Global Vectors），结合了两个世界的优点：
                </p>
                <ul class="mt-2">
                    <li>像Word2Vec一样学习词向量</li>
                    <li>像传统方法一样利用全局共现统计</li>
                </ul>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>为什么说共现次数的比值比绝对次数更有意义？</li>
                    <li>GloVe的目标函数为什么要用对数？</li>
                    <li>全局方法和局部方法各有什么优劣？</li>
                </ul>
            </div>

            <div class="math-display">
                <h4 class="mb-3" style="color: var(--primary-light);">GloVe的核心思想</h4>

                <p>关键观察：词向量的内积应该等于它们共现概率的对数</p>

                <div class="math-formula mt-3" style="font-size: 1.5rem;">
                    $w_i^T \tilde{w}_j + b_i + \tilde{b}_j = \log(X_{ij})$
                </div>

                <div class="formula-explanation">
                    <h5>📖 公式解读：为什么这样设计？</h5>
                    <table class="formula-table">
                        <tr>
                            <td class="formula-part">$w_i, \tilde{w}_j$</td>
                            <td class="formula-meaning">词i和词j的向量（每个词有两个向量）</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$w_i^T \tilde{w}_j$</td>
                            <td class="formula-meaning">两个词向量的点积</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$b_i, \tilde{b}_j$</td>
                            <td class="formula-meaning">偏置项，调整每个词的基础频率</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$X_{ij}$</td>
                            <td class="formula-meaning">词i和词j在语料库中共同出现的次数</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$\log(X_{ij})$</td>
                            <td class="formula-meaning">取对数，让频率差异不那么极端</td>
                        </tr>
                    </table>

                    <p class="mt-3"><strong>💡 直观理解：</strong></p>
                    <ul>
                        <li>如果两个词经常一起出现（$X_{ij}$大），它们的向量点积应该大</li>
                        <li>如果两个词很少一起出现（$X_{ij}$小），它们的向量点积应该小</li>
                        <li>用对数是因为词频分布通常很不均匀（有些词对出现上万次，有些只有几次）</li>
                    </ul>
                </div>

                <p class="mt-4">损失函数：</p>
                <div class="math-formula">
                    $J = \sum_{i,j=1}^V f(X_{ij})(w_i^T \tilde{w}_j + b_i + \tilde{b}_j - \log X_{ij})^2$
                </div>

                <div class="formula-explanation">
                    <h5>📖 损失函数解读：</h5>
                    <table class="formula-table">
                        <tr>
                            <td class="formula-part">$(...)^2$</td>
                            <td class="formula-meaning">平方误差，让预测值尽量接近真实值</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$f(X_{ij})$</td>
                            <td class="formula-meaning">权重函数，给高频词对更大权重</td>
                        </tr>
                        <tr>
                            <td class="formula-part">$\sum_{i,j=1}^V$</td>
                            <td class="formula-meaning">对所有词对求和</td>
                        </tr>
                    </table>

                    <div class="code-from-math">
                        <h6>💻 训练代码示例：</h6>
                        <pre style="color: #e6edf3; margin: 0;">
<span class="comment"># 对于每个词对(i,j)</span>
<span class="keyword">for</span> i, j <span class="keyword">in</span> word_pairs:
    <span class="comment"># 计算当前预测值</span>
    prediction = np.dot(W[i], W_tilde[j]) + b[i] + b_tilde[j]

    <span class="comment"># 真实值是共现次数的对数</span>
    target = np.log(X[i,j])

    <span class="comment"># 计算误差</span>
    error = prediction - target

    <span class="comment"># 梯度下降更新向量</span>
    W[i] -= learning_rate * error * W_tilde[j] * f(X[i,j])
    W_tilde[j] -= learning_rate * error * W[i] * f(X[i,j])</pre>
                    </div>
                </div>
            </div>

            <div class="tip info mt-4">
                <span class="tip-icon">🎯</span>
                <strong>GloVe vs Word2Vec</strong>
                <div class="comparison-table mt-3">
                    <table>
                        <thead>
                        <tr>
                            <th>特性</th>
                            <th>Word2Vec</th>
                            <th>GloVe</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td>训练方式</td>
                            <td>预测任务（局部）</td>
                            <td>矩阵分解（全局）</td>
                        </tr>
                        <tr>
                            <td>计算效率</td>
                            <td>在线学习，内存友好</td>
                            <td>需要构建共现矩阵</td>
                        </tr>
                        <tr>
                            <td>性能表现</td>
                            <td>在相似度任务上较好</td>
                            <td>在类比任务上较好</td>
                        </tr>
                        <tr>
                            <td>可解释性</td>
                            <td>黑盒模型</td>
                            <td>有明确的数学目标</td>
                        </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </section>

        <!-- FastText -->
        <section id="fasttext" class="section-card">
            <h2>⚡ FastText：子词的力量</h2>

            <div class="story-card">
                <span class="story-icon">🔤</span>
                <p><strong>Facebook的创新：不再忽视词的内部结构</strong></p>
                <p class="mt-2">
                    传统词向量把每个词当作原子，但Facebook的研究者意识到这忽略了重要信息：
                </p>
                <ul class="mt-2">
                    <li>"不开心"和"开心"明显有关系（共享"开心"）</li>
                    <li>"老师"和"教师"也该相似（都有"师"）</li>
                    <li>新词"元宇宙"完全没见过怎么办？</li>
                </ul>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>中文的字符级n-gram和英文的有什么不同？</li>
                    <li>为什么FastText特别适合处理中文？</li>
                    <li>子词建模对于处理网络新词有什么优势？</li>
                </ul>
            </div>

            <div class="demo-container">
                <h3 class="mb-3">FastText的子词分解</h3>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-lang">子词拆分示例</span>
                    </div>
                    <div class="code-content">
                        <pre>中文示例：
原词：自然语言处理

字符n-gram（n=2）：
<自, 自然, 然语, 语言, 言处, 处理, 理>

字符n-gram（n=3）：
<自然, 自然语, 然语言, 语言处, 言处理, 处理>

英文示例：
原词：teaching

字符n-gram（n=3）：
<te, tea, eac, ach, chi, hin, ing, ng>

最终词向量 = 平均(所有子词向量)</pre>
                    </div>
                </div>

                <div class="tip success mt-3">
                    <span class="tip-icon">✨</span>
                    <strong>FastText的优势</strong>
                    <ul class="mt-2">
                        <li><strong>处理未登录词：</strong>即使没见过"元宇宙"，也能通过子词组合得到向量</li>
                        <li><strong>形态学信息：</strong>相同词根的词自然相似</li>
                        <li><strong>拼写错误鲁棒：</strong>"自然语言"和"自然语言"会有相似的向量</li>
                        <li><strong>多语言友好：</strong>特别适合中文等表意文字</li>
                    </ul>
                </div>
            </div>

            <div class="code-block mt-4">
                <div class="code-header">
                    <span class="code-lang">Python - 使用FastText</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content collapsed">
                    <pre><span class="keyword">from</span> gensim.models <span class="keyword">import</span> FastText
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="comment"># 训练FastText模型</span>
sentences = [
    [<span class="string">'我'</span>, <span class="string">'爱'</span>, <span class="string">'自然语言处理'</span>],
    [<span class="string">'机器学习'</span>, <span class="string">'很'</span>, <span class="string">'有趣'</span>],
    [<span class="string">'深度学习'</span>, <span class="string">'改变'</span>, <span class="string">'世界'</span>],
    [<span class="string">'人工智能'</span>, <span class="string">'是'</span>, <span class="string">'未来'</span>]
]

<span class="comment"># 创建FastText模型</span>
model = FastText(
    sentences,
    vector_size=<span class="number">100</span>,      <span class="comment"># 词向量维度</span>
    window=<span class="number">5</span>,            <span class="comment"># 上下文窗口</span>
    min_count=<span class="number">1</span>,         <span class="comment"># 最小词频</span>
    min_n=<span class="number">2</span>,             <span class="comment"># 最小n-gram</span>
    max_n=<span class="number">5</span>,             <span class="comment"># 最大n-gram</span>
    sg=<span class="number">1</span>,                <span class="comment"># Skip-gram</span>
    epochs=<span class="number">100</span>
)

<span class="comment"># 测试未登录词（OOV）</span>
<span class="keyword">def</span> <span class="function">test_oov_words</span>(model):
    <span class="string">"""测试FastText处理未见过的词"""</span>

    oov_words = [
        <span class="string">'深度学习算法'</span>,    <span class="comment"># 组合已知词</span>
        <span class="string">'超级人工智能'</span>,    <span class="comment"># 新组合</span>
        <span class="string">'元宇宙'</span>,         <span class="comment"># 流行新词</span>
        <span class="string">'区块链技术'</span>,      <span class="comment"># 专业术语</span>
    ]

    print(<span class="string">"=== 未登录词测试 ==="</span>)
    <span class="keyword">for</span> word <span class="keyword">in</span> oov_words:
        <span class="keyword">try</span>:
            <span class="comment"># FastText可以为任何词生成向量</span>
            vector = model.wv[word]
            print(<span class="string">f"{word}: 成功生成向量"</span>)

            <span class="comment"># 找相似词</span>
            similar = model.wv.most_similar(word, topn=<span class="number">3</span>)
            print(<span class="string">f"  相似词: {[w[0] for w in similar]}"</span>)
        <span class="keyword">except</span> KeyError:
            print(<span class="string">f"{word}: 无法生成向量（这在FastText中不应该发生）"</span>)

test_oov_words(model)

<span class="comment"># 分析子词的贡献</span>
<span class="keyword">def</span> <span class="function">analyze_subwords</span>(model, word):
    <span class="string">"""分析子词对最终词向量的贡献"""</span>

    <span class="comment"># 获取所有子词</span>
    subwords = []
    word_bounded = <span class="string">f"<{word}>"</span>

    <span class="keyword">for</span> n <span class="keyword">in</span> range(model.wv.min_n, min(len(word_bounded), model.wv.max_n + <span class="number">1</span>)):
        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(word_bounded) - n + <span class="number">1</span>):
            subwords.append(word_bounded[i:i+n])

    print(<span class="string">f"\n'{word}'的子词: {subwords[:10]}..."</span>)  <span class="comment"># 只显示前10个</span>

<span class="comment"># 对比Word2Vec和FastText</span>
<span class="keyword">def</span> <span class="function">compare_models</span>():
    <span class="string">"""对比两种模型的特点"""</span>

    <span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec

    <span class="comment"># 相同的训练数据</span>
    sentences_large = sentences * <span class="number">100</span>  <span class="comment"># 重复数据以便训练</span>

    <span class="comment"># 训练Word2Vec</span>
    w2v_model = Word2Vec(sentences_large, vector_size=<span class="number">100</span>,
                         window=<span class="number">5</span>, min_count=<span class="number">1</span>, sg=<span class="number">1</span>)

    <span class="comment"># 训练FastText</span>
    ft_model = FastText(sentences_large, vector_size=<span class="number">100</span>,
                        window=<span class="number">5</span>, min_count=<span class="number">1</span>, sg=<span class="number">1</span>)

    <span class="comment"># 测试OOV词</span>
    test_word = <span class="string">'超级深度学习'</span>

    print(<span class="string">"\n=== 模型对比 ==="</span>)

    <span class="comment"># Word2Vec</span>
    <span class="keyword">try</span>:
        w2v_vector = w2v_model.wv[test_word]
        print(<span class="string">f"Word2Vec: '{test_word}'有向量"</span>)
    <span class="keyword">except</span> KeyError:
        print(<span class="string">f"Word2Vec: '{test_word}'是OOV词，无法处理"</span>)

    <span class="comment"># FastText</span>
    <span class="keyword">try</span>:
        ft_vector = ft_model.wv[test_word]
        print(<span class="string">f"FastText: '{test_word}'成功生成向量"</span>)
        similar = ft_model.wv.most_similar(test_word, topn=<span class="number">3</span>)
        print(<span class="string">f"  相似词: {[w[0] for w in similar]}"</span>)
    <span class="keyword">except</span> KeyError:
        print(<span class="string">f"FastText: 出错（不应该发生）"</span>)

compare_models()</pre>
                </div>
            </div>
        </section>

        <!-- 上下文词向量 -->
        <section id="contextual" class="section-card">
            <h2>🎭 上下文词向量：一词多义的解决方案</h2>

            <div class="story-card">
                <span class="story-icon">🎪</span>
                <p><strong>词的变色龙特性</strong></p>
                <p class="mt-2">
                    考虑"苹果"这个词：
                </p>
                <ul class="mt-2">
                    <li>"我买了一个<strong>苹果</strong>吃" → 水果</li>
                    <li>"我买了一台<strong>苹果</strong>电脑" → 公司/品牌</li>
                </ul>
                <p class="mt-2">
                    传统词向量给"苹果"一个固定的向量，无法区分这两种含义。这就像一个演员只能演一个角色。
                </p>
                <p class="mt-3 text-center" style="color: var(--warning); font-size: 1.1rem;">
                    💡 2018年，BERT横空出世，让每个词都能根据上下文"变身"！
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>还有哪些中文词有多个含义？比如"打"有多少种用法？</li>
                    <li>为什么说上下文词向量是"动态"的？</li>
                    <li>BERT是如何做到理解上下文的？</li>
                </ul>
            </div>

            <div class="demo-container">
                <h3 class="mb-3">静态 vs 动态词向量</h3>

                <div class="card-grid">
                    <div class="info-card">
                        <h4 style="color: var(--danger);">静态词向量（Word2Vec）</h4>
                        <div class="vector-display">
                            <span class="vector-label">"苹果"：</span>
                            <div class="vector-values">
                                <span class="vector-value">0.32</span>
                                <span class="vector-value">-0.21</span>
                                <span class="vector-value">0.18</span>
                                <span class="vector-value">...</span>
                            </div>
                        </div>
                        <p class="mt-3 text-center" style="color: var(--text-muted);">
                            永远是同一个向量，混合了所有含义
                        </p>
                    </div>

                    <div class="info-card">
                        <h4 style="color: var(--success);">动态词向量（BERT）</h4>
                        <div class="vector-display">
                            <span class="vector-label">"苹果"(水果)：</span>
                            <div class="vector-values">
                                <span class="vector-value">0.15</span>
                                <span class="vector-value">0.82</span>
                                <span class="vector-value">-0.33</span>
                                <span class="vector-value">...</span>
                            </div>
                        </div>
                        <div class="vector-display mt-2">
                            <span class="vector-label">"苹果"(公司)：</span>
                            <div class="vector-values">
                                <span class="vector-value">0.78</span>
                                <span class="vector-value">-0.45</span>
                                <span class="vector-value">0.21</span>
                                <span class="vector-value">...</span>
                            </div>
                        </div>
                        <p class="mt-3 text-center" style="color: var(--text-muted);">
                            根据上下文生成不同的向量
                        </p>
                    </div>
                </div>
            </div>

            <div class="tip info mt-4">
                <span class="tip-icon">🔄</span>
                <strong>从静态到动态的演进</strong>
                <ul class="mt-2">
                    <li><strong>2013-2017：</strong>Word2Vec、GloVe、FastText（静态）</li>
                    <li><strong>2018：</strong>ELMo（首个动态词向量）</li>
                    <li><strong>2018：</strong>BERT（双向上下文）</li>
                    <li><strong>2019-至今：</strong>GPT、RoBERTa、ALBERT等</li>
                </ul>
                <p class="mt-2">
                    现代NLP几乎都使用上下文词向量，但静态词向量在某些场景仍有价值（速度快、内存小）。
                </p>
            </div>
        </section>

        <!-- 相似度计算 -->
        <section id="similarity" class="section-card">
            <h2>📏 相似度计算：度量语义距离</h2>

            <div class="story-card">
                <span class="story-icon">📐</span>
                <p><strong>语义空间中的几何学</strong></p>
                <p class="mt-2">
                    在词向量空间中，语义相似度变成了几何距离。就像在地图上测量两个城市的距离，我们可以测量两个词的"语义距离"。
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>为什么余弦相似度比欧氏距离更常用于词向量？</li>
                    <li>两个词的余弦相似度为负数意味着什么？</li>
                    <li>相似度高的词一定是同义词吗？</li>
                </ul>
            </div>

            <div class="algorithm-steps">
                <h4 class="mb-4" style="color: var(--primary-light);">🎯 常用的相似度度量方法</h4>

                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>余弦相似度（最常用）</h5>
                        <p>测量两个向量的夹角，忽略长度差异</p>
                        <div class="math-display mt-3">
                            <p class="math-formula">
                                $\cos(\vec{a}, \vec{b}) = \frac{\vec{a} \cdot \vec{b}}{||\vec{a}|| \times ||\vec{b}||} = \frac{\sum_{i=1}^n a_i b_i}{\sqrt{\sum_{i=1}^n a_i^2} \times \sqrt{\sum_{i=1}^n b_i^2}}$
                            </p>
                            <p class="mt-2">
                                取值范围：[-1, 1]<br>
                                1表示完全相同，0表示正交（无关），-1表示完全相反
                            </p>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>欧氏距离</h5>
                        <p>直线距离，考虑向量的长度</p>
                        <div class="math-display mt-3">
                            <p class="math-formula">
                                $d(\vec{a}, \vec{b}) = ||\vec{a} - \vec{b}||_2 = \sqrt{\sum_{i=1}^n (a_i - b_i)^2}$
                            </p>
                            <p class="mt-2">
                                取值范围：[0, +∞)<br>
                                0表示完全相同，值越大差异越大
                            </p>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>点积（内积）</h5>
                        <p>同时考虑方向和长度</p>
                        <div class="math-display mt-3">
                            <p class="math-formula">
                                $\vec{a} \cdot \vec{b} = \sum_{i=1}^n a_i b_i = ||\vec{a}|| \times ||\vec{b}|| \times \cos\theta$
                            </p>
                            <p class="mt-2">
                                常用于注意力机制和信息检索
                            </p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="code-block mt-4">
                <div class="code-header">
                    <span class="code-lang">Python - 相似度计算实战</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content collapsed">
                    <pre><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine, euclidean
<span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity
<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt

<span class="keyword">class</span> <span class="function">SimilarityCalculator</span>:
    <span class="string">"""词向量相似度计算器"""</span>

    @staticmethod
    <span class="keyword">def</span> <span class="function">cosine_sim</span>(vec1, vec2):
        <span class="string">"""余弦相似度"""</span>
        <span class="keyword">return</span> np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

    @staticmethod
    <span class="keyword">def</span> <span class="function">euclidean_dist</span>(vec1, vec2):
        <span class="string">"""欧氏距离"""</span>
        <span class="keyword">return</span> np.linalg.norm(vec1 - vec2)

    @staticmethod
    <span class="keyword">def</span> <span class="function">manhattan_dist</span>(vec1, vec2):
        <span class="string">"""曼哈顿距离"""</span>
        <span class="keyword">return</span> np.sum(np.abs(vec1 - vec2))

    @staticmethod
    <span class="keyword">def</span> <span class="function">dot_product</span>(vec1, vec2):
        <span class="string">"""点积"""</span>
        <span class="keyword">return</span> np.dot(vec1, vec2)

<span class="comment"># 实验：不同相似度度量的特性</span>
<span class="keyword">def</span> <span class="function">compare_similarity_metrics</span>():
    <span class="string">"""比较不同相似度度量的特性"""</span>

    <span class="comment"># 创建测试向量</span>
    vec_a = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])
    vec_b = np.array([<span class="number">0.8</span>, <span class="number">0.6</span>, <span class="number">0</span>])  <span class="comment"># 与A相似</span>
    vec_c = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])      <span class="comment"># 与A正交</span>
    vec_d = np.array([<span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>])     <span class="comment"># 与A相反</span>
    vec_e = np.array([<span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>])      <span class="comment"># 与A同向但长度不同</span>

    vectors = {
        <span class="string">'A'</span>: vec_a,
        <span class="string">'B(相似)'</span>: vec_b,
        <span class="string">'C(正交)'</span>: vec_c,
        <span class="string">'D(相反)'</span>: vec_d,
        <span class="string">'E(同向×2)'</span>: vec_e
    }

    calc = SimilarityCalculator()

    print(<span class="string">"=== 相似度度量对比 ==="</span>)
    print(<span class="string">f"基准向量 A: {vec_a}"</span>)
    print(<span class="string">"\n与其他向量的相似度/距离："</span>)

    <span class="keyword">for</span> name, vec <span class="keyword">in</span> vectors.items():
        <span class="keyword">if</span> name == <span class="string">'A'</span>:
            <span class="keyword">continue</span>

        cos_sim = calc.cosine_sim(vec_a, vec)
        euc_dist = calc.euclidean_dist(vec_a, vec)
        dot_prod = calc.dot_product(vec_a, vec)

        print(<span class="string">f"\n{name}: {vec}"</span>)
        print(<span class="string">f"  余弦相似度: {cos_sim:.3f}"</span>)
        print(<span class="string">f"  欧氏距离: {euc_dist:.3f}"</span>)
        print(<span class="string">f"  点积: {dot_prod:.3f}"</span>)

<span class="comment"># 可视化相似度</span>
<span class="keyword">def</span> <span class="function">visualize_similarity</span>(word_vectors, words):
    <span class="string">"""可视化词向量相似度矩阵"""</span>

    n = len(words)
    similarity_matrix = np.zeros((n, n))

    <span class="comment"># 计算相似度矩阵</span>
    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):
        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):
            similarity_matrix[i, j] = cosine_similarity(
                word_vectors[i].reshape(<span class="number">1</span>, -<span class="number">1</span>),
                word_vectors[j].reshape(<span class="number">1</span>, -<span class="number">1</span>)
            )[<span class="number">0</span>, <span class="number">0</span>]

    <span class="comment"># 绘制热力图</span>
    plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))
    plt.imshow(similarity_matrix, cmap=<span class="string">'coolwarm'</span>, vmin=-<span class="number">1</span>, vmax=<span class="number">1</span>)
    plt.colorbar(label=<span class="string">'余弦相似度'</span>)

    <span class="comment"># 添加标签</span>
    plt.xticks(range(n), words, rotation=<span class="number">45</span>, ha=<span class="string">'right'</span>)
    plt.yticks(range(n), words)

    <span class="comment"># 添加数值</span>
    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):
        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):
            plt.text(j, i, <span class="string">f'{similarity_matrix[i, j]:.2f}'</span>,
                    ha=<span class="string">'center'</span>, va=<span class="string">'center'</span>,
                    color=<span class="string">'white'</span> <span class="keyword">if</span> abs(similarity_matrix[i, j]) > <span class="number">0.5</span> <span class="keyword">else</span> <span class="string">'black'</span>)

    plt.title(<span class="string">'词向量相似度热力图'</span>)
    plt.tight_layout()
    plt.show()

<span class="comment"># 应用：找最相似的词</span>
<span class="keyword">def</span> <span class="function">find_similar_words</span>(target_word, word_vectors, words, top_k=<span class="number">5</span>):
    <span class="string">"""找出最相似的词"""</span>

    target_idx = words.index(target_word)
    target_vec = word_vectors[target_idx]

    similarities = []
    <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(words):
        <span class="keyword">if</span> i != target_idx:
            sim = cosine_similarity(
                target_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>),
                word_vectors[i].reshape(<span class="number">1</span>, -<span class="number">1</span>)
            )[<span class="number">0</span>, <span class="number">0</span>]
            similarities.append((word, sim))

    <span class="comment"># 按相似度排序</span>
    similarities.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="keyword">True</span>)

    print(<span class="string">f"\n与'{target_word}'最相似的{top_k}个词："</span>)
    <span class="keyword">for</span> word, sim <span class="keyword">in</span> similarities[:top_k]:
        print(<span class="string">f"  {word}: {sim:.3f}"</span>)

    <span class="keyword">return</span> similarities[:top_k]

<span class="comment"># 运行实验</span>
compare_similarity_metrics()</pre>
                </div>
            </div>

            <div class="demo-container">
                <h3 class="mb-3">🎮 交互式相似度计算器</h3>

                <div class="mb-3">
                    <input type="text" id="word1" class="demo-input" placeholder="输入第一个词，如：小猫" style="width: 48%; display: inline-block;">
                    <input type="text" id="word2" class="demo-input" placeholder="输入第二个词，如：小狗" style="width: 48%; display: inline-block; margin-left: 2%;">
                </div>

                <button class="demo-button" onclick="calculateSimilarity()">
                    计算相似度
                </button>

                <div id="similarity-result" class="demo-result">
                    <p class="text-muted">相似度计算结果将显示在这里...</p>
                </div>
            </div>
        </section>

        <!-- 文档向量 -->
        <section id="document-vectors" class="section-card">
            <h2>📄 文档向量：从词到篇章</h2>

            <div class="story-card">
                <span class="story-icon">📚</span>
                <p><strong>如何表示一整篇文章？</strong></p>
                <p class="mt-2">
                    有了词向量，新的问题来了：如何表示句子、段落甚至整篇文章？
                </p>
                <p class="mt-2">
                    这就像从认识单个音符到理解整首交响乐——需要捕捉整体的主题和结构。
                </p>
            </div>

            <div class="think-box">
                <h4>🤔 思考一下</h4>
                <ul>
                    <li>简单平均所有词向量会丢失什么信息？</li>
                    <li>为什么TF-IDF加权比简单平均效果好？</li>
                    <li>Doc2Vec是如何学到文档级别的语义的？</li>
                </ul>
            </div>

            <div class="algorithm-steps">
                <h4 class="mb-4" style="color: var(--primary-light);">📊 文档向量的常用方法</h4>

                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>词向量平均（最简单）</h5>
                        <p>将文档中所有词的向量取平均</p>
                        <div class="code-block mt-3">
                            <div class="code-header">
                                <span class="code-lang">实现示例</span>
                            </div>
                            <div class="code-content">
                                <pre><span class="keyword">def</span> <span class="function">doc_vector_mean</span>(doc, word_vectors):
    vectors = [word_vectors[word] <span class="keyword">for</span> word <span class="keyword">in</span> doc
               <span class="keyword">if</span> word <span class="keyword">in</span> word_vectors]
    <span class="keyword">return</span> np.mean(vectors, axis=<span class="number">0</span>)</pre>
                            </div>
                        </div>
                        <p class="mt-2">
                            ✅ 简单快速 ❌ 忽略词序和重要性
                        </p>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>TF-IDF加权平均</h5>
                        <p>根据词的重要性加权</p>
                        <div class="code-block mt-3">
                            <div class="code-header">
                                <span class="code-lang">实现示例</span>
                            </div>
                            <div class="code-content">
                                <pre><span class="keyword">def</span> <span class="function">doc_vector_tfidf</span>(doc, word_vectors, tfidf_weights):
    weighted_vectors = []
    <span class="keyword">for</span> word <span class="keyword">in</span> doc:
        <span class="keyword">if</span> word <span class="keyword">in</span> word_vectors:
            weight = tfidf_weights.get(word, <span class="number">1.0</span>)
            weighted_vectors.append(word_vectors[word] * weight)
    <span class="keyword">return</span> np.mean(weighted_vectors, axis=<span class="number">0</span>)</pre>
                            </div>
                        </div>
                        <p class="mt-2">
                            ✅ 考虑词的重要性 ❌ 仍然忽略词序
                        </p>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>Doc2Vec（段落向量）</h5>
                        <p>学习专门的文档向量</p>
                        <div class="demo-container">
                            <p><strong>核心思想：</strong>在训练词向量时，加入一个特殊的"文档ID"</p>
                            <p class="mt-2">每个文档都有自己的向量，与词向量一起训练</p>

                            <div class="math-display mt-3">
                                <p>训练目标：预测文档中的词</p>
                                <p class="math-formula">
                                    $P(w_t | w_{t-k}, ..., w_{t+k}, d_i)$
                                </p>
                                <p class="mt-2 text-muted">其中 $d_i$ 是文档向量</p>
                            </div>
                        </div>
                        <p class="mt-2">
                            ✅ 捕获文档整体语义 ❌ 需要重新训练
                        </p>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h5>句子嵌入（Sentence-BERT）</h5>
                        <p>使用预训练模型生成句子向量</p>
                        <div class="tip success">
                            <span class="tip-icon">🚀</span>
                            <strong>现代方法：使用BERT等模型直接生成高质量的句子/文档向量</strong>
                        </div>
                    </div>
                </div>
            </div>

            <div class="code-block mt-4">
                <div class="code-header">
                    <span class="code-lang">Python - 文档向量实战</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content collapsed">
                    <pre><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> Doc2Vec, TaggedDocument
<span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="keyword">class</span> <span class="function">DocumentVectorizer</span>:
    <span class="string">"""文档向量化工具"""</span>

    <span class="keyword">def</span> <span class="function">__init__</span>(self, word_vectors=None):
        self.word_vectors = word_vectors
        self.tfidf = TfidfVectorizer()
        self.doc2vec_model = None

    <span class="keyword">def</span> <span class="function">average_word_vectors</span>(self, doc):
        <span class="string">"""方法1：简单平均"""</span>
        vectors = []
        <span class="keyword">for</span> word <span class="keyword">in</span> doc:
            <span class="keyword">if</span> word <span class="keyword">in</span> self.word_vectors:
                vectors.append(self.word_vectors[word])

        <span class="keyword">if</span> vectors:
            <span class="keyword">return</span> np.mean(vectors, axis=<span class="number">0</span>)
        <span class="keyword">else</span>:
            <span class="comment"># 如果没有词在词表中，返回零向量</span>
            <span class="keyword">return</span> np.zeros(self.word_vectors.vector_size)

    <span class="keyword">def</span> <span class="function">weighted_average</span>(self, docs):
        <span class="string">"""方法2：TF-IDF加权平均"""</span>
        <span class="comment"># 训练TF-IDF</span>
        docs_text = [<span class="string">' '</span>.join(doc) <span class="keyword">for</span> doc <span class="keyword">in</span> docs]
        self.tfidf.fit(docs_text)

        doc_vectors = []
        <span class="keyword">for</span> doc <span class="keyword">in</span> docs:
            <span class="comment"># 获取TF-IDF权重</span>
            doc_text = <span class="string">' '</span>.join(doc)
            tfidf_vector = self.tfidf.transform([doc_text]).toarray()[<span class="number">0</span>]
            vocab = self.tfidf.get_feature_names_out()

            <span class="comment"># 加权平均</span>
            weighted_vectors = []
            <span class="keyword">for</span> word <span class="keyword">in</span> doc:
                <span class="keyword">if</span> word <span class="keyword">in</span> self.word_vectors <span class="keyword">and</span> word <span class="keyword">in</span> vocab:
                    idx = list(vocab).index(word)
                    weight = tfidf_vector[idx]
                    weighted_vectors.append(self.word_vectors[word] * weight)

            <span class="keyword">if</span> weighted_vectors:
                doc_vectors.append(np.mean(weighted_vectors, axis=<span class="number">0</span>))
            <span class="keyword">else</span>:
                doc_vectors.append(np.zeros(self.word_vectors.vector_size))

        <span class="keyword">return</span> doc_vectors

    <span class="keyword">def</span> <span class="function">train_doc2vec</span>(self, documents, vector_size=<span class="number">100</span>, epochs=<span class="number">20</span>):
        <span class="string">"""方法3：训练Doc2Vec模型"""</span>
        <span class="comment"># 准备训练数据</span>
        tagged_docs = []
        <span class="keyword">for</span> i, doc <span class="keyword">in</span> enumerate(documents):
            tagged_docs.append(TaggedDocument(words=doc, tags=[str(i)]))

        <span class="comment"># 训练模型</span>
        self.doc2vec_model = Doc2Vec(
            vector_size=vector_size,
            window=<span class="number">5</span>,
            min_count=<span class="number">1</span>,
            workers=<span class="number">4</span>,
            epochs=epochs
        )

        self.doc2vec_model.build_vocab(tagged_docs)
        self.doc2vec_model.train(
            tagged_docs,
            total_examples=self.doc2vec_model.corpus_count,
            epochs=self.doc2vec_model.epochs
        )

        <span class="keyword">return</span> self.doc2vec_model

    <span class="keyword">def</span> <span class="function">infer_doc_vector</span>(self, doc):
        <span class="string">"""推断新文档的向量"""</span>
        <span class="keyword">if</span> self.doc2vec_model:
            <span class="keyword">return</span> self.doc2vec_model.infer_vector(doc)
        <span class="keyword">else</span>:
            <span class="keyword">raise</span> ValueError(<span class="string">"请先训练Doc2Vec模型"</span>)

<span class="comment"># 使用示例</span>
documents = [
    [<span class="string">'机器学习'</span>, <span class="string">'是'</span>, <span class="string">'人工智能'</span>, <span class="string">'的'</span>, <span class="string">'一个'</span>, <span class="string">'分支'</span>],
    [<span class="string">'深度学习'</span>, <span class="string">'改变'</span>, <span class="string">'了'</span>, <span class="string">'计算机视觉'</span>],
    [<span class="string">'自然语言处理'</span>, <span class="string">'让'</span>, <span class="string">'机器'</span>, <span class="string">'理解'</span>, <span class="string">'人类语言'</span>]
]

<span class="comment"># 文档相似度计算</span>
<span class="keyword">def</span> <span class="function">find_similar_documents</span>(query_doc, doc_vectors, documents, top_k=<span class="number">3</span>):
    <span class="string">"""找出最相似的文档"""</span>

    similarities = []
    query_vec = doc_vectors[query_doc]

    <span class="keyword">for</span> i, doc_vec <span class="keyword">in</span> enumerate(doc_vectors):
        <span class="keyword">if</span> i != query_doc:
            sim = cosine_similarity(
                query_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>),
                doc_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>)
            )[<span class="number">0</span>, <span class="number">0</span>]
            similarities.append((i, sim))

    similarities.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="keyword">True</span>)

    print(<span class="string">f"与文档{query_doc}最相似的文档："</span>)
    <span class="keyword">for</span> idx, sim <span class="keyword">in</span> similarities[:top_k]:
        print(<span class="string">f"  文档{idx}: {' '.join(documents[idx][:10])}... (相似度: {sim:.3f})"</span>)</pre>
                </div>
            </div>
        </section>

        <!-- 实际应用案例 -->
        <section id="applications" class="section-card">
            <h2>🚀 实际应用案例</h2>

            <div class="story-card">
                <span class="story-icon">💼</span>
                <p><strong>词向量改变了整个NLP行业</strong></p>
                <p class="mt-2">
                    从2013年Word2Vec发布至今，词向量已经成为NLP的基础设施，支撑着无数应用。
                </p>
            </div>

            <div class="card-grid">
                <div class="info-card">
                    <span class="card-icon">🔍</span>
                    <h3 class="card-title">智能搜索</h3>
                    <p><strong>问题：</strong>用户搜索"便宜的手机"</p>
                    <p><strong>传统方法：</strong>只能匹配包含"便宜"的结果</p>
                    <p><strong>词向量方案：</strong>找到"实惠"、"性价比高"、"经济实惠"等相似表达</p>
                    <div class="code-block mt-3">
                        <div class="code-header">
                            <span class="code-lang">实现思路</span>
                        </div>
                        <div class="code-content">
                            <pre><span class="comment"># 扩展查询词</span>
similar_words = model.most_similar(<span class="string">"便宜"</span>, topn=<span class="number">5</span>)
<span class="comment"># ['实惠', '廉价', '低价', '经济', '省钱']</span></pre>
                        </div>
                    </div>
                </div>

                <div class="info-card">
                    <span class="card-icon">💬</span>
                    <h3 class="card-title">智能客服</h3>
                    <p><strong>问题：</strong>理解用户的各种问法</p>
                    <p><strong>示例：</strong></p>
                    <ul style="font-size: 0.9rem;">
                        <li>"怎么退货？"</li>
                        <li>"我想退掉这个商品"</li>
                        <li>"不想要了能退吗"</li>
                    </ul>
                    <p><strong>词向量方案：</strong>计算问题相似度，匹配到同一个答案</p>
                </div>

                <div class="info-card">
                    <span class="card-icon">🎯</span>
                    <h3 class="card-title">推荐系统</h3>
                    <p><strong>场景：</strong>新闻推荐</p>
                    <p><strong>传统方法：</strong>基于关键词匹配</p>
                    <p><strong>词向量方案：</strong></p>
                    <ol style="font-size: 0.9rem;">
                        <li>计算用户历史文章的平均向量</li>
                        <li>找相似度最高的新文章</li>
                        <li>推荐语义相关而非仅仅关键词相同</li>
                    </ol>
                </div>

                <div class="info-card">
                    <span class="card-icon">🌐</span>
                    <h3 class="card-title">机器翻译</h3>
                    <p><strong>挑战：</strong>词汇对齐</p>
                    <p><strong>词向量方案：</strong>跨语言词向量</p>
                    <div class="demo-container mt-3" style="padding: 1rem;">
                        <p style="font-size: 0.9rem;">
                            King - Man + Woman = Queen<br>
                            国王 - 男人 + 女人 = 女王<br>
                            <span class="text-muted">→ 不同语言的词向量空间可以对齐！</span>
                        </p>
                    </div>
                </div>

                <div class="info-card">
                    <span class="card-icon">🎭</span>
                    <h3 class="card-title">情感分析</h3>
                    <p><strong>任务：</strong>判断评论的情感倾向</p>
                    <p><strong>词向量优势：</strong></p>
                    <ul style="font-size: 0.9rem;">
                        <li>相似情感词聚集：开心≈高兴≈愉快</li>
                        <li>反义词分离：好⟷坏</li>
                        <li>程度词区分：喜欢 < 爱 < 酷爱</li>
                    </ul>
                </div>

                <div class="info-card">
                    <span class="card-icon">🏷️</span>
                    <h3 class="card-title">文本分类</h3>
                    <p><strong>改进效果：</strong></p>
                    <div class="comparison-table mt-3" style="font-size: 0.875rem;">
                        <table>
                            <tr>
                                <td>传统方法(BoW)</td>
                                <td>85%准确率</td>
                            </tr>
                            <tr>
                                <td>+词向量</td>
                                <td>92%准确率</td>
                            </tr>
                            <tr>
                                <td>+预训练模型</td>
                                <td>97%准确率</td>
                            </tr>
                        </table>
                    </div>
                </div>
            </div>

            <div class="code-block mt-4">
                <div class="code-header">
                    <span class="code-lang">Python - 综合应用示例</span>
                    <div class="code-actions">
                        <button class="code-btn" onclick="toggleCode(this)">展开</button>
                        <button class="code-btn" onclick="copyCode(this)">复制</button>
                    </div>
                </div>
                <div class="code-content collapsed">
                    <pre><span class="comment"># 应用1：智能搜索扩展</span>
<span class="keyword">class</span> <span class="function">SmartSearch</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, word_vectors):
        self.word_vectors = word_vectors
        self.documents = []
        self.doc_vectors = []

    <span class="keyword">def</span> <span class="function">expand_query</span>(self, query, n_expansions=<span class="number">3</span>):
        <span class="string">"""扩展查询词"""</span>
        expanded_terms = []

        <span class="keyword">for</span> word <span class="keyword">in</span> query.split():
            expanded_terms.append(word)
            <span class="keyword">if</span> word <span class="keyword">in</span> self.word_vectors:
                similar = self.word_vectors.most_similar(word, topn=n_expansions)
                expanded_terms.extend([w[<span class="number">0</span>] <span class="keyword">for</span> w <span class="keyword">in</span> similar])

        <span class="keyword">return</span> list(set(expanded_terms))

    <span class="keyword">def</span> <span class="function">search</span>(self, query, top_k=<span class="number">5</span>):
        <span class="string">"""语义搜索"""</span>
        <span class="comment"># 计算查询向量</span>
        query_words = query.split()
        query_vec = np.mean([
            self.word_vectors[w] <span class="keyword">for</span> w <span class="keyword">in</span> query_words
            <span class="keyword">if</span> w <span class="keyword">in</span> self.word_vectors
        ], axis=<span class="number">0</span>)

        <span class="comment"># 计算相似度</span>
        similarities = []
        <span class="keyword">for</span> i, doc_vec <span class="keyword">in</span> enumerate(self.doc_vectors):
            sim = cosine_similarity(
                query_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>),
                doc_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>)
            )[<span class="number">0</span>, <span class="number">0</span>]
            similarities.append((i, sim))

        <span class="comment"># 返回最相似的文档</span>
        similarities.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="keyword">True</span>)
        <span class="keyword">return</span> [(self.documents[i], sim) <span class="keyword">for</span> i, sim <span class="keyword">in</span> similarities[:top_k]]

<span class="comment"># 应用2：问答系统相似问题匹配</span>
<span class="keyword">class</span> <span class="function">FAQMatcher</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, word_vectors):
        self.word_vectors = word_vectors
        self.faq_database = []
        self.faq_vectors = []

    <span class="keyword">def</span> <span class="function">add_faq</span>(self, question, answer):
        <span class="string">"""添加FAQ"""</span>
        self.faq_database.append({<span class="string">'question'</span>: question, <span class="string">'answer'</span>: answer})

        <span class="comment"># 计算问题向量</span>
        words = question.split()
        vec = np.mean([
            self.word_vectors[w] <span class="keyword">for</span> w <span class="keyword">in</span> words
            <span class="keyword">if</span> w <span class="keyword">in</span> self.word_vectors
        ], axis=<span class="number">0</span>)
        self.faq_vectors.append(vec)

    <span class="keyword">def</span> <span class="function">find_answer</span>(self, user_question, threshold=<span class="number">0.7</span>):
        <span class="string">"""找到最匹配的答案"""</span>
        <span class="comment"># 计算用户问题向量</span>
        words = user_question.split()
        user_vec = np.mean([
            self.word_vectors[w] <span class="keyword">for</span> w <span class="keyword">in</span> words
            <span class="keyword">if</span> w <span class="keyword">in</span> self.word_vectors
        ], axis=<span class="number">0</span>)

        <span class="comment"># 找最相似的FAQ</span>
        best_match = None
        best_sim = -<span class="number">1</span>

        <span class="keyword">for</span> i, faq_vec <span class="keyword">in</span> enumerate(self.faq_vectors):
            sim = cosine_similarity(
                user_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>),
                faq_vec.reshape(<span class="number">1</span>, -<span class="number">1</span>)
            )[<span class="number">0</span>, <span class="number">0</span>]

            <span class="keyword">if</span> sim > best_sim:
                best_sim = sim
                best_match = i

        <span class="keyword">if</span> best_sim >= threshold:
            <span class="keyword">return</span> self.faq_database[best_match][<span class="string">'answer'</span>], best_sim
        <span class="keyword">else</span>:
            <span class="keyword">return</span> <span class="string">"抱歉，我不太理解您的问题。"</span>, best_sim

<span class="comment"># 应用3：文本去重</span>
<span class="keyword">def</span> <span class="function">find_duplicate_documents</span>(documents, word_vectors, threshold=<span class="number">0.9</span>):
    <span class="string">"""找出重复或高度相似的文档"""</span>

    <span class="comment"># 计算所有文档向量</span>
    doc_vectors = []
    <span class="keyword">for</span> doc <span class="keyword">in</span> documents:
        words = doc.split()
        vec = np.mean([
            word_vectors[w] <span class="keyword">for</span> w <span class="keyword">in</span> words
            <span class="keyword">if</span> w <span class="keyword">in</span> word_vectors
        ], axis=<span class="number">0</span>)
        doc_vectors.append(vec)

    <span class="comment"># 找出相似文档对</span>
    duplicates = []
    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(documents)):
        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, len(documents)):
            sim = cosine_similarity(
                doc_vectors[i].reshape(<span class="number">1</span>, -<span class="number">1</span>),
                doc_vectors[j].reshape(<span class="number">1</span>, -<span class="number">1</span>)
            )[<span class="number">0</span>, <span class="number">0</span>]

            <span class="keyword">if</span> sim >= threshold:
                duplicates.append((i, j, sim))

    <span class="keyword">return</span> duplicates</pre>
                </div>
            </div>
        </section>

        <!-- 本章总结 -->
        <section id="summary" class="section-card">
            <h2>📚 本章总结</h2>

            <div class="story-card">
                <span class="story-icon">🎓</span>
                <p><strong>从符号到语义的伟大跨越</strong></p>
                <p class="mt-2">
                    还记得开篇的"国王-男人+女人=女王"吗？这个简单的算式背后，是人类让机器理解语言含义的重大突破。
                </p>
                <p class="mt-2">
                    词向量不仅仅是一种技术，更是一种全新的语言理解范式——它让"意义"变得可计算。
                </p>
            </div>

            <div class="flow-diagram">
                <h4 class="text-center mb-4" style="color: var(--primary-light);">🗺️ 词向量技术全景图</h4>

                <div class="visualization">
                    <svg width="900" height="600" viewBox="0 0 900 600" style="max-width: 100%;">
                        <!-- 时间轴 -->
                        <line x1="50" y1="500" x2="850" y2="500" stroke="#475569" stroke-width="2"/>
                        <text x="450" y="540" text-anchor="middle" fill="#94a3b8" font-size="14">时间发展</text>

                        <!-- 2013 -->
                        <circle cx="150" cy="500" r="5" fill="#6366f1"/>
                        <text x="150" y="520" text-anchor="middle" fill="#cbd5e1" font-size="12">2013</text>
                        <rect x="100" y="420" width="100" height="60" fill="#334155" rx="10"/>
                        <text x="150" y="445" text-anchor="middle" fill="white" font-size="14" font-weight="bold">Word2Vec</text>
                        <text x="150" y="465" text-anchor="middle" fill="#94a3b8" font-size="11">开创性突破</text>

                        <!-- 2014 -->
                        <circle cx="300" cy="500" r="5" fill="#6366f1"/>
                        <text x="300" y="520" text-anchor="middle" fill="#cbd5e1" font-size="12">2014</text>
                        <rect x="250" y="420" width="100" height="60" fill="#334155" rx="10"/>
                        <text x="300" y="445" text-anchor="middle" fill="white" font-size="14" font-weight="bold">GloVe</text>
                        <text x="300" y="465" text-anchor="middle" fill="#94a3b8" font-size="11">全局视角</text>

                        <!-- 2016 -->
                        <circle cx="450" cy="500" r="5" fill="#6366f1"/>
                        <text x="450" y="520" text-anchor="middle" fill="#cbd5e1" font-size="12">2016</text>
                        <rect x="400" y="420" width="100" height="60" fill="#334155" rx="10"/>
                        <text x="450" y="445" text-anchor="middle" fill="white" font-size="14" font-weight="bold">FastText</text>
                        <text x="450" y="465" text-anchor="middle" fill="#94a3b8" font-size="11">子词建模</text>

                        <!-- 2018 -->
                        <circle cx="600" cy="500" r="5" fill="#ec4899"/>
                        <text x="600" y="520" text-anchor="middle" fill="#cbd5e1" font-size="12">2018</text>
                        <rect x="550" y="340" width="100" height="60" fill="#ec4899" rx="10"/>
                        <text x="600" y="365" text-anchor="middle" fill="white" font-size="14" font-weight="bold">BERT</text>
                        <text x="600" y="385" text-anchor="middle" fill="white" font-size="11">上下文理解</text>
                        <path d="M 600 400 L 600 495" stroke="#ec4899" stroke-width="2" stroke-dasharray="5,5"/>

                        <!-- 2023+ -->
                        <circle cx="750" cy="500" r="5" fill="#10b981"/>
                        <text x="750" y="520" text-anchor="middle" fill="#cbd5e1" font-size="12">2023+</text>
                        <rect x="700" y="340" width="100" height="60" fill="#10b981" rx="10"/>
                        <text x="750" y="365" text-anchor="middle" fill="white" font-size="14" font-weight="bold">LLM时代</text>
                        <text x="750" y="385" text-anchor="middle" fill="white" font-size="11">GPT/ChatGPT</text>

                        <!-- 技术分类 -->
                        <text x="50" y="50" fill="#f1f5f9" font-size="16" font-weight="bold">词向量技术演进</text>

                        <!-- 静态词向量 -->
                        <rect x="50" y="80" width="500" height="200" fill="none" stroke="#6366f1" stroke-width="2" rx="10" stroke-dasharray="10,5"/>
                        <text x="60" y="105" fill="#818cf8" font-size="14" font-weight="bold">静态词向量</text>

                        <!-- 动态词向量 -->
                        <rect x="480" y="80" width="370" height="200" fill="none" stroke="#ec4899" stroke-width="2" rx="10" stroke-dasharray="10,5"/>
                        <text x="490" y="105" fill="#f472b6" font-size="14" font-weight="bold">动态词向量</text>

                        <!-- 特点对比 -->
                        <text x="80" y="140" fill="#94a3b8" font-size="12">• 一词一向量</text>
                        <text x="80" y="165" fill="#94a3b8" font-size="12">• 训练快速</text>
                        <text x="80" y="190" fill="#94a3b8" font-size="12">• 内存占用小</text>
                        <text x="80" y="215" fill="#94a3b8" font-size="12">• 无法处理多义词</text>

                        <text x="510" y="140" fill="#94a3b8" font-size="12">• 根据上下文变化</text>
                        <text x="510" y="165" fill="#94a3b8" font-size="12">• 需要大模型</text>
                        <text x="510" y="190" fill="#94a3b8" font-size="12">• 计算资源密集</text>
                        <text x="510" y="215" fill="#94a3b8" font-size="12">• 理解多义词</text>
                    </svg>
                </div>
            </div>

            <div class="card-grid mt-4">
                <div class="info-card">
                    <span class="card-icon">🎯</span>
                    <h3 class="card-title">核心概念</h3>
                    <ul>
                        <li><strong>分布假设：</strong>词的意义由上下文决定</li>
                        <li><strong>词向量：</strong>用连续向量表示词的语义</li>
                        <li><strong>语义运算：</strong>向量运算对应语义关系</li>
                        <li><strong>相似度：</strong>余弦相似度衡量语义相近</li>
                    </ul>
                </div>

                <div class="info-card">
                    <span class="card-icon">🛠️</span>
                    <h3 class="card-title">关键技术</h3>
                    <ul>
                        <li><strong>Word2Vec：</strong>CBOW和Skip-gram</li>
                        <li><strong>GloVe：</strong>结合全局统计</li>
                        <li><strong>FastText：</strong>子词级别建模</li>
                        <li><strong>BERT等：</strong>上下文相关表示</li>
                    </ul>
                </div>

                <div class="info-card">
                    <span class="card-icon">💡</span>
                    <h3 class="card-title">实践要点</h3>
                    <ul>
                        <li>预训练模型优于从零训练</li>
                        <li>根据任务选择合适的词向量</li>
                        <li>注意处理未登录词（OOV）</li>
                        <li>考虑计算资源和实时性需求</li>
                    </ul>
                </div>
            </div>

            <div class="tip success mt-4">
                <span class="tip-icon">🌟</span>
                <strong>展望未来</strong>
                <p class="mt-2">
                    词向量技术仍在快速发展。从静态到动态，从单语到多语，从文本到多模态，词向量正在帮助机器更深入地理解人类语言。
                </p>
                <p class="mt-2">
                    在大语言模型时代，词向量依然是理解和改进这些模型的关键。掌握词向量，就掌握了打开NLP大门的钥匙。
                </p>
            </div>
        </section>

        <!-- 练习题 -->
        <section id="exercises" class="section-card">
            <h2>🏋️ 动手练习</h2>

            <div class="algorithm-steps">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>基础练习：实现简单的词向量训练</h5>
                        <p>使用numpy实现一个简化版的Word2Vec</p>
                        <div class="code-block mt-3">
                            <div class="code-header">
                                <span class="code-lang">Python - 练习模板</span>
                            </div>
                            <div class="code-content">
                                <pre><span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="keyword">class</span> <span class="function">SimpleWord2Vec</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, vocab_size, embedding_dim):
        <span class="string">"""
        实现一个简单的Word2Vec模型

        任务：
        1. 初始化词向量矩阵
        2. 实现前向传播
        3. 实现梯度更新
        """</span>
        <span class="comment"># 提示：需要两个矩阵</span>
        self.W = np.random.randn(vocab_size, embedding_dim) * 0.01  <span class="comment"># 输入词向量</span>
        self.U = np.random.randn(vocab_size, embedding_dim) * 0.01  <span class="comment"># 输出词向量</span>

    <span class="keyword">def</span> <span class="function">forward</span>(self, center_word_idx):
        <span class="string">"""前向传播：计算P(context|center)"""</span>
        <span class="comment"># 提示：</span>
        <span class="comment"># 1. 获取中心词向量: v_c = self.W[center_word_idx]</span>
        <span class="comment"># 2. 计算所有词的得分: scores = np.dot(self.U, v_c)</span>
        <span class="comment"># 3. 应用softmax: exp_scores = np.exp(scores - np.max(scores))</span>
        <span class="comment"># 4. 归一化: probs = exp_scores / np.sum(exp_scores)</span>
        <span class="keyword">pass</span>

    <span class="keyword">def</span> <span class="function">train_step</span>(self, center_idx, context_idx, learning_rate=0.01):
        <span class="string">"""训练一步"""</span>
        <span class="comment"># 提示：基于公式更新向量</span>
        <span class="comment"># error = predicted_prob - actual_prob</span>
        <span class="comment"># grad_U = error * v_c</span>
        <span class="comment"># grad_v_c = U.T @ error</span>
        <span class="keyword">pass</span>

<span class="comment"># 测试提示</span>
<span class="comment"># 1. 创建简单词汇表：vocab = ['猫', '狗', '喝', '吃', '牛奶', '骨头']</span>
<span class="comment"># 2. 生成训练对：pairs = [(2, 0), (2, 4), ...]  # (喝, 猫), (喝, 牛奶)</span>
<span class="comment"># 3. 训练后检查相似度：猫和狗应该比猫和喝更相似</span></pre>
                            </div>
                        </div>

                        <div class="formula-explanation mt-3">
                            <h5>📖 从数学到代码的桥梁</h5>
                            <p>Skip-gram的核心公式：</p>
                            <p class="text-center">$P(w_o|w_c) = \frac{\exp(u_o^T v_c)}{\sum_{w} \exp(u_w^T v_c)}$</p>

                            <p class="mt-3">转换成代码的步骤：</p>
                            <ol>
                                <li><strong>向量相乘：</strong><code>u_o^T v_c</code> → <code>np.dot(U[o], v_c)</code></li>
                                <li><strong>指数函数：</strong><code>exp(...)</code> → <code>np.exp(...)</code></li>
                                <li><strong>求和：</strong><code>Σ</code> → <code>np.sum(...)</code></li>
                                <li><strong>梯度下降：</strong><code>θ = θ - α∇L</code> → <code>W -= lr * gradient</code></li>
                            </ol>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>进阶练习：构建语义搜索引擎</h5>
                        <p>使用预训练词向量实现一个简单的语义搜索系统</p>
                        <div class="demo-container">
                            <p><strong>需求：</strong></p>
                            <ul>
                                <li>加载预训练词向量</li>
                                <li>实现查询扩展</li>
                                <li>计算文档相似度</li>
                                <li>返回最相关的结果</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>挑战练习：多语言词向量对齐</h5>
                        <p>实现中英文词向量空间的对齐</p>
                        <div class="demo-container">
                            <p><strong>目标：</strong></p>
                            <ul>
                                <li>加载中文和英文词向量</li>
                                <li>使用对齐词典学习转换矩阵</li>
                                <li>实现跨语言词汇检索</li>
                                <li>评估对齐质量</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <div class="think-box mt-4">
                <h4>💭 深度思考题</h4>
                <ul>
                    <li>为什么词向量的维度通常选择100-300，而不是更高或更低？</li>
                    <li>词向量真的理解了语义吗？还是只是统计规律？</li>
                    <li>在什么情况下，简单的TF-IDF可能比词向量效果更好？</li>
                    <li>如何评估词向量的质量？有哪些标准的评测任务？</li>
                    <li>大语言模型时代，静态词向量还有价值吗？</li>
                </ul>
            </div>

            <div class="tip info mt-4">
                <span class="tip-icon">📖</span>
                <strong>推荐阅读</strong>
                <ul class="mt-2">
                    <li>📄 Mikolov et al. (2013) - Efficient Estimation of Word Representations</li>
                    <li>📄 Pennington et al. (2014) - GloVe: Global Vectors for Word Representation</li>
                    <li>📄 Bojanowski et al. (2017) - Enriching Word Vectors with Subword Information</li>
                    <li>📄 Peters et al. (2018) - Deep contextualized word representations (ELMo)</li>
                    <li>📄 Devlin et al. (2018) - BERT: Pre-training of Deep Bidirectional Transformers</li>
                </ul>
            </div>
        </section>
    </div>
</main>

<!-- JavaScript -->
<script>
    // 进度条
    window.addEventListener('scroll', function() {
        const winScroll = document.documentElement.scrollTop;
        const height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
        const scrolled = (winScroll / height) * 100;
        document.getElementById('progress-bar').style.width = scrolled + '%';
    });

    // 侧边栏切换
    document.getElementById('toggle-sidebar').addEventListener('click', function() {
        document.getElementById('sidebar').classList.toggle('open');
    });

    // 目录高亮
    const sections = document.querySelectorAll('section[id]');
    const tocItems = document.querySelectorAll('.toc-item');

    window.addEventListener('scroll', () => {
        let current = '';
        sections.forEach(section => {
            const sectionTop = section.offsetTop;
            const sectionHeight = section.clientHeight;
            if (scrollY >= sectionTop - 100) {
                current = section.getAttribute('id');
            }
        });

        tocItems.forEach(item => {
            item.classList.remove('active');
            if (item.getAttribute('href') === `#${current}`) {
                item.classList.add('active');
            }
        });

        // 更新快速导航
        const quickNavItems = document.querySelectorAll('.quick-nav-item');
        quickNavItems.forEach(item => {
            item.classList.remove('active');
            if (item.getAttribute('data-section') === current) {
                item.classList.add('active');
            }
        });
    });

    // 快速导航
    const quickNavItems = document.querySelectorAll('.quick-nav-item');
    quickNavItems.forEach(item => {
        item.addEventListener('click', function() {
            const section = this.getAttribute('data-section');
            document.getElementById(section).scrollIntoView({ behavior: 'smooth' });
        });
    });

    // 3D词向量空间可视化
    function initVectorSpace() {
        const canvas = document.getElementById('vector-space');
        const ctx = canvas.getContext('2d');

        // 设置画布大小
        canvas.width = canvas.offsetWidth;
        canvas.height = canvas.offsetHeight;

        // 模拟的词向量数据
        const words = [
            {name: '国王', x: 100, y: 100, color: '#6366f1'},
            {name: '女王', x: 120, y: 280, color: '#ec4899'},
            {name: '男人', x: 250, y: 100, color: '#3b82f6'},
            {name: '女人', x: 270, y: 280, color: '#f472b6'},
            {name: '王子', x: 150, y: 150, color: '#818cf8'},
            {name: '公主', x: 170, y: 230, color: '#f9a8d4'}
        ];

        // 缩放到画布大小
        const scaleX = canvas.width / 400;
        const scaleY = canvas.height / 400;

        // 绘制背景
        ctx.fillStyle = '#1e293b';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        // 绘制网格
        ctx.strokeStyle = '#334155';
        ctx.lineWidth = 1;
        for (let i = 0; i < canvas.width; i += 50) {
            ctx.beginPath();
            ctx.moveTo(i, 0);
            ctx.lineTo(i, canvas.height);
            ctx.stroke();
        }
        for (let i = 0; i < canvas.height; i += 50) {
            ctx.beginPath();
            ctx.moveTo(0, i);
            ctx.lineTo(canvas.width, i);
            ctx.stroke();
        }

        // 绘制关系箭头
        ctx.strokeStyle = '#475569';
        ctx.lineWidth = 2;
        ctx.setLineDash([5, 5]);

        // 国王->女王
        drawArrow(ctx, words[0].x * scaleX, words[0].y * scaleY,
            words[1].x * scaleX, words[1].y * scaleY, '#6366f1');

        // 男人->女人
        drawArrow(ctx, words[2].x * scaleX, words[2].y * scaleY,
            words[3].x * scaleX, words[3].y * scaleY, '#3b82f6');

        ctx.setLineDash([]);

        // 绘制词向量点
        words.forEach(word => {
            const x = word.x * scaleX;
            const y = word.y * scaleY;

            // 绘制光晕效果
            ctx.beginPath();
            ctx.arc(x, y, 20, 0, 2 * Math.PI);
            const gradient = ctx.createRadialGradient(x, y, 0, x, y, 20);
            gradient.addColorStop(0, word.color + '40');
            gradient.addColorStop(1, 'transparent');
            ctx.fillStyle = gradient;
            ctx.fill();

            // 绘制点
            ctx.beginPath();
            ctx.arc(x, y, 8, 0, 2 * Math.PI);
            ctx.fillStyle = word.color;
            ctx.fill();

            // 绘制标签背景
            ctx.fillStyle = 'rgba(30, 41, 59, 0.8)';
            ctx.fillRect(x - 25, y - 30, 50, 20);

            // 绘制标签
            ctx.fillStyle = '#f1f5f9';
            ctx.font = '14px Arial';
            ctx.textAlign = 'center';
            ctx.fillText(word.name, x, y - 15);
        });

        // 绘制向量运算示例
        ctx.fillStyle = '#f59e0b';
        ctx.font = 'bold 16px Arial';
        ctx.textAlign = 'center';
        ctx.fillText('国王 - 男人 + 女人 ≈ 女王', canvas.width / 2, canvas.height - 30);
    }

    // 绘制箭头
    function drawArrow(ctx, fromX, fromY, toX, toY, color) {
        const headlen = 10;
        const angle = Math.atan2(toY - fromY, toX - fromX);

        ctx.beginPath();
        ctx.moveTo(fromX, fromY);
        ctx.lineTo(toX, toY);
        ctx.strokeStyle = color + '80';
        ctx.stroke();

        ctx.beginPath();
        ctx.moveTo(toX, toY);
        ctx.lineTo(toX - headlen * Math.cos(angle - Math.PI / 6), toY - headlen * Math.sin(angle - Math.PI / 6));
        ctx.moveTo(toX, toY);
        ctx.lineTo(toX - headlen * Math.cos(angle + Math.PI / 6), toY - headlen * Math.sin(angle + Math.PI / 6));
        ctx.stroke();
    }

    // 初始化可视化
    if (document.getElementById('vector-space')) {
        initVectorSpace();

        // 响应式重绘
        window.addEventListener('resize', initVectorSpace);
    }

    // 词云更新
    function updateWordCloud(category) {
        const container = document.getElementById('word-embedding-viz');
        container.innerHTML = '';

        const wordGroups = {
            animals: [
                {text: '小猫', size: 28},
                {text: '小狗', size: 26},
                {text: '兔子', size: 22},
                {text: '老虎', size: 24},
                {text: '狮子', size: 23},
                {text: '熊猫', size: 30},
                {text: '大象', size: 25},
                {text: '猴子', size: 20},
                {text: '松鼠', size: 18},
                {text: '海豚', size: 21}
            ],
            food: [
                {text: '苹果', size: 25},
                {text: '香蕉', size: 23},
                {text: '面包', size: 22},
                {text: '米饭', size: 28},
                {text: '牛奶', size: 24},
                {text: '鸡蛋', size: 20},
                {text: '蔬菜', size: 26},
                {text: '水果', size: 30},
                {text: '巧克力', size: 21},
                {text: '咖啡', size: 19}
            ],
            tech: [
                {text: '人工智能', size: 30},
                {text: '机器学习', size: 28},
                {text: '深度学习', size: 26},
                {text: '神经网络', size: 24},
                {text: '算法', size: 22},
                {text: '编程', size: 20},
                {text: '数据', size: 25},
                {text: '云计算', size: 21},
                {text: '区块链', size: 19},
                {text: '量子计算', size: 18}
            ],
            emotion: [
                {text: '快乐', size: 28},
                {text: '悲伤', size: 24},
                {text: '愤怒', size: 22},
                {text: '恐惧', size: 20},
                {text: '惊喜', size: 26},
                {text: '平静', size: 23},
                {text: '兴奋', size: 25},
                {text: '失望', size: 21},
                {text: '感动', size: 27},
                {text: '温暖', size: 29}
            ]
        };

        const words = wordGroups[category] || wordGroups.animals;

        words.forEach((word, index) => {
            const span = document.createElement('span');
            span.className = 'word-item';
            span.textContent = word.text;

            // 计算位置（聚类效果）
            const angle = (index / words.length) * 2 * Math.PI;
            const radius = 100 + Math.random() * 80;
            const x = 50 + radius * Math.cos(angle) / 3;
            const y = 50 + radius * Math.sin(angle) / 3;

            span.style.fontSize = word.size + 'px';
            span.style.left = x + '%';
            span.style.top = y + '%';
            span.style.color = `hsl(${index * 36}, 70%, 60%)`;
            span.style.animationDelay = `${index * 0.1}s`;

            container.appendChild(span);
        });
    }

    // 初始化词云
    updateWordCloud('animals');

    // 相似度计算演示
    function calculateSimilarity() {
        const word1 = document.getElementById('word1').value.trim();
        const word2 = document.getElementById('word2').value.trim();
        const resultDiv = document.getElementById('similarity-result');

        if (!word1 || !word2) {
            resultDiv.innerHTML = '<p class="text-muted">请输入两个词...</p>';
            return;
        }

        // 模拟相似度计算
        const similarPairs = {
            '小猫,小狗': 0.85,
            '小狗,小猫': 0.85,
            '汽车,自行车': 0.72,
            '自行车,汽车': 0.72,
            '汽车,飞机': 0.68,
            '飞机,汽车': 0.68,
            '快乐,高兴': 0.92,
            '高兴,快乐': 0.92,
            '悲伤,难过': 0.89,
            '难过,悲伤': 0.89,
            '美丽,漂亮': 0.94,
            '漂亮,美丽': 0.94,
            '聪明,智慧': 0.87,
            '智慧,聪明': 0.87,
            '大,小': -0.65,
            '小,大': -0.65,
            '热,冷': -0.58,
            '冷,热': -0.58,
            '苹果,香蕉': 0.76,
            '香蕉,苹果': 0.76,
            '北京,上海': 0.83,
            '上海,北京': 0.83,
            '老师,学生': 0.61,
            '学生,老师': 0.61,
            '春天,夏天': 0.78,
            '夏天,春天': 0.78
        };

        const key = `${word1},${word2}`;
        let similarity = similarPairs[key];

        // 如果没有预定义的相似度，根据一些规则生成
        if (similarity === undefined) {
            // 相同的词
            if (word1 === word2) {
                similarity = 1.0;
            }
            // 包含关系
            else if (word1.includes(word2) || word2.includes(word1)) {
                similarity = 0.7 + Math.random() * 0.2;
            }
            // 默认随机
            else {
                similarity = Math.random() * 0.6 - 0.1; // -0.1 到 0.5
            }
        }

        let html = `
            <h4>计算结果</h4>
            <div class="mt-3">
                <p><strong>${word1}</strong> 和 <strong>${word2}</strong> 的余弦相似度：</p>
                <div style="font-size: 2rem; color: var(--primary-light); text-align: center; margin: 1rem 0;">
                    ${similarity.toFixed(3)}
                </div>

                <!-- 相似度可视化 -->
                <div style="background: var(--bg-dark); padding: 1rem; border-radius: 0.5rem; margin-top: 1rem;">
                    <div style="display: flex; align-items: center; gap: 1rem;">
                        <span style="color: var(--text-muted);">相似度：</span>
                        <div style="flex: 1; background: rgba(255,255,255,0.1); height: 20px; border-radius: 10px; overflow: hidden;">
                            <div style="height: 100%; background: ${similarity > 0.7 ? 'var(--success)' : similarity > 0.4 ? 'var(--warning)' : 'var(--danger)'}; width: ${Math.abs(similarity) * 100}%; transition: width 0.5s ease;"></div>
                        </div>
                        <span style="color: var(--text-primary);">${(Math.abs(similarity) * 100).toFixed(0)}%</span>
                    </div>
                </div>

                <div style="background: var(--bg-dark); padding: 1rem; border-radius: 0.5rem; margin-top: 1rem;">
                    <p style="font-size: 0.875rem; color: var(--text-muted);">
                        <strong>相似度解释：</strong><br>`;

        if (similarity > 0.8) {
            html += '✅ 非常相似 - 这两个词在语义上高度相关，经常出现在相似的上下文中。';
        } else if (similarity > 0.6) {
            html += '🟡 较为相似 - 有一定的语义关联，属于相关概念。';
        } else if (similarity > 0.3) {
            html += '🟠 略有相似 - 存在某些共同特征，但关联性不强。';
        } else if (similarity > -0.3) {
            html += '⚪ 基本无关 - 这两个词在语义上没有明显关联。';
        } else {
            html += '🔴 相反关系 - 这两个词可能是反义词或对立概念。';
        }

        html += `
                    </p>

                    <div class="mt-3" style="font-size: 0.875rem;">
                        <p style="color: var(--primary-light); margin-bottom: 0.5rem;">💡 小知识：</p>
                        <p>余弦相似度通过计算两个向量夹角的余弦值来衡量相似性。值越接近1表示越相似，越接近-1表示越相反，0表示无关。</p>
                    </div>
                </div>
            </div>
        `;

        resultDiv.innerHTML = html;
    }

    // 代码折叠
    function toggleCode(btn) {
        const codeContent = btn.parentElement.parentElement.nextElementSibling;
        if (codeContent.classList.contains('collapsed')) {
            codeContent.classList.remove('collapsed');
            btn.textContent = '折叠';
        } else {
            codeContent.classList.add('collapsed');
            btn.textContent = '展开';
        }
    }

    // 复制代码
    function copyCode(btn) {
        const codeContent = btn.parentElement.parentElement.nextElementSibling;
        const code = codeContent.querySelector('pre').textContent;

        navigator.clipboard.writeText(code).then(() => {
            const originalText = btn.textContent;
            btn.textContent = '已复制！';
            btn.style.background = 'var(--success)';
            setTimeout(() => {
                btn.textContent = originalText;
                btn.style.background = '';
            }, 2000);
        }).catch(() => {
            // 降级方案
            const textArea = document.createElement('textarea');
            textArea.value = code;
            textArea.style.position = 'fixed';
            textArea.style.opacity = '0';
            document.body.appendChild(textArea);
            textArea.select();
            document.execCommand('copy');
            document.body.removeChild(textArea);

            const originalText = btn.textContent;
            btn.textContent = '已复制！';
            btn.style.background = 'var(--success)';
            setTimeout(() => {
                btn.textContent = originalText;
                btn.style.background = '';
            }, 2000);
        });
    }

    // 主题切换（预留）
    document.getElementById('theme-toggle').addEventListener('click', function() {
        // 这里可以添加主题切换逻辑
        alert('主题切换功能开发中...');
    });
</script>

</body>
</html>