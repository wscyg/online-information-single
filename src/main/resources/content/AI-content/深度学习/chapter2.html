<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第2章：误差反向传播 - 深度网络的血脉 | 深度学习之旅</title>
    <meta name="description" content="从手推梯度到自动微分：探索深度学习最重要的算法，理解误差如何在网络中反向流动">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
    <style>
        /* ===== CSS变量定义 ===== */
        :root {
            --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            --bg-dark: #0f172a;
            --bg-section: #1e293b;
            --text-primary: #f1f5f9;
            --text-secondary: #e2e8f0;
            --text-muted: #cbd5e1;
            --accent-red: #ef4444;
            --accent-green: #22c55e;
            --accent-blue: #06b6d4;
            --accent-yellow: #fbbf24;
            --accent-purple: #8b5cf6;
            --accent-pink: #ec4899;
            --border-color: rgba(255, 255, 255, 0.1);
            --shadow-lg: 0 10px 40px rgba(0, 0, 0, 0.3);
            --animation-duration: 0.3s;
            --content-max-width: 1200px;
            --focus-ring: 0 0 0 3px rgba(139, 92, 246, 0.5);
        }

        /* 亮色主题 */
        [data-theme="light"] {
            --bg-dark: #ffffff;
            --bg-section: #f8fafc;
            --text-primary: #0f172a;
            --text-secondary: #475569;
            --text-muted: #64748b;
            --border-color: rgba(0, 0, 0, 0.1);
            --shadow-lg: 0 10px 40px rgba(0, 0, 0, 0.1);
        }

        /* ===== 全局样式 ===== */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: var(--bg-dark);
            color: var(--text-primary);
            line-height: 1.6;
            overflow-x: hidden;
            transition: background-color var(--animation-duration) ease;
        }

        /* ===== 焦点样式 ===== */
        :focus-visible {
            outline: none;
            box-shadow: var(--focus-ring);
            border-radius: 0.25rem;
        }

        button:focus-visible,
        a:focus-visible {
            outline: none;
            box-shadow: var(--focus-ring);
        }

        /* ===== 布局组件 ===== */
        .container {
            max-width: var(--content-max-width);
            margin: 0 auto;
            padding: 0 1rem;
        }

        /* ===== 导航栏 ===== */
        .nav-header {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(15, 23, 42, 0.95);
            backdrop-filter: blur(10px);
            z-index: 1000;
            border-bottom: 1px solid var(--border-color);
            transition: transform 0.3s ease;
        }

        .nav-header.hidden {
            transform: translateY(-100%);
        }

        .nav-content {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 1rem 0;
        }

        .nav-title {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .nav-title h1 {
            font-size: 1.25rem;
            font-weight: 600;
            background: var(--primary-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .nav-controls {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        .btn-control {
            background: transparent;
            border: 1px solid var(--border-color);
            color: var(--text-primary);
            padding: 0.5rem;
            border-radius: 0.5rem;
            cursor: pointer;
            transition: all var(--animation-duration) ease;
            display: flex;
            align-items: center;
            justify-content: center;
            width: 40px;
            height: 40px;
            position: relative;
        }

        .btn-control:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateY(-2px);
        }

        .nav-progress {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: rgba(255, 255, 255, 0.1);
        }

        .progress-bar {
            height: 100%;
            background: var(--primary-gradient);
            width: 0%;
            transition: width 0.3s ease;
        }

        /* ===== 难度选择器 ===== */
        .difficulty-selector {
            position: fixed;
            right: 20px;
            top: 80px;
            background: var(--bg-section);
            border: 1px solid var(--border-color);
            border-radius: 0.5rem;
            padding: 1rem;
            z-index: 999;
            box-shadow: var(--shadow-lg);
        }

        .difficulty-selector h4 {
            color: var(--accent-purple);
            margin-bottom: 0.5rem;
            font-size: 0.875rem;
        }

        .difficulty-option {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem;
            cursor: pointer;
            border-radius: 0.25rem;
            transition: all 0.2s ease;
        }

        .difficulty-option:hover {
            background: rgba(255, 255, 255, 0.05);
        }

        .difficulty-option.active {
            background: rgba(139, 92, 246, 0.2);
            color: var(--accent-purple);
        }

        .difficulty-option input[type="radio"] {
            display: none;
        }

        /* ===== 侧边导航 ===== */
        .sidebar {
            position: fixed;
            left: -300px;
            top: 60px;
            bottom: 0;
            width: 300px;
            background: var(--bg-section);
            border-right: 1px solid var(--border-color);
            padding: 2rem;
            overflow-y: auto;
            transition: transform 0.3s ease;
            z-index: 999;
        }

        .sidebar.open {
            transform: translateX(300px);
        }

        .sidebar-overlay {
            position: fixed;
            inset: 0;
            background: rgba(0, 0, 0, 0.5);
            display: none;
            z-index: 998;
        }

        .sidebar-overlay.active {
            display: block;
        }

        .toc-item {
            display: block;
            padding: 0.75rem 1rem;
            color: var(--text-secondary);
            text-decoration: none;
            border-radius: 0.5rem;
            transition: all var(--animation-duration) ease;
            margin-bottom: 0.25rem;
        }

        .toc-item:hover {
            background: rgba(255, 255, 255, 0.05);
            color: var(--text-primary);
            transform: translateX(4px);
        }

        .toc-item.active {
            background: var(--primary-gradient);
            color: white;
        }

        /* ===== 学习伙伴系统 ===== */
        .learning-buddy {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 300px;
            background: var(--bg-section);
            border: 2px solid var(--accent-purple);
            border-radius: 1rem;
            padding: 1.5rem;
            box-shadow: var(--shadow-lg);
            z-index: 900;
            transform: translateY(400px);
            transition: transform 0.5s ease;
        }

        .learning-buddy.active {
            transform: translateY(0);
        }

        .learning-buddy.minimized {
            width: auto;
            padding: 0;
            border-radius: 50%;
            overflow: hidden;
        }

        .learning-buddy.minimized .buddy-content {
            display: none;
        }

        .learning-buddy.minimized .buddy-avatar {
            margin: 0;
            cursor: pointer;
        }

        .buddy-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 1rem;
        }

        .buddy-avatar {
            width: 60px;
            height: 60px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2rem;
            flex-shrink: 0;
        }

        .buddy-controls {
            display: flex;
            gap: 0.5rem;
        }

        .buddy-control-btn {
            width: 30px;
            height: 30px;
            border-radius: 50%;
            border: 1px solid var(--border-color);
            background: transparent;
            color: var(--text-primary);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s ease;
        }

        .buddy-control-btn:hover {
            background: rgba(255, 255, 255, 0.1);
        }

        .buddy-message {
            background: rgba(139, 92, 246, 0.1);
            padding: 1rem;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
            position: relative;
        }

        .buddy-message::before {
            content: '';
            position: absolute;
            top: -8px;
            left: 20px;
            width: 0;
            height: 0;
            border-left: 8px solid transparent;
            border-right: 8px solid transparent;
            border-bottom: 8px solid rgba(139, 92, 246, 0.1);
        }

        /* ===== 主内容区 ===== */
        main {
            margin-top: 80px;
            padding-bottom: 4rem;
        }

        /* ===== 章节卡片 ===== */
        .chapter-hero {
            background: var(--primary-gradient);
            padding: 4rem 0;
            margin-bottom: 3rem;
            position: relative;
            overflow: hidden;
        }

        .chapter-hero::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255, 255, 255, 0.1) 0%, transparent 70%);
            animation: pulse 10s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1) rotate(0deg); }
            50% { transform: scale(1.1) rotate(180deg); }
        }

        .chapter-hero-content {
            position: relative;
            z-index: 2;
            text-align: center;
            color: white;
        }

        .chapter-hero h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            animation: fadeInUp 0.8s ease;
        }

        .chapter-hero p {
            font-size: 1.25rem;
            opacity: 0.9;
            max-width: 600px;
            margin: 0 auto;
            animation: fadeInUp 0.8s ease 0.2s both;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* ===== 内容区块 ===== */
        .section-card {
            background: var(--bg-section);
            border-radius: 1rem;
            padding: 2.5rem;
            margin-bottom: 2rem;
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-lg);
            transition: transform var(--animation-duration) ease;
            scroll-margin-top: 100px;
        }

        .section-card:hover {
            transform: translateY(-2px);
        }

        /* ===== 学习循环指示器 ===== */
        .learning-loop {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 2rem;
            margin-bottom: 3rem;
            padding: 1.5rem;
            background: rgba(139, 92, 246, 0.1);
            border-radius: 1rem;
            border: 1px solid rgba(139, 92, 246, 0.3);
        }

        .loop-step {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.5rem;
            padding: 1rem;
            border-radius: 0.5rem;
            transition: all var(--animation-duration) ease;
            position: relative;
        }

        .loop-step.active {
            background: rgba(139, 92, 246, 0.2);
            transform: scale(1.1);
        }

        .loop-step .icon {
            font-size: 2rem;
        }

        .loop-step .label {
            font-size: 0.875rem;
            color: var(--text-secondary);
        }

        .loop-connector {
            position: absolute;
            top: 50%;
            right: -2rem;
            width: 2rem;
            height: 2px;
            background: rgba(139, 92, 246, 0.3);
        }

        /* ===== 故事卡片 ===== */
        .story-card {
            background: linear-gradient(135deg, rgba(251, 191, 36, 0.15), rgba(245, 158, 11, 0.1));
            border-radius: 1rem;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 2px solid rgba(251, 191, 36, 0.2);
            position: relative;
            overflow: hidden;
        }

        .story-card::before {
            content: '🌙';
            position: absolute;
            top: -20px;
            right: -20px;
            font-size: 5rem;
            opacity: 0.1;
            transform: rotate(15deg);
        }

        /* ===== 人物对话 ===== */
        .dialogue-container {
            margin: 2rem 0;
            padding: 1.5rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 0.75rem;
        }

        .dialogue-item {
            display: flex;
            gap: 1rem;
            margin-bottom: 1.5rem;
            animation: slideIn 0.5s ease;
        }

        .dialogue-avatar {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            flex-shrink: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5rem;
        }

        .dialogue-avatar.student {
            background: linear-gradient(135deg, #fbbf24, #f59e0b);
        }

        .dialogue-avatar.teacher {
            background: linear-gradient(135deg, #06b6d4, #0891b2);
        }

        .dialogue-avatar.friend {
            background: linear-gradient(135deg, #22c55e, #16a34a);
        }

        .dialogue-content {
            flex: 1;
            background: rgba(255, 255, 255, 0.05);
            padding: 1rem;
            border-radius: 0.5rem;
            position: relative;
        }

        .dialogue-content::before {
            content: '';
            position: absolute;
            left: -8px;
            top: 15px;
            width: 0;
            height: 0;
            border-top: 8px solid transparent;
            border-bottom: 8px solid transparent;
            border-right: 8px solid rgba(255, 255, 255, 0.05);
        }

        .dialogue-name {
            font-weight: bold;
            color: var(--accent-purple);
            margin-bottom: 0.25rem;
        }

        /* ===== 概念卡片网格 ===== */
        .concept-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .concept-card {
            padding: 1.5rem;
            border-radius: 0.75rem;
            transition: all var(--animation-duration) ease;
            cursor: pointer;
            position: relative;
            overflow: hidden;
        }

        .concept-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: var(--primary-gradient);
            transform: scaleX(0);
            transition: transform var(--animation-duration) ease;
        }

        .concept-card:hover::before {
            transform: scaleX(1);
        }

        .concept-card.why {
            background: rgba(239, 68, 68, 0.1);
            border: 1px solid rgba(239, 68, 68, 0.3);
        }

        .concept-card.what {
            background: rgba(34, 197, 94, 0.1);
            border: 1px solid rgba(34, 197, 94, 0.3);
        }

        .concept-card.how {
            background: rgba(6, 182, 212, 0.1);
            border: 1px solid rgba(6, 182, 212, 0.3);
        }

        .concept-card.pitfall {
            background: rgba(251, 191, 36, 0.1);
            border: 1px solid rgba(251, 191, 36, 0.3);
        }

        /* ===== 数学推导容器 ===== */
        .math-derivation {
            background: rgba(79, 70, 229, 0.05);
            border: 1px solid rgba(79, 70, 229, 0.3);
            border-radius: 1rem;
            padding: 2rem;
            margin: 2rem 0;
        }

        .math-step {
            margin: 1.5rem 0;
            padding-left: 2rem;
            position: relative;
        }

        .math-step::before {
            content: attr(data-step);
            position: absolute;
            left: 0;
            top: 0;
            width: 24px;
            height: 24px;
            background: var(--accent-purple);
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.875rem;
            font-weight: bold;
        }

        .math-explanation {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 0.5rem;
            padding: 1rem;
            margin-top: 0.5rem;
            font-size: 0.95rem;
            color: var(--text-secondary);
        }

        /* ===== 交互式可视化 ===== */
        .interactive-demo {
            background: rgba(15, 23, 42, 0.8);
            border: 1px solid var(--border-color);
            border-radius: 1rem;
            padding: 2rem;
            margin: 2rem 0;
            position: relative;
        }

        .demo-controls {
            display: flex;
            gap: 2rem;
            align-items: center;
            margin-bottom: 1.5rem;
            flex-wrap: wrap;
        }

        .control-group {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
        }

        .control-group label {
            font-size: 0.875rem;
            color: var(--text-secondary);
        }

        .slider-container {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        input[type="range"] {
            width: 150px;
            height: 6px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 3px;
            outline: none;
            -webkit-appearance: none;
            cursor: pointer;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 18px;
            height: 18px;
            background: var(--primary-gradient);
            border-radius: 50%;
            cursor: pointer;
            transition: transform 0.2s ease;
        }

        input[type="range"]::-webkit-slider-thumb:hover {
            transform: scale(1.2);
        }

        .slider-value {
            background: rgba(255, 255, 255, 0.1);
            padding: 0.25rem 0.75rem;
            border-radius: 0.5rem;
            font-family: monospace;
            min-width: 50px;
            text-align: center;
        }

        canvas {
            display: block;
            margin: 0 auto;
            border-radius: 0.5rem;
            background: rgba(0, 0, 0, 0.2);
            cursor: crosshair;
        }

        /* ===== 即时练习 ===== */
        .instant-practice {
            background: rgba(34, 197, 94, 0.1);
            border: 1px solid rgba(34, 197, 94, 0.3);
            border-radius: 1rem;
            padding: 2rem;
            margin: 2rem 0;
        }

        .practice-question {
            font-size: 1.1rem;
            margin-bottom: 1.5rem;
            font-weight: 500;
        }

        .practice-options {
            display: grid;
            gap: 1rem;
        }

        .practice-option {
            background: rgba(255, 255, 255, 0.05);
            border: 2px solid transparent;
            border-radius: 0.5rem;
            padding: 1rem 1.5rem;
            cursor: pointer;
            transition: all var(--animation-duration) ease;
            position: relative;
            overflow: hidden;
            text-align: left;
            width: 100%;
        }

        .practice-option:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateX(4px);
        }

        .practice-option.selected {
            border-color: var(--accent-blue);
        }

        .practice-option.correct {
            background: rgba(34, 197, 94, 0.2);
            border-color: var(--accent-green);
        }

        .practice-option.incorrect {
            background: rgba(239, 68, 68, 0.2);
            border-color: var(--accent-red);
        }

        .practice-feedback {
            margin-top: 1.5rem;
            padding: 1rem;
            border-radius: 0.5rem;
            display: none;
            animation: fadeIn 0.3s ease;
        }

        .practice-feedback.show {
            display: block;
        }

        .practice-feedback.correct {
            background: rgba(34, 197, 94, 0.2);
            border: 1px solid rgba(34, 197, 94, 0.3);
            color: var(--accent-green);
        }

        .practice-feedback.incorrect {
            background: rgba(239, 68, 68, 0.2);
            border: 1px solid rgba(239, 68, 68, 0.3);
            color: var(--accent-red);
        }

        /* ===== 常见错误专栏 ===== */
        .common-mistakes {
            background: rgba(239, 68, 68, 0.1);
            border: 2px solid rgba(239, 68, 68, 0.3);
            border-radius: 1rem;
            padding: 2rem;
            margin: 2rem 0;
        }

        .mistake-item {
            display: flex;
            gap: 1rem;
            margin-bottom: 1.5rem;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 0.5rem;
        }

        .mistake-icon {
            font-size: 2rem;
            flex-shrink: 0;
        }

        .mistake-content h4 {
            color: var(--accent-red);
            margin-bottom: 0.5rem;
        }

        /* ===== 代码容器 ===== */
        .code-container {
            margin: 2rem 0;
            border-radius: 0.75rem;
            overflow: hidden;
            box-shadow: var(--shadow-lg);
        }

        .code-header {
            background: #1a1a2e;
            padding: 1rem 1.5rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .code-header-left {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .code-header-right {
            display: flex;
            gap: 0.5rem;
        }

        .code-tab {
            padding: 0.5rem 1rem;
            background: transparent;
            border: none;
            color: var(--text-secondary);
            cursor: pointer;
            border-radius: 0.5rem;
            transition: all var(--animation-duration) ease;
        }

        .code-tab.active {
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-primary);
        }

        .code-action {
            padding: 0.5rem 1rem;
            background: transparent;
            border: 1px solid var(--border-color);
            color: var(--text-primary);
            cursor: pointer;
            border-radius: 0.5rem;
            transition: all var(--animation-duration) ease;
            font-size: 0.875rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .code-action:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateY(-1px);
        }

        .code-content {
            background: #0d1117;
            overflow-x: auto;
        }

        .code-content pre {
            margin: 0;
            padding: 1.5rem;
        }

        .code-content code {
            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Code', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        .code-output {
            background: rgba(34, 197, 94, 0.1);
            border: 1px solid rgba(34, 197, 94, 0.3);
            border-radius: 0.5rem;
            padding: 1rem;
            margin-top: 1rem;
            font-family: monospace;
            font-size: 0.875rem;
            display: none;
        }

        .code-output.show {
            display: block;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* ===== 学习路径推荐 ===== */
        .learning-path {
            background: linear-gradient(135deg, rgba(139, 92, 246, 0.1), rgba(236, 72, 153, 0.1));
            border: 2px solid rgba(139, 92, 246, 0.3);
            border-radius: 1rem;
            padding: 2rem;
            margin: 2rem 0;
        }

        .path-item {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 1rem;
            margin: 0.5rem 0;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 0.5rem;
            transition: all var(--animation-duration) ease;
            cursor: pointer;
        }

        .path-item:hover {
            background: rgba(255, 255, 255, 0.08);
            transform: translateX(4px);
        }

        .path-item.completed {
            opacity: 0.6;
        }

        .path-item.current {
            border: 2px solid var(--accent-purple);
            background: rgba(139, 92, 246, 0.1);
        }

        .path-icon {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: var(--primary-gradient);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.2rem;
            color: white;
        }

        .path-content h4 {
            color: var(--accent-purple);
            margin-bottom: 0.25rem;
        }

        .path-content p {
            font-size: 0.875rem;
            color: var(--text-secondary);
        }

        /* ===== 提示框 ===== */
        .tip {
            display: flex;
            gap: 1rem;
            padding: 1.5rem;
            border-radius: 0.75rem;
            margin: 1.5rem 0;
        }

        .tip-icon {
            font-size: 1.5rem;
            flex-shrink: 0;
        }

        .tip-content {
            flex: 1;
        }

        .tip.info {
            background: rgba(6, 182, 212, 0.1);
            border: 1px solid rgba(6, 182, 212, 0.3);
        }

        .tip.warning {
            background: rgba(251, 191, 36, 0.1);
            border: 1px solid rgba(251, 191, 36, 0.3);
        }

        .tip.error {
            background: rgba(239, 68, 68, 0.1);
            border: 1px solid rgba(239, 68, 68, 0.3);
        }

        .tip.success {
            background: rgba(34, 197, 94, 0.1);
            border: 1px solid rgba(34, 197, 94, 0.3);
        }

        /* ===== 深度指示器 ===== */
        .depth-indicator {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.25rem 0.75rem;
            background: rgba(139, 92, 246, 0.1);
            border: 1px solid rgba(139, 92, 246, 0.3);
            border-radius: 20px;
            font-size: 0.875rem;
            margin-left: 1rem;
        }

        .depth-indicator.beginner {
            background: rgba(34, 197, 94, 0.1);
            border-color: rgba(34, 197, 94, 0.3);
            color: var(--accent-green);
        }

        .depth-indicator.intermediate {
            background: rgba(251, 191, 36, 0.1);
            border-color: rgba(251, 191, 36, 0.3);
            color: var(--accent-yellow);
        }

        .depth-indicator.advanced {
            background: rgba(239, 68, 68, 0.1);
            border-color: rgba(239, 68, 68, 0.3);
            color: var(--accent-red);
        }

        /* ===== 可折叠内容 ===== */
        .collapsible {
            margin: 1.5rem 0;
            border: 1px solid var(--border-color);
            border-radius: 0.75rem;
            overflow: hidden;
        }

        .collapsible-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 1.25rem 1.5rem;
            background: rgba(255, 255, 255, 0.05);
            cursor: pointer;
            transition: background var(--animation-duration) ease;
            user-select: none;
        }

        .collapsible-header:hover {
            background: rgba(255, 255, 255, 0.08);
        }

        .collapsible-title {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            font-weight: 500;
        }

        .collapsible-icon {
            transition: transform var(--animation-duration) ease;
        }

        .collapsible.expanded .collapsible-icon {
            transform: rotate(180deg);
        }

        .collapsible-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height var(--animation-duration) ease;
        }

        .collapsible.expanded .collapsible-content {
            max-height: 2000px;
        }

        .collapsible-inner {
            padding: 1.5rem;
        }

        /* ===== 按钮样式 ===== */
        .btn {
            padding: 0.75rem 1.5rem;
            border-radius: 0.5rem;
            border: none;
            font-weight: 500;
            cursor: pointer;
            transition: all var(--animation-duration) ease;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            text-decoration: none;
        }

        .btn-primary {
            background: var(--primary-gradient);
            color: white;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.3);
        }

        .btn-secondary {
            background: transparent;
            color: var(--text-primary);
            border: 1px solid var(--border-color);
        }

        .btn-secondary:hover {
            background: rgba(255, 255, 255, 0.1);
        }

        /* ===== 学习成就系统 ===== */
        .achievement-popup {
            position: fixed;
            top: 100px;
            right: -400px;
            width: 350px;
            background: var(--bg-section);
            border: 2px solid var(--accent-yellow);
            border-radius: 1rem;
            padding: 1.5rem;
            box-shadow: var(--shadow-lg);
            z-index: 1000;
            transition: right 0.5s ease;
        }

        .achievement-popup.show {
            right: 20px;
        }

        .achievement-header {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-bottom: 1rem;
        }

        .achievement-icon {
            width: 60px;
            height: 60px;
            background: var(--accent-yellow);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2rem;
        }

        .achievement-content h3 {
            color: var(--accent-yellow);
            margin-bottom: 0.25rem;
        }

        /* ===== 通知样式 ===== */
        .notification {
            position: fixed;
            top: 80px;
            right: 20px;
            background: var(--accent-green);
            color: white;
            padding: 1rem 1.5rem;
            border-radius: 0.5rem;
            z-index: 1000;
            animation: slideInRight 0.3s ease;
            box-shadow: var(--shadow-lg);
        }

        @keyframes slideInRight {
            from {
                transform: translateX(100%);
                opacity: 0;
            }
            to {
                transform: translateX(0);
                opacity: 1;
            }
        }

        /* ===== 响应式设计 ===== */
        @media (max-width: 1024px) {
            .chapter-hero h1 {
                font-size: 2.5rem;
            }

            .concept-grid {
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            }

            .difficulty-selector {
                top: auto;
                bottom: 80px;
            }
        }

        @media (max-width: 768px) {
            .nav-title h1 {
                font-size: 1rem;
            }

            .section-card {
                padding: 1.5rem;
            }

            .chapter-hero {
                padding: 3rem 0;
            }

            .chapter-hero h1 {
                font-size: 2rem;
            }

            .chapter-hero p {
                font-size: 1rem;
            }

            .learning-loop {
                flex-direction: column;
                gap: 1rem;
            }

            .loop-connector {
                display: none;
            }

            .demo-controls {
                flex-direction: column;
                align-items: stretch;
            }

            input[type="range"] {
                width: 100%;
            }

            .learning-buddy {
                width: 90%;
                left: 5%;
                right: 5%;
            }
        }

        /* ===== 打印样式 ===== */
        @media print {
            .nav-header,
            .sidebar,
            .btn,
            .demo-controls,
            .code-action,
            .difficulty-selector,
            .learning-buddy {
                display: none;
            }

            .section-card {
                page-break-inside: avoid;
                box-shadow: none;
                border: 1px solid #ddd;
            }

            body {
                background: white;
                color: black;
            }
        }

        /* ===== 动画优化 ===== */
        @media (prefers-reduced-motion: reduce) {
            *,
            *::before,
            *::after {
                animation-duration: 0.01ms !important;
                animation-iteration-count: 1 !important;
                transition-duration: 0.01ms !important;
            }
        }

        /* ===== 工具类 ===== */
        .visually-hidden {
            position: absolute;
            width: 1px;
            height: 1px;
            padding: 0;
            margin: -1px;
            overflow: hidden;
            clip: rect(0, 0, 0, 0);
            white-space: nowrap;
            border: 0;
        }

        .text-center {
            text-align: center;
        }

        .mt-1 { margin-top: 0.5rem; }
        .mt-2 { margin-top: 1rem; }
        .mt-3 { margin-top: 1.5rem; }
        .mt-4 { margin-top: 2rem; }

        .mb-1 { margin-bottom: 0.5rem; }
        .mb-2 { margin-bottom: 1rem; }
        .mb-3 { margin-bottom: 1.5rem; }
        .mb-4 { margin-bottom: 2rem; }

        /* ===== 加载动画 ===== */
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: var(--accent-purple);
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        /* ===== 梯度流动画 ===== */
        .gradient-flow {
            position: relative;
            overflow: hidden;
        }

        .gradient-flow::after {
            content: '';
            position: absolute;
            top: -100%;
            left: -100%;
            right: -100%;
            bottom: -100%;
            background: linear-gradient(
                    45deg,
                    transparent 30%,
                    rgba(139, 92, 246, 0.2) 50%,
                    transparent 70%
            );
            animation: gradientFlow 3s linear infinite;
        }

        @keyframes gradientFlow {
            0% {
                transform: translateX(-100%) translateY(-100%);
            }
            100% {
                transform: translateX(100%) translateY(100%);
            }
        }

        /* ===== 神经网络节点样式 ===== */
        .neuron {
            fill: var(--accent-purple);
            stroke: var(--text-primary);
            stroke-width: 2;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .neuron:hover {
            fill: var(--accent-pink);
            transform: scale(1.1);
        }

        .neuron.active {
            fill: var(--accent-green);
            animation: pulse 1s ease-in-out infinite;
        }

        .synapse {
            stroke: var(--text-secondary);
            stroke-width: 1.5;
            fill: none;
            opacity: 0.6;
            transition: all 0.3s ease;
        }

        .synapse.active {
            stroke: var(--accent-yellow);
            stroke-width: 3;
            opacity: 1;
            animation: synapseFlow 1s linear infinite;
        }

        @keyframes synapseFlow {
            0% {
                stroke-dasharray: 0 100;
            }
            100% {
                stroke-dasharray: 100 0;
            }
        }

        /* ===== 手写效果 ===== */
        .handwritten {
            font-family: 'Kalam', cursive;
            color: var(--accent-yellow);
            transform: rotate(-2deg);
            display: inline-block;
        }

        /* ===== 数学公式容器 ===== */
        .equation-container {
            background: rgba(139, 92, 246, 0.05);
            border: 1px solid rgba(139, 92, 246, 0.2);
            border-radius: 0.5rem;
            padding: 1.5rem;
            margin: 1rem 0;
            text-align: center;
            font-size: 1.1rem;
            overflow-x: auto;
        }

        .equation-label {
            display: inline-block;
            background: var(--accent-purple);
            color: white;
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            font-size: 0.875rem;
            margin-bottom: 0.5rem;
        }
    </style>
</head>
<body>
<!-- 导航栏 -->
<nav class="nav-header" role="navigation" aria-label="主导航">
    <div class="container">
        <div class="nav-content">
            <div class="nav-title">
                <button id="toggle-sidebar" class="btn-control" aria-label="切换侧边栏" tabindex="0">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <line x1="3" y1="12" x2="21" y2="12"></line>
                        <line x1="3" y1="6" x2="21" y2="6"></line>
                        <line x1="3" y1="18" x2="21" y2="18"></line>
                    </svg>
                </button>
                <h1>第2章：误差反向传播</h1>
            </div>
            <div class="nav-controls">
                <button id="toggle-buddy" class="btn-control" aria-label="学习伙伴" tabindex="0">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
                        <circle cx="12" cy="7" r="4"></circle>
                    </svg>
                </button>
                <button id="toggle-theme" class="btn-control" aria-label="切换主题" tabindex="0">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                    </svg>
                </button>
            </div>
        </div>
        <div class="nav-progress">
            <div class="progress-bar" id="progress-bar"></div>
        </div>
    </div>
</nav>

<!-- 难度选择器 -->
<div class="difficulty-selector">
    <h4>选择学习深度</h4>
    <label class="difficulty-option active" tabindex="0">
        <input type="radio" name="difficulty" value="beginner" checked>
        <span>🌱 初学者</span>
    </label>
    <label class="difficulty-option" tabindex="0">
        <input type="radio" name="difficulty" value="intermediate">
        <span>🌿 进阶</span>
    </label>
    <label class="difficulty-option" tabindex="0">
        <input type="radio" name="difficulty" value="advanced">
        <span>🌳 深入</span>
    </label>
</div>

<!-- 侧边栏 -->
<aside class="sidebar" id="sidebar" role="navigation" aria-label="章节导航">
    <h3 style="margin-bottom: 1.5rem; color: var(--accent-purple);">目录导航</h3>
    <nav>
        <a href="#intro" class="toc-item active" tabindex="0">引言：深夜的手算噩梦</a>
        <a href="#problem" class="toc-item" tabindex="0">发现问题：手推梯度的痛苦</a>
        <a href="#history" class="toc-item" tabindex="0">历史回顾：从冷落到辉煌</a>
        <a href="#chain-rule" class="toc-item" tabindex="0">链式法则：微积分的魔法</a>
        <a href="#algorithm" class="toc-item" tabindex="0">BP算法：误差的反向流动</a>
        <a href="#implementation" class="toc-item" tabindex="0">代码实现：从手写到自动</a>
        <a href="#visualization" class="toc-item" tabindex="0">梯度可视化：看见信息流</a>
        <a href="#experiment" class="toc-item" tabindex="0">实战：MNIST手写数字识别</a>
        <a href="#problems" class="toc-item" tabindex="0">常见问题：梯度消失与爆炸</a>
        <a href="#biological" class="toc-item" tabindex="0">生物学视角：大脑如何学习</a>
        <a href="#alternatives" class="toc-item" tabindex="0">替代方案：超越BP</a>
        <a href="#summary" class="toc-item" tabindex="0">总结：深度学习的引擎</a>
    </nav>
</aside>

<!-- 侧边栏遮罩 -->
<div class="sidebar-overlay" id="sidebar-overlay"></div>

<!-- 学习伙伴系统 -->
<div class="learning-buddy" id="learning-buddy">
    <div class="buddy-header">
        <div class="buddy-avatar" id="buddy-avatar">🤖</div>
        <div class="buddy-controls">
            <button class="buddy-control-btn" id="minimize-buddy" aria-label="最小化" tabindex="0">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <line x1="5" y1="12" x2="19" y2="12"></line>
                </svg>
            </button>
            <button class="buddy-control-btn" id="close-buddy" aria-label="关闭" tabindex="0">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <line x1="18" y1="6" x2="6" y2="18"></line>
                    <line x1="6" y1="6" x2="18" y2="18"></line>
                </svg>
            </button>
        </div>
    </div>
    <div class="buddy-content">
        <div class="buddy-message">
            <p>嗨！我是小智。反向传播是深度学习的核心，让我们一起征服它！记住：梯度就像水流，总是沿着最陡的方向流动。</p>
        </div>
        <div style="display: flex; gap: 0.5rem; margin-top: 1rem;">
            <button class="btn btn-secondary" onclick="getBuddyHint()" tabindex="0">给我提示</button>
            <button class="btn btn-secondary" onclick="getBuddySummary()" tabindex="0">总结要点</button>
        </div>
    </div>
</div>

<!-- 成就弹窗 -->
<div class="achievement-popup" id="achievement-popup">
    <div class="achievement-header">
        <div class="achievement-icon">🏆</div>
        <div class="achievement-content">
            <h3>解锁成就！</h3>
            <p id="achievement-text">完成第一个梯度计算</p>
        </div>
    </div>
    <div class="progress" style="margin-top: 1rem;">
        <div style="height: 8px; background: rgba(255, 255, 255, 0.1); border-radius: 4px;">
            <div id="achievement-progress" style="height: 100%; width: 20%; background: var(--accent-yellow); border-radius: 4px;"></div>
        </div>
        <p style="font-size: 0.875rem; color: var(--text-secondary); margin-top: 0.5rem;">
            <span id="achievement-count">1</span>/5 完成本章学习
        </p>
    </div>
</div>

<!-- 主内容 -->
<main>
    <!-- 章节标题 -->
    <section class="chapter-hero">
        <div class="container">
            <div class="chapter-hero-content">
                <h1>误差反向传播：深度网络的血脉</h1>
                <p>从手推梯度到自动微分 —— 让机器学会"责任分摊"的艺术</p>
                <div class="mt-4">
                    <span style="background: rgba(255, 255, 255, 0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem;">
                        ⚡ 核心算法
                    </span>
                    <span style="background: rgba(255, 255, 255, 0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem;">
                        ⏱️ 90分钟
                    </span>
                    <span style="background: rgba(255, 255, 255, 0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem;">
                        🎯 深度基石
                    </span>
                </div>
            </div>
        </div>
    </section>

    <div class="container">
        <!-- 学习目标 -->
        <section class="section-card">
            <h2 style="color: var(--accent-purple); margin-bottom: 1.5rem;">📚 本章学习目标</h2>
            <div class="concept-grid">
                <div class="concept-card what" tabindex="0">
                    <h3 style="color: var(--accent-green); margin-bottom: 0.5rem;">✓ 理解核心原理</h3>
                    <p>掌握链式法则和梯度反向传播的数学基础，理解误差如何逐层分配</p>
                </div>
                <div class="concept-card how" tabindex="0">
                    <h3 style="color: var(--accent-blue); margin-bottom: 0.5rem;">✓ 掌握实现技巧</h3>
                    <p>从手写BP到使用自动微分，对比不同实现方式的优劣</p>
                </div>
                <div class="concept-card why" tabindex="0">
                    <h3 style="color: var(--accent-red); margin-bottom: 0.5rem;">✓ 识别常见问题</h3>
                    <p>理解梯度消失/爆炸的根源，学会调试和监控梯度流</p>
                </div>
                <div class="concept-card pitfall" tabindex="0">
                    <h3 style="color: var(--accent-yellow); margin-bottom: 0.5rem;">✓ 拓展视野</h3>
                    <p>探索BP的生物学合理性和替代方案，理解深度学习的未来</p>
                </div>
            </div>
        </section>

        <!-- 学习路径推荐 -->
        <section class="learning-path">
            <h3 style="color: var(--accent-purple); margin-bottom: 1.5rem;">🗺️ 推荐学习路径</h3>
            <div class="path-item completed" tabindex="0">
                <div class="path-icon">✓</div>
                <div class="path-content">
                    <h4>上一章：感知机</h4>
                    <p>单层网络的局限性</p>
                </div>
            </div>
            <div class="path-item current" tabindex="0">
                <div class="path-icon">📍</div>
                <div class="path-content">
                    <h4>当前章节：反向传播</h4>
                    <p>深度网络训练的核心算法</p>
                </div>
            </div>
            <div class="path-item" tabindex="0">
                <div class="path-icon">🔜</div>
                <div class="path-content">
                    <h4>下一站：多层感知机</h4>
                    <p>表达力与激活函数</p>
                </div>
            </div>
        </section>

        <!-- 学习循环1：引言故事 -->
        <section id="intro" class="section-card">
            <div class="story-card">
                <h2 style="color: var(--accent-yellow); margin-bottom: 1.5rem;">🌙 凌晨3点14分，北航机房的崩溃时刻</h2>
                <!-- 场景设定 -->
                <div style="background: rgba(0, 0, 0, 0.2); padding: 1rem; border-radius: 0.5rem; margin-bottom: 2rem;">
                    <p style="font-style: italic; color: var(--text-secondary);">
                        小陈终于理解了多层网络的必要性，兴奋地搭建了一个三层神经网络。
                        然而，当他试图手动计算梯度时，噩梦开始了...
                    </p>
                </div>

                <!-- 对话场景 -->
                <div class="dialogue-container">
                    <div class="dialogue-item">
                        <div class="dialogue-avatar student">😭</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">小陈（抓狂中）</div>
                            <p>我已经算了3个小时了！这才第二层的梯度，还有十几个参数要算...</p>
                        </div>
                    </div>
                    <div class="dialogue-item">
                        <div class="dialogue-avatar friend">😴</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">室友小李（迷糊中）</div>
                            <p>你在干啥？不是有现成的框架吗？</p>
                        </div>
                    </div>
                    <div class="dialogue-item">
                        <div class="dialogue-avatar student">💢</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">小陈</div>
                            <p>老师说要理解原理！可这链式法则套链式法则，我都不知道自己算的对不对了...</p>
                        </div>
                    </div>
                </div>

                <!-- 手算展示 -->
                <div class="tip error mt-3">
                    <span class="tip-icon">📝</span>
                    <div class="tip-content">
                        <strong>小陈的草稿纸（第17页）：</strong><br>
                        <div style="font-family: 'Kalam', cursive; color: var(--accent-yellow); transform: rotate(-1deg); margin: 1rem 0;">
                            ∂L/∂w₁₁⁽²⁾ = ∂L/∂a⁽³⁾ · ∂a⁽³⁾/∂z⁽³⁾ · ∂z⁽³⁾/∂a₁⁽²⁾ · ∂a₁⁽²⁾/∂z₁⁽²⁾ · ∂z₁⁽²⁾/∂w₁₁⁽²⁾<br>
                            = δ⁽³⁾ · w₁⁽³⁾ · σ'(z₁⁽²⁾) · a₁⁽¹⁾<br>
                            = 0.73 × (-2.1) × 0.196 × 0.84 = ???
                        </div>
                        <span style="color: var(--accent-red);">错误累积：一个小数点错误，后面全完了...</span>
                    </div>
                </div>

                <!-- 转折点 -->
                <div class="dialogue-container mt-3">
                    <div class="dialogue-item">
                        <div class="dialogue-avatar teacher">👨‍🏫</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">王教授（突然出现）</div>
                            <p>小陈，还在手算梯度？你知道吗，1974年就有人想到了自动计算梯度的方法，
                                但直到1986年才被重新发现并推广...</p>
                        </div>
                    </div>
                    <div class="dialogue-item">
                        <div class="dialogue-avatar student">😲</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">小陈</div>
                            <p>自动计算？怎么可能！这么复杂的链式法则...</p>
                        </div>
                    </div>
                    <div class="dialogue-item">
                        <div class="dialogue-avatar teacher">👨‍🏫</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">王教授</div>
                            <p>这就是反向传播的美妙之处——<strong class="handwritten">误差像水流一样，从输出层反向流回每个参数</strong>。
                                让我给你演示一下...</p>
                        </div>
                    </div>
                </div>

                <!-- 关键洞察 -->
                <div class="tip success mt-3">
                    <span class="tip-icon">💡</span>
                    <div class="tip-content">
                        <strong>顿悟时刻：</strong><br>
                        反向传播的核心思想——<br>
                        1. <strong>前向计算</strong>：保存所有中间结果<br>
                        2. <strong>反向传播</strong>：利用链式法则，从后往前计算梯度<br>
                        3. <strong>责任分摊</strong>：每个参数根据其"贡献"承担相应的误差
                    </div>
                </div>
            </div>

            <!-- 即时练习 -->
            <div class="instant-practice">
                <h3 style="color: var(--accent-green); margin-bottom: 1rem;">🎯 思考练习</h3>
                <div class="practice-question">
                    手动计算梯度的主要问题是什么？
                </div>
                <div class="practice-options">
                    <button class="practice-option" data-answer="a" tabindex="0">
                        A. 计算量太小，不够精确
                    </button>
                    <button class="practice-option" data-answer="b" tabindex="0">
                        B. 容易出错且效率极低
                    </button>
                    <button class="practice-option" data-answer="c" tabindex="0">
                        C. 无法处理非线性函数
                    </button>
                    <button class="practice-option" data-answer="d" tabindex="0">
                        D. 需要高深的数学知识
                    </button>
                </div>
                <div class="practice-feedback" id="practice-feedback-1"></div>
            </div>
        </section>

        <!-- 学习循环2：发现问题 -->
        <section id="problem" class="section-card">

            <h2 style="color: var(--accent-red); margin-bottom: 1.5rem;">
                🎯 梯度计算的挑战：为什么手推不可持续
                <span class="depth-indicator beginner">初学者</span>
            </h2>

            <!-- 问题可视化 -->
            <div class="interactive-demo">
                <h3 style="color: var(--accent-blue); margin-bottom: 1.5rem;">📊 网络复杂度爆炸演示</h3>

                <div class="demo-controls">
                    <div class="control-group">
                        <label>网络层数</label>
                        <div class="slider-container">
                            <input type="range" id="layers-slider" min="2" max="10" step="1" value="3">
                            <span class="slider-value" id="layers-value">3</span>
                        </div>
                    </div>
                    <div class="control-group">
                        <label>每层神经元数</label>
                        <div class="slider-container">
                            <input type="range" id="neurons-slider" min="2" max="20" step="2" value="4">
                            <span class="slider-value" id="neurons-value">4</span>
                        </div>
                    </div>
                </div>

                <canvas id="network-complexity-canvas" width="800" height="400"></canvas>

                <div style="margin-top: 1rem; display: grid; grid-template-columns: repeat(3, 1fr); gap: 1rem; text-align: center;">
                    <div style="background: rgba(239, 68, 68, 0.1); padding: 1rem; border-radius: 0.5rem;">
                        <h4 style="color: var(--accent-red);">参数数量</h4>
                        <p style="font-size: 2rem; font-weight: bold;" id="param-count">20</p>
                    </div>
                    <div style="background: rgba(251, 191, 36, 0.1); padding: 1rem; border-radius: 0.5rem;">
                        <h4 style="color: var(--accent-yellow);">梯度计算次数</h4>
                        <p style="font-size: 2rem; font-weight: bold;" id="gradient-count">60</p>
                    </div>
                    <div style="background: rgba(34, 197, 94, 0.1); padding: 1rem; border-radius: 0.5rem;">
                        <h4 style="color: var(--accent-green);">手算时间（估计）</h4>
                        <p style="font-size: 2rem; font-weight: bold;" id="time-estimate">30分钟</p>
                    </div>
                </div>
            </div>

            <!-- 手算错误统计 -->
            <div class="common-mistakes mt-4">
                <h3 style="color: var(--accent-red); margin-bottom: 1rem;">📊 手算梯度常见错误统计</h3>

                <div style="background: rgba(0, 0, 0, 0.2); padding: 1.5rem; border-radius: 0.5rem;">
                    <p style="margin-bottom: 1rem;">根据对100名学生的统计：</p>

                    <div style="display: grid; gap: 0.5rem;">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <div style="width: 200px; background: var(--accent-red); height: 20px; border-radius: 10px;"></div>
                            <span>87% - 链式法则应用错误</span>
                        </div>
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <div style="width: 180px; background: var(--accent-yellow); height: 20px; border-radius: 10px;"></div>
                            <span>79% - 矩阵维度不匹配</span>
                        </div>
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <div style="width: 150px; background: var(--accent-blue); height: 20px; border-radius: 10px;"></div>
                            <span>65% - 激活函数导数错误</span>
                        </div>
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <div style="width: 120px; background: var(--accent-green); height: 20px; border-radius: 10px;"></div>
                            <span>52% - 数值计算错误</span>
                        </div>
                    </div>

                    <p style="margin-top: 1rem; color: var(--accent-purple);">
                        <strong>平均每个学生在3层网络上花费4.5小时，正确率仅23%</strong>
                    </p>
                </div>
            </div>

            <!-- 深入理解 -->
            <div class="collapsible mt-4 beginner-content">
                <div class="collapsible-header" tabindex="0">
                    <div class="collapsible-title">
                        <span>🤔</span>
                        <span>深入理解：为什么需要自动化？</span>
                        <span class="depth-indicator beginner">初学者</span>
                    </div>
                    <svg class="collapsible-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polyline points="6 9 12 15 18 9"></polyline>
                    </svg>
                </div>
                <div class="collapsible-content">
                    <div class="collapsible-inner">
                        <h4>手动计算的致命缺陷：</h4>
                        <ol style="line-height: 2; margin-top: 1rem;">
                            <li><strong>组合爆炸</strong>：10层网络可能有上百万参数</li>
                            <li><strong>错误传播</strong>：一个错误导致后续全错</li>
                            <li><strong>无法调试</strong>：很难定位错误在哪</li>
                            <li><strong>更新困难</strong>：改变网络结构需要重新推导</li>
                        </ol>

                        <div style="background: rgba(139, 92, 246, 0.1); padding: 1rem; border-radius: 0.5rem; margin-top: 1rem;">
                            <strong>解决方案：</strong><br>
                            让计算机按照固定的规则自动计算梯度 —— 这就是反向传播算法！
                        </div>
                    </div>
                </div>
            </div>

            <!-- 即时练习 -->
            <div class="instant-practice">
                <h3 style="color: var(--accent-green); margin-bottom: 1rem;">🎯 快速计算</h3>
                <div class="practice-question">
                    一个10层的全连接网络，每层100个神经元，大约有多少个参数？
                </div>
                <div class="practice-options">
                    <button class="practice-option" data-answer="a" tabindex="0">
                        A. 1,000个
                    </button>
                    <button class="practice-option" data-answer="b" tabindex="0">
                        B. 10,000个
                    </button>
                    <button class="practice-option" data-answer="c" tabindex="0">
                        C. 100,000个
                    </button>
                    <button class="practice-option" data-answer="d" tabindex="0">
                        D. 1,000,000个
                    </button>
                </div>
                <div class="practice-feedback" id="practice-feedback-2"></div>
            </div>
        </section>

        <!-- 历史回顾 -->
        <section id="history" class="section-card">
            <h2 style="color: var(--accent-yellow); margin-bottom: 1.5rem;">
                📚 历史回顾：反向传播的曲折发展
                <span class="depth-indicator beginner">初学者</span>
            </h2>

            <!-- 时间线 -->
            <div style="position: relative; padding: 2rem 0;">
                <div style="position: absolute; left: 50%; top: 0; bottom: 0; width: 2px; background: var(--accent-purple);"></div>

                <!-- 1960s：早期思想 -->
                <div style="display: flex; align-items: center; margin-bottom: 3rem;">
                    <div style="flex: 1; text-align: right; padding-right: 2rem;">
                        <h4 style="color: var(--accent-blue);">1960s：最早的思想萌芽</h4>
                        <p>Bryson & Ho 在控制论中提出类似思想</p>
                        <p style="font-style: italic; color: var(--text-secondary);">
                            "但无人将其应用于神经网络..."
                        </p>
                    </div>
                    <div style="width: 20px; height: 20px; background: var(--accent-blue); border-radius: 50%; position: relative; z-index: 1;"></div>
                    <div style="flex: 1; padding-left: 2rem;">
                        <div style="background: rgba(6, 182, 212, 0.1); padding: 1rem; border-radius: 0.5rem;">
                            💭 被忽视的珍珠：思想超前于时代
                        </div>
                    </div>
                </div>

                <!-- 1974年：Werbos -->
                <div style="display: flex; align-items: center; margin-bottom: 3rem;">
                    <div style="flex: 1; text-align: right; padding-right: 2rem;">
                        <div style="background: rgba(251, 191, 36, 0.1); padding: 1rem; border-radius: 0.5rem;">
                            📝 博士论文提出完整的BP算法
                        </div>
                    </div>
                    <div style="width: 20px; height: 20px; background: var(--accent-yellow); border-radius: 50%; position: relative; z-index: 1;"></div>
                    <div style="flex: 1; padding-left: 2rem;">
                        <h4 style="color: var(--accent-yellow);">1974年：Paul Werbos</h4>
                        <p>《Beyond Regression》</p>
                        <p style="font-style: italic; color: var(--text-secondary);">
                            "可惜发表在冷门期刊，无人问津..."
                        </p>
                    </div>
                </div>

                <!-- 1986年：重新发现 -->
                <div style="display: flex; align-items: center; margin-bottom: 3rem;">
                    <div style="flex: 1; text-align: right; padding-right: 2rem;">
                        <h4 style="color: var(--accent-green);">1986年：Rumelhart等人</h4>
                        <p>《Learning representations by back-propagating errors》</p>
                        <p style="font-style: italic; color: var(--text-secondary);">
                            "Nature期刊发表，轰动学界！"
                        </p>
                    </div>
                    <div style="width: 20px; height: 20px; background: var(--accent-green); border-radius: 50%; position: relative; z-index: 1;"></div>
                    <div style="flex: 1; padding-left: 2rem;">
                        <div style="background: rgba(34, 197, 94, 0.1); padding: 1rem; border-radius: 0.5rem;">
                            🎉 BP算法正式进入主流视野
                        </div>
                    </div>
                </div>

                <!-- 1989年：手写识别 -->
                <div style="display: flex; align-items: center; margin-bottom: 3rem;">
                    <div style="flex: 1; text-align: right; padding-right: 2rem;">
                        <div style="background: rgba(139, 92, 246, 0.1); padding: 1rem; border-radius: 0.5rem;">
                            ✍️ 首次大规模商业应用
                        </div>
                    </div>
                    <div style="width: 20px; height: 20px; background: var(--accent-purple); border-radius: 50%; position: relative; z-index: 1;"></div>
                    <div style="flex: 1; padding-left: 2rem;">
                        <h4 style="color: var(--accent-purple);">1989年：LeCun的LeNet</h4>
                        <p>银行支票识别系统</p>
                        <p style="font-style: italic; color: var(--text-secondary);">
                            "处理了美国10%的支票！"
                        </p>
                    </div>
                </div>

                <!-- 2010s：自动微分 -->
                <div style="display: flex; align-items: center;">
                    <div style="flex: 1; text-align: right; padding-right: 2rem;">
                        <h4 style="color: var(--accent-pink);">2010s：自动微分时代</h4>
                        <p>Theano → TensorFlow → PyTorch</p>
                        <p style="font-style: italic; color: var(--text-secondary);">
                            "define-by-run，梯度计算完全自动化"
                        </p>
                    </div>
                    <div style="width: 20px; height: 20px; background: var(--accent-pink); border-radius: 50%; position: relative; z-index: 1;"></div>
                    <div style="flex: 1; padding-left: 2rem;">
                        <div style="background: rgba(236, 72, 153, 0.1); padding: 1rem; border-radius: 0.5rem;">
                            🚀 深度学习的民主化时代来临
                        </div>
                    </div>
                </div>
            </div>

            <!-- 历史教训 -->
            <div class="tip info mt-4">
                <span class="tip-icon">📖</span>
                <div class="tip-content">
                    <strong>历史启示：</strong><br>
                    • 好的想法可能被埋没多年<br>
                    • 计算能力的提升让旧算法焕发新生<br>
                    • 工具的进步（自动微分）极大推动了领域发展<br>
                    • 从手算到自动化是必然趋势
                </div>
            </div>
        </section>

        <!-- 链式法则 -->
        <section id="chain-rule" class="section-card">
            <h2 style="color: var(--accent-purple); margin-bottom: 1.5rem;">
                ⛓️ 链式法则：微积分的优雅
                <span class="depth-indicator intermediate">进阶</span>
            </h2>

            <!-- 直观解释 -->
            <div class="story-card">
                <h3>🏭 链式法则的工厂比喻</h3>
                <div class="dialogue-container">
                    <div class="dialogue-item">
                        <div class="dialogue-avatar teacher">👨‍🏫</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">王教授</div>
                            <p>想象一个生产线：原料 → 加工 → 半成品 → 组装 → 成品</p>
                        </div>
                    </div>
                    <div class="dialogue-item">
                        <div class="dialogue-avatar student">🤔</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">小陈</div>
                            <p>如果最终产品有缺陷，怎么找出是哪个环节的问题？</p>
                        </div>
                    </div>
                    <div class="dialogue-item">
                        <div class="dialogue-avatar teacher">👨‍🏫</div>
                        <div class="dialogue-content">
                            <div class="dialogue-name">王教授</div>
                            <p>正是！链式法则就是<strong>逐层追溯责任</strong>的数学方法。
                                每个环节的"责任"等于它对下一环节的影响×下一环节的总责任。</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- 数学推导 -->
            <div class="math-derivation">
                <h3>链式法则的数学表达</h3>

                <div class="math-step" data-step="1">
                    <strong>一维情况</strong>
                    <p>设 y = f(g(x))，则：</p>
                    <div class="equation-container">
                        <span class="equation-label">基本链式法则</span><br>
                        <span style="font-size: 1.3rem;">
                            dy/dx = (dy/dg) · (dg/dx)
                        </span>
                    </div>
                </div>

                <div class="math-step" data-step="2">
                    <strong>多维情况（神经网络）</strong>
                    <p>对于 L = f⁽ⁿ⁾(f⁽ⁿ⁻¹⁾(...f⁽¹⁾(x)))：</p>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem;">
                            ∂L/∂W⁽ˡ⁾ = ∂L/∂z⁽ˡ⁺¹⁾ · ∂z⁽ˡ⁺¹⁾/∂a⁽ˡ⁾ · ∂a⁽ˡ⁾/∂z⁽ˡ⁾ · ∂z⁽ˡ⁾/∂W⁽ˡ⁾
                        </span>
                    </div>
                    <div class="math-explanation">
                        每一项都有明确的含义：<br>
                        • ∂L/∂z⁽ˡ⁺¹⁾：来自后层的误差信号<br>
                        • ∂z⁽ˡ⁺¹⁾/∂a⁽ˡ⁾：当前层的权重影响<br>
                        • ∂a⁽ˡ⁾/∂z⁽ˡ⁾：激活函数的局部梯度<br>
                        • ∂z⁽ˡ⁾/∂W⁽ˡ⁾：参数的直接影响
                    </div>
                </div>

                <div class="math-step" data-step="3">
                    <strong>矩阵形式（向量化）</strong>
                    <p>误差反向传播公式：</p>
                    <div class="equation-container">
                        <span class="equation-label">核心BP公式</span><br>
                        <span style="font-size: 1.3rem; color: var(--accent-purple);">
                            δ⁽ˡ⁾ = (W⁽ˡ⁺¹⁾ᵀ δ⁽ˡ⁺¹⁾) ⊙ σ'(z⁽ˡ⁾)
                        </span>
                    </div>
                    <div class="math-explanation">
                        • δ⁽ˡ⁾：第l层的误差项<br>
                        • W⁽ˡ⁺¹⁾ᵀ：后一层权重的转置<br>
                        • ⊙：逐元素乘法（Hadamard积）<br>
                        • σ'：激活函数的导数
                    </div>
                </div>
            </div>

            <!-- 交互式链式法则演示 -->
            <div class="interactive-demo mt-4">
                <h3 style="color: var(--accent-blue); margin-bottom: 1.5rem;">🔗 链式法则可视化</h3>

                <div class="demo-controls">
                    <button class="btn btn-primary" onclick="animateChainRule()" tabindex="0">
                        ▶️ 播放动画
                    </button>
                    <button class="btn btn-secondary" onclick="resetChainRule()" tabindex="0">
                        🔄 重置
                    </button>
                </div>

                <svg id="chain-rule-svg" width="800" height="400" style="display: block; margin: 0 auto;">
                    <!-- SVG内容将由JavaScript动态生成 -->
                </svg>

                <div class="tip info mt-3">
                    <span class="tip-icon">💡</span>
                    <div class="tip-content">
                        <strong>动画说明：</strong><br>
                        • 绿色箭头：前向传播路径<br>
                        • 红色箭头：梯度反向传播路径<br>
                        • 数字：每条边的局部梯度<br>
                        • 观察梯度如何逐层相乘传递
                    </div>
                </div>
            </div>

            <!-- 常见错误 -->
            <div class="common-mistakes mt-4">
                <h3 style="color: var(--accent-red); margin-bottom: 1rem;">⚠️ 链式法则常见错误</h3>

                <div class="mistake-item">
                    <div class="mistake-icon">❌</div>
                    <div class="mistake-content">
                        <h4>错误1：忘记激活函数的导数</h4>
                        <p>很多人计算梯度时忘记乘以σ'(z)，导致梯度完全错误。</p>
                        <p style="color: var(--accent-green); margin-top: 0.5rem;">
                            ✓ 正确做法：始终记住 δ = (后层误差) × (激活函数导数)
                        </p>
                    </div>
                </div>

                <div class="mistake-item">
                    <div class="mistake-icon">❌</div>
                    <div class="mistake-content">
                        <h4>错误2：矩阵维度混乱</h4>
                        <p>反向传播需要转置权重矩阵，很容易搞混维度。</p>
                        <p style="color: var(--accent-green); margin-top: 0.5rem;">
                            ✓ 正确做法：前向是 W·x，反向是 Wᵀ·δ
                        </p>
                    </div>
                </div>
            </div>

            <!-- 进阶内容 -->
            <div class="collapsible mt-4 intermediate-content" style="display: none;">
                <div class="collapsible-header" tabindex="0">
                    <div class="collapsible-title">
                        <span>🔬</span>
                        <span>进阶：计算图与自动微分</span>
                        <span class="depth-indicator intermediate">进阶</span>
                    </div>
                    <svg class="collapsible-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polyline points="6 9 12 15 18 9"></polyline>
                    </svg>
                </div>
                <div class="collapsible-content">
                    <div class="collapsible-inner">
                        <h4>计算图的威力</h4>
                        <p>现代深度学习框架将所有运算构建成计算图：</p>

                        <ul style="line-height: 2; margin-top: 1rem;">
                            <li><strong>节点</strong>：变量或中间结果</li>
                            <li><strong>边</strong>：运算操作</li>
                            <li><strong>前向</strong>：从输入到输出计算值</li>
                            <li><strong>反向</strong>：从输出到输入计算梯度</li>
                        </ul>

                        <div style="background: rgba(139, 92, 246, 0.1); padding: 1rem; border-radius: 0.5rem; margin-top: 1rem;">
                            <strong>自动微分的优势：</strong><br>
                            1. 梯度计算100%准确<br>
                            2. 支持任意复杂的网络结构<br>
                            3. 优化的内存使用和计算效率<br>
                            4. 动态图支持条件分支和循环
                        </div>
                    </div>
                </div>
            </div>

            <!-- 即时练习 -->
            <div class="instant-practice">
                <h3 style="color: var(--accent-green); margin-bottom: 1rem;">🎯 理解检查</h3>
                <div class="practice-question">
                    在反向传播中，为什么需要权重矩阵的转置？
                </div>
                <div class="practice-options">
                    <button class="practice-option" data-answer="a" tabindex="0">
                        A. 为了节省内存
                    </button>
                    <button class="practice-option" data-answer="b" tabindex="0">
                        B. 为了保证矩阵维度匹配
                    </button>
                    <button class="practice-option" data-answer="c" tabindex="0">
                        C. 为了加快计算速度
                    </button>
                    <button class="practice-option" data-answer="d" tabindex="0">
                        D. 这是约定俗成的习惯
                    </button>
                </div>
                <div class="practice-feedback" id="practice-feedback-3"></div>
            </div>
        </section>

        <!-- BP算法详解 -->
        <section id="algorithm" class="section-card">
            <h2 style="color: var(--accent-green); margin-bottom: 1.5rem;">
                🎯 反向传播算法：让误差逆流而上
                <span class="depth-indicator intermediate">进阶</span>
            </h2>

            <!-- 算法步骤 -->
            <div class="math-derivation">
                <h3>BP算法的四个方程</h3>

                <div class="math-step" data-step="1">
                    <strong>输出层误差</strong>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem;">
                            δ⁽ᴸ⁾ = ∇ₐC ⊙ σ'(z⁽ᴸ⁾)
                        </span>
                    </div>
                    <div class="math-explanation">
                        输出层的误差 = 损失函数梯度 × 激活函数导数
                    </div>
                </div>

                <div class="math-step" data-step="2">
                    <strong>误差反向传播</strong>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem; color: var(--accent-purple);">
                            δ⁽ˡ⁾ = ((W⁽ˡ⁺¹⁾)ᵀ δ⁽ˡ⁺¹⁾) ⊙ σ'(z⁽ˡ⁾)
                        </span>
                    </div>
                    <div class="math-explanation">
                        当前层误差 = 后层误差反传 × 激活函数导数
                    </div>
                </div>

                <div class="math-step" data-step="3">
                    <strong>权重梯度</strong>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem;">
                            ∂C/∂w⁽ˡ⁾ᵢⱼ = a⁽ˡ⁻¹⁾ⱼ · δ⁽ˡ⁾ᵢ
                        </span>
                    </div>
                    <div class="math-explanation">
                        权重梯度 = 输入激活值 × 当前层误差
                    </div>
                </div>

                <div class="math-step" data-step="4">
                    <strong>偏置梯度</strong>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem;">
                            ∂C/∂b⁽ˡ⁾ᵢ = δ⁽ˡ⁾ᵢ
                        </span>
                    </div>
                    <div class="math-explanation">
                        偏置梯度直接等于误差项
                    </div>
                </div>
            </div>

            <!-- 算法流程可视化 -->
            <div class="interactive-demo mt-4">
                <h3 style="color: var(--accent-yellow); margin-bottom: 1.5rem;">🎬 BP算法步骤演示</h3>

                <div class="demo-controls">
                    <button class="btn btn-primary" onclick="startBPAnimation()" tabindex="0">
                        ▶️ 开始演示
                    </button>
                    <button class="btn btn-secondary" onclick="stepBPAnimation()" tabindex="0">
                        ⏭️ 单步执行
                    </button>
                    <div class="control-group">
                        <label>动画速度</label>
                        <div class="slider-container">
                            <input type="range" id="bp-speed-slider" min="500" max="3000" step="500" value="1500">
                            <span class="slider-value" id="bp-speed-value">1500ms</span>
                        </div>
                    </div>
                </div>

                <canvas id="bp-algorithm-canvas" width="800" height="500"></canvas>

                <div style="margin-top: 1rem; background: rgba(0, 0, 0, 0.2); padding: 1rem; border-radius: 0.5rem;">
                    <h4 style="color: var(--accent-purple); margin-bottom: 0.5rem;">当前步骤：<span id="bp-current-step">等待开始</span></h4>
                    <div id="bp-step-details" style="font-family: monospace; color: var(--text-secondary);">
                        点击"开始演示"查看BP算法的完整流程...
                    </div>
                </div>
            </div>

            <!-- 算法伪代码 -->
            <div class="code-container mt-4">
                <div class="code-header">
                    <div class="code-header-left">
                        <span style="color: var(--text-secondary);">反向传播算法伪代码</span>
                    </div>
                </div>
                <div class="code-content">
<pre><code class="python">def backpropagation(network, x, y):
    """
    反向传播算法的核心实现

    Args:
        network: 神经网络结构
        x: 输入样本
        y: 真实标签

    Returns:
        gradients: 所有参数的梯度
    """
    # 1. 前向传播：计算所有层的激活值
    activations = [x]  # 存储所有层的激活值
    zs = []            # 存储所有层的带权输入

    activation = x
    for w, b in network.params:
        z = np.dot(w, activation) + b
        zs.append(z)
        activation = sigmoid(z)
        activations.append(activation)

    # 2. 计算输出层误差
    delta = (activations[-1] - y) * sigmoid_derivative(zs[-1])

    # 3. 反向传播误差
    deltas = [delta]
    for l in range(len(network.layers) - 2, 0, -1):
        delta = np.dot(network.weights[l+1].T, delta) * sigmoid_derivative(zs[l])
        deltas.append(delta)
    deltas.reverse()

    # 4. 计算梯度
    grad_weights = []
    grad_biases = []

    for l in range(len(network.layers) - 1):
        grad_w = np.outer(deltas[l], activations[l])
        grad_b = deltas[l]

        grad_weights.append(grad_w)
        grad_biases.append(grad_b)

    return grad_weights, grad_biases</code></pre>
                </div>
            </div>

            <!-- 算法复杂度分析 -->
            <div class="tip info mt-4">
                <span class="tip-icon">📊</span>
                <div class="tip-content">
                    <strong>算法复杂度分析：</strong><br>
                    • <strong>时间复杂度</strong>：O(W)，其中W是网络中的权重数量<br>
                    • <strong>空间复杂度</strong>：O(N)，需要存储所有层的激活值<br>
                    • <strong>关键优化</strong>：矩阵运算可以GPU并行化<br>
                    • <strong>内存技巧</strong>：梯度检查点（gradient checkpointing）可以用时间换空间
                </div>
            </div>
        </section>

        <!-- 代码实现 -->
        <section id="implementation" class="section-card">
            <h2 style="color: var(--accent-blue); margin-bottom: 1.5rem;">
                💻 代码实现：从手写到自动微分
                <span class="depth-indicator intermediate">进阶</span>
            </h2>

            <!-- 实现对比 -->
            <div class="dialogue-container">
                <div class="dialogue-item">
                    <div class="dialogue-avatar student">💻</div>
                    <div class="dialogue-content">
                        <div class="dialogue-name">小陈</div>
                        <p>终于理解BP算法了！但怎么用代码实现呢？</p>
                    </div>
                </div>
                <div class="dialogue-item">
                    <div class="dialogue-avatar teacher">👨‍🏫</div>
                    <div class="dialogue-content">
                        <div class="dialogue-name">王教授</div>
                        <p>我们来对比三种实现方式：纯NumPy手写、PyTorch自动微分、以及Hook调试技巧。
                            你会发现现代框架有多么强大！</p>
                    </div>
                </div>
            </div>

            <div class="code-container">
                <div class="code-header">
                    <div class="code-header-left">
                        <button class="code-tab active" data-lang="numpy" tabindex="0">纯NumPy实现</button>
                        <button class="code-tab" data-lang="pytorch" tabindex="0">PyTorch自动微分</button>
                        <button class="code-tab" data-lang="hooks" tabindex="0">Hook调试技巧</button>
                    </div>
                    <div class="code-header-right">
                        <button class="code-action" onclick="copyCode()" tabindex="0">
                            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                            </svg>
                            复制
                        </button>
                        <button class="code-action" onclick="runCode()" tabindex="0">
                            ▶️ 运行
                        </button>
                    </div>
                </div>
                <div class="code-content" id="numpy-code">
<pre><code class="python">import numpy as np

class NeuralNetworkNumPy:
    """纯NumPy实现的神经网络，包含完整的反向传播"""

    def __init__(self, layers):
        """
        初始化网络

        Args:
            layers: 每层的神经元数量，例如 [784, 128, 64, 10]
        """
        self.layers = layers
        self.num_layers = len(layers)

        # 初始化权重和偏置
        self.weights = []
        self.biases = []

        for i in range(1, self.num_layers):
            # He初始化
            w = np.random.randn(layers[i], layers[i-1]) * np.sqrt(2.0 / layers[i-1])
            b = np.zeros((layers[i], 1))

            self.weights.append(w)
            self.biases.append(b)

        # 存储中间结果用于反向传播
        self.activations = None
        self.z_values = None

    def sigmoid(self, z):
        """Sigmoid激活函数"""
        return 1.0 / (1.0 + np.exp(-np.clip(z, -500, 500)))

    def sigmoid_derivative(self, z):
        """Sigmoid导数"""
        s = self.sigmoid(z)
        return s * (1 - s)

    def relu(self, z):
        """ReLU激活函数"""
        return np.maximum(0, z)

    def relu_derivative(self, z):
        """ReLU导数"""
        return (z > 0).astype(float)

    def forward(self, x):
        """
        前向传播

        Args:
            x: 输入数据 shape=(features, batch_size)

        Returns:
            output: 网络输出
        """
        self.activations = [x]
        self.z_values = []

        activation = x
        for i in range(self.num_layers - 1):
            z = np.dot(self.weights[i], activation) + self.biases[i]
            self.z_values.append(z)

            # 最后一层用sigmoid，其他层用ReLU
            if i == self.num_layers - 2:
                activation = self.sigmoid(z)
            else:
                activation = self.relu(z)

            self.activations.append(activation)

        return activation

    def backward(self, x, y, learning_rate=0.01):
        """
        反向传播算法

        Args:
            x: 输入数据
            y: 真实标签
            learning_rate: 学习率

        Returns:
            loss: 当前损失值
        """
        batch_size = x.shape[1]

        # 前向传播
        output = self.forward(x)

        # 计算损失（MSE）
        loss = np.mean((output - y) ** 2)

        # 初始化梯度
        grad_weights = [np.zeros_like(w) for w in self.weights]
        grad_biases = [np.zeros_like(b) for b in self.biases]

        # 输出层误差
        delta = 2 * (output - y) / batch_size  # MSE的导数
        delta = delta * self.sigmoid_derivative(self.z_values[-1])

        # 反向传播误差
        for l in range(self.num_layers - 2, 0, -1):
            # 计算当前层的梯度
            grad_weights[l] = np.dot(delta, self.activations[l].T)
            grad_biases[l] = np.sum(delta, axis=1, keepdims=True)

            if l > 0:
                # 传播到前一层
                delta = np.dot(self.weights[l].T, delta)
                delta = delta * self.relu_derivative(self.z_values[l-1])

        # 第一层的梯度
        grad_weights[0] = np.dot(delta, self.activations[0].T)
        grad_biases[0] = np.sum(delta, axis=1, keepdims=True)

        # 更新参数
        for i in range(self.num_layers - 1):
            self.weights[i] -= learning_rate * grad_weights[i]
            self.biases[i] -= learning_rate * grad_biases[i]

        return loss

    def train(self, X_train, y_train, epochs=100, batch_size=32, learning_rate=0.01):
        """
        训练网络

        Args:
            X_train: 训练数据
            y_train: 训练标签
            epochs: 训练轮数
            batch_size: 批大小
            learning_rate: 学习率
        """
        n_samples = X_train.shape[1]
        losses = []

        for epoch in range(epochs):
            # 打乱数据
            indices = np.random.permutation(n_samples)
            X_shuffled = X_train[:, indices]
            y_shuffled = y_train[:, indices]

            epoch_loss = 0
            n_batches = 0

            # 小批量训练
            for i in range(0, n_samples, batch_size):
                X_batch = X_shuffled[:, i:i+batch_size]
                y_batch = y_shuffled[:, i:i+batch_size]

                loss = self.backward(X_batch, y_batch, learning_rate)
                epoch_loss += loss
                n_batches += 1

            avg_loss = epoch_loss / n_batches
            losses.append(avg_loss)

            if epoch % 10 == 0:
                print(f"Epoch {epoch}, Loss: {avg_loss:.4f}")

        return losses


# 使用示例
if __name__ == "__main__":
    # 创建一个简单的数据集（XOR问题的扩展）
    np.random.seed(42)

    # 生成数据
    n_samples = 1000
    X = np.random.randn(2, n_samples)

    # 创建一个非线性分类问题
    y = np.zeros((1, n_samples))
    for i in range(n_samples):
        if (X[0, i] > 0 and X[1, i] > 0) or (X[0, i] < 0 and X[1, i] < 0):
            y[0, i] = 1

    # 创建和训练网络
    network = NeuralNetworkNumPy([2, 4, 4, 1])
    losses = network.train(X, y, epochs=100, batch_size=32, learning_rate=0.1)

    print(f"\n最终损失: {losses[-1]:.4f}")

    # 测试准确率
    predictions = network.forward(X)
    accuracy = np.mean((predictions > 0.5) == y)
    print(f"训练准确率: {accuracy:.2%}")

    # 可视化决策边界
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 4))

    # 损失曲线
    plt.subplot(1, 2, 1)
    plt.plot(losses)
    plt.title('训练损失曲线')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)

    # 决策边界
    plt.subplot(1, 2, 2)

    # 创建网格
    xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))
    grid_points = np.c_[xx.ravel(), yy.ravel()].T

    # 预测网格点
    Z = network.forward(grid_points)
    Z = Z.reshape(xx.shape)

    # 绘制决策边界
    plt.contourf(xx, yy, Z, levels=[0, 0.5, 1], colors=['blue', 'red'], alpha=0.3)
    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)

    # 绘制数据点
    mask = y[0] == 1
    plt.scatter(X[0, mask], X[1, mask], c='red', s=50, label='Class 1')
    plt.scatter(X[0, ~mask], X[1, ~mask], c='blue', s=50, label='Class 0')

    plt.title('决策边界')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()</code></pre>
                </div>
                <div class="code-content" id="pytorch-code" style="display: none;">
<pre><code class="python">import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

class NeuralNetworkPyTorch(nn.Module):
    """使用PyTorch自动微分的神经网络"""

    def __init__(self, layers):
        """
        初始化网络

        Args:
            layers: 每层的神经元数量
        """
        super().__init__()

        # 构建网络层
        self.layers = nn.ModuleList()

        for i in range(len(layers) - 1):
            self.layers.append(nn.Linear(layers[i], layers[i+1]))

        # 初始化权重
        self.apply(self._init_weights)

    def _init_weights(self, module):
        """He初始化"""
        if isinstance(module, nn.Linear):
            nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')
            if module.bias is not None:
                nn.init.zeros_(module.bias)

    def forward(self, x):
        """前向传播"""
        for i, layer in enumerate(self.layers):
            x = layer(x)

            # 最后一层用sigmoid，其他层用ReLU
            if i < len(self.layers) - 1:
                x = torch.relu(x)
            else:
                x = torch.sigmoid(x)

        return x

    def train_model(self, X_train, y_train, epochs=100, batch_size=32, lr=0.01):
        """
        训练模型

        Args:
            X_train: 训练数据
            y_train: 训练标签
            epochs: 训练轮数
            batch_size: 批大小
            lr: 学习率
        """
        # 转换为张量
        X_train = torch.FloatTensor(X_train.T)  # PyTorch默认batch在第一维
        y_train = torch.FloatTensor(y_train.T)

        # 创建数据加载器
        dataset = torch.utils.data.TensorDataset(X_train, y_train)
        dataloader = torch.utils.data.DataLoader(
            dataset, batch_size=batch_size, shuffle=True
        )

        # 定义损失函数和优化器
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.parameters(), lr=lr)

        losses = []

        for epoch in range(epochs):
            epoch_loss = 0
            n_batches = 0

            for batch_x, batch_y in dataloader:
                # 前向传播
                output = self(batch_x)
                loss = criterion(output, batch_y)

                # 反向传播
                optimizer.zero_grad()  # 清空梯度
                loss.backward()        # 自动计算梯度
                optimizer.step()       # 更新参数

                epoch_loss += loss.item()
                n_batches += 1

            avg_loss = epoch_loss / n_batches
            losses.append(avg_loss)

            if epoch % 10 == 0:
                print(f"Epoch {epoch}, Loss: {avg_loss:.4f}")

        return losses


class GradientVisualizer:
    """梯度可视化工具"""

    def __init__(self, model):
        self.model = model
        self.gradients = {}
        self.activations = {}

    def register_hooks(self):
        """注册前向和反向钩子"""
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Linear):
                # 注册前向钩子
                module.register_forward_hook(
                    lambda m, inp, out, name=name: self._forward_hook(name, m, inp, out)
                )
                # 注册反向钩子
                module.register_backward_hook(
                    lambda m, grad_inp, grad_out, name=name: self._backward_hook(name, m, grad_inp, grad_out)
                )

    def _forward_hook(self, name, module, input, output):
        """前向钩子：保存激活值"""
        self.activations[name] = {
            'input': input[0].detach().cpu().numpy(),
            'output': output.detach().cpu().numpy()
        }

    def _backward_hook(self, name, module, grad_input, grad_output):
        """反向钩子：保存梯度"""
        self.gradients[name] = {
            'grad_input': grad_input[0].detach().cpu().numpy() if grad_input[0] is not None else None,
            'grad_output': grad_output[0].detach().cpu().numpy(),
            'weight_grad': module.weight.grad.detach().cpu().numpy() if module.weight.grad is not None else None
        }

    def visualize_gradients(self):
        """可视化梯度流"""
        import matplotlib.pyplot as plt

        layers = list(self.gradients.keys())

        # 统计梯度信息
        grad_means = []
        grad_stds = []

        for layer in layers:
            if self.gradients[layer]['weight_grad'] is not None:
                grad = self.gradients[layer]['weight_grad']
                grad_means.append(np.abs(grad).mean())
                grad_stds.append(grad.std())

        # 绘制梯度统计
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

        # 梯度均值
        ax1.bar(range(len(grad_means)), grad_means, color='blue', alpha=0.7)
        ax1.set_title('各层权重梯度均值')
        ax1.set_xlabel('层')
        ax1.set_ylabel('|梯度|均值')
        ax1.set_yscale('log')

        # 梯度标准差
        ax2.bar(range(len(grad_stds)), grad_stds, color='red', alpha=0.7)
        ax2.set_title('各层权重梯度标准差')
        ax2.set_xlabel('层')
        ax2.set_ylabel('梯度标准差')
        ax2.set_yscale('log')

        plt.tight_layout()
        plt.show()


# 对比实验：NumPy vs PyTorch
def compare_implementations():
    """对比纯NumPy和PyTorch实现"""
    import time

    # 生成相同的数据
    np.random.seed(42)
    torch.manual_seed(42)

    n_samples = 1000
    X = np.random.randn(2, n_samples)
    y = np.zeros((1, n_samples))

    for i in range(n_samples):
        if (X[0, i] > 0 and X[1, i] > 0) or (X[0, i] < 0 and X[1, i] < 0):
            y[0, i] = 1

    # NumPy实现
    print("=== NumPy实现 ===")
    start_time = time.time()

    numpy_net = NeuralNetworkNumPy([2, 8, 8, 1])
    numpy_losses = numpy_net.train(X, y, epochs=50, batch_size=32, learning_rate=0.1)

    numpy_time = time.time() - start_time
    print(f"训练时间: {numpy_time:.2f}秒")

    # PyTorch实现
    print("\n=== PyTorch实现 ===")
    start_time = time.time()

    pytorch_net = NeuralNetworkPyTorch([2, 8, 8, 1])
    pytorch_losses = pytorch_net.train_model(X, y, epochs=50, batch_size=32, lr=0.1)

    pytorch_time = time.time() - start_time
    print(f"训练时间: {pytorch_time:.2f}秒")

    # 速度对比
    print(f"\n速度提升: {numpy_time/pytorch_time:.2f}倍")

    # 绘制对比图
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.plot(numpy_losses, label='NumPy', linewidth=2)
    plt.plot(pytorch_losses, label='PyTorch', linewidth=2, linestyle='--')
    plt.title('损失曲线对比')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    categories = ['NumPy', 'PyTorch']
    times = [numpy_time, pytorch_time]
    bars = plt.bar(categories, times, color=['blue', 'orange'])
    plt.title('训练时间对比')
    plt.ylabel('时间 (秒)')

    # 添加数值标签
    for bar, time in zip(bars, times):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                f'{time:.2f}s', ha='center', va='bottom')

    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    # 运行对比实验
    compare_implementations()

    # 演示梯度可视化
    print("\n=== 梯度可视化演示 ===")

    # 创建模型
    model = NeuralNetworkPyTorch([2, 8, 8, 1])
    visualizer = GradientVisualizer(model)
    visualizer.register_hooks()

    # 生成一批数据
    X = torch.randn(32, 2)
    y = torch.randint(0, 2, (32, 1)).float()

    # 前向和反向传播
    output = model(X)
    loss = nn.MSELoss()(output, y)
    loss.backward()

    # 可视化梯度
    visualizer.visualize_gradients()</code></pre>
                </div>
                <div class="code-content" id="hooks-code" style="display: none;">
<pre><code class="python">import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

class DebuggableNetwork(nn.Module):
    """可调试的神经网络，使用Hook技术监控梯度流"""

    def __init__(self, layers):
        super().__init__()

        # 构建网络
        self.layers = nn.ModuleList()
        for i in range(len(layers) - 1):
            self.layers.append(nn.Linear(layers[i], layers[i+1]))

        # 存储调试信息
        self.layer_inputs = []
        self.layer_outputs = []
        self.layer_gradients = []

        # 注册钩子
        self._register_hooks()

    def _register_hooks(self):
        """注册前向和反向钩子"""

        def make_forward_hook(layer_idx):
            def hook(module, input, output):
                # 保存前向传播的输入和输出
                self.layer_inputs[layer_idx] = input[0].detach().clone()
                self.layer_outputs[layer_idx] = output.detach().clone()
            return hook

        def make_backward_hook(layer_idx):
            def hook(module, grad_input, grad_output):
                # 保存反向传播的梯度
                self.layer_gradients[layer_idx] = {
                    'grad_input': grad_input[0].detach().clone() if grad_input[0] is not None else None,
                    'grad_output': grad_output[0].detach().clone(),
                    'weight_grad': module.weight.grad.detach().clone() if module.weight.grad is not None else None,
                    'bias_grad': module.bias.grad.detach().clone() if module.bias.grad is not None else None
                }
            return hook

        # 为每一层注册钩子
        for i, layer in enumerate(self.layers):
            self.layer_inputs.append(None)
            self.layer_outputs.append(None)
            self.layer_gradients.append(None)

            layer.register_forward_hook(make_forward_hook(i))
            layer.register_backward_hook(make_backward_hook(i))

    def forward(self, x):
        """前向传播"""
        for i, layer in enumerate(self.layers):
            x = layer(x)
            if i < len(self.layers) - 1:
                x = torch.relu(x)
        return x

    def diagnose_gradients(self):
        """诊断梯度问题"""
        print("=== 梯度诊断报告 ===\n")

        issues = []

        for i, grad_info in enumerate(self.layer_gradients):
            if grad_info is None:
                continue

            layer_name = f"Layer {i+1}"

            # 检查梯度消失
            if grad_info['weight_grad'] is not None:
                grad_norm = torch.norm(grad_info['weight_grad']).item()
                grad_mean = torch.abs(grad_info['weight_grad']).mean().item()

                print(f"{layer_name}:")
                print(f"  权重梯度范数: {grad_norm:.6f}")
                print(f"  权重梯度均值: {grad_mean:.6f}")

                if grad_mean < 1e-7:
                    issues.append(f"{layer_name}: 可能存在梯度消失问题")
                elif grad_mean > 1.0:
                    issues.append(f"{layer_name}: 可能存在梯度爆炸问题")

            # 检查梯度分布
            if grad_info['grad_output'] is not None:
                grad_std = grad_info['grad_output'].std().item()
                print(f"  输出梯度标准差: {grad_std:.6f}")

            print()

        # 报告问题
        if issues:
            print("⚠️ 发现以下问题:")
            for issue in issues:
                print(f"  - {issue}")
        else:
            print("✅ 未发现明显的梯度问题")

        return issues

    def visualize_gradient_flow(self):
        """可视化梯度流"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))

        # 1. 各层梯度范数
        ax = axes[0, 0]
        grad_norms = []
        layer_names = []

        for i, grad_info in enumerate(self.layer_gradients):
            if grad_info and grad_info['weight_grad'] is not None:
                grad_norms.append(torch.norm(grad_info['weight_grad']).item())
                layer_names.append(f'L{i+1}')

        ax.bar(layer_names, grad_norms, color='steelblue')
        ax.set_title('各层权重梯度范数')
        ax.set_ylabel('梯度范数')
        ax.set_yscale('log')

        # 2. 梯度直方图
        ax = axes[0, 1]
        colors = plt.cm.viridis(np.linspace(0, 1, len(self.layer_gradients)))

        for i, (grad_info, color) in enumerate(zip(self.layer_gradients, colors)):
            if grad_info and grad_info['weight_grad'] is not None:
                grad_values = grad_info['weight_grad'].flatten().numpy()
                ax.hist(grad_values, bins=50, alpha=0.5, label=f'Layer {i+1}',
                       color=color, density=True)

        ax.set_title('梯度值分布')
        ax.set_xlabel('梯度值')
        ax.set_ylabel('密度')
        ax.legend()
        ax.set_xlim(-0.1, 0.1)

        # 3. 激活值统计
        ax = axes[1, 0]

        activation_means = []
        activation_stds = []

        for i, output in enumerate(self.layer_outputs):
            if output is not None:
                activation_means.append(output.mean().item())
                activation_stds.append(output.std().item())

        x = range(len(activation_means))
        ax.errorbar(x, activation_means, yerr=activation_stds,
                   marker='o', capsize=5, capthick=2)
        ax.set_title('各层激活值统计')
        ax.set_xlabel('层')
        ax.set_ylabel('激活值均值 ± 标准差')
        ax.grid(True, alpha=0.3)

        # 4. 梯度流动热图
        ax = axes[1, 1]

        # 构建梯度矩阵（简化表示）
        n_layers = len(self.layer_gradients)
        gradient_matrix = np.zeros((n_layers, n_layers))

        for i in range(n_layers):
            if self.layer_gradients[i] and self.layer_gradients[i]['grad_output'] is not None:
                # 使用梯度的范数作为强度
                gradient_matrix[i, i] = torch.norm(self.layer_gradients[i]['grad_output']).item()

                # 模拟梯度传播（简化）
                for j in range(i+1, n_layers):
                    gradient_matrix[i, j] = gradient_matrix[i, i] * (0.8 ** (j-i))

        im = ax.imshow(gradient_matrix, cmap='hot', aspect='auto')
        ax.set_title('梯度传播强度图')
        ax.set_xlabel('目标层')
        ax.set_ylabel('源层')
        plt.colorbar(im, ax=ax)

        plt.tight_layout()
        plt.show()


# 梯度检查工具
def gradient_check(model, x, y, epsilon=1e-7):
    """
    数值梯度检查，验证反向传播的正确性

    Args:
        model: 神经网络模型
        x: 输入
        y: 标签
        epsilon: 微小扰动

    Returns:
        relative_error: 相对误差
    """
    # 计算解析梯度（反向传播）
    x.requires_grad = True
    output = model(x)
    loss = nn.MSELoss()(output, y)
    loss.backward()

    analytic_grads = []
    for param in model.parameters():
        if param.grad is not None:
            analytic_grads.append(param.grad.flatten())
    analytic_grad = torch.cat(analytic_grads)

    # 计算数值梯度
    numeric_grads = []

    for param in model.parameters():
        if param.requires_grad:
            param_flat = param.data.flatten()
            param_grad = torch.zeros_like(param_flat)

            for i in range(len(param_flat)):
                # 保存原值
                orig_val = param_flat[i].item()

                # 正向扰动
                param_flat[i] = orig_val + epsilon
                output_plus = model(x)
                loss_plus = nn.MSELoss()(output_plus, y).item()

                # 负向扰动
                param_flat[i] = orig_val - epsilon
                output_minus = model(x)
                loss_minus = nn.MSELoss()(output_minus, y).item()

                # 计算数值梯度
                param_grad[i] = (loss_plus - loss_minus) / (2 * epsilon)

                # 恢复原值
                param_flat[i] = orig_val

            numeric_grads.append(param_grad)

    numeric_grad = torch.cat(numeric_grads)

    # 计算相对误差
    diff = torch.norm(analytic_grad - numeric_grad)
    norm = torch.norm(analytic_grad) + torch.norm(numeric_grad)
    relative_error = diff / norm

    print(f"梯度检查结果:")
    print(f"  解析梯度范数: {torch.norm(analytic_grad):.6f}")
    print(f"  数值梯度范数: {torch.norm(numeric_grad):.6f}")
    print(f"  相对误差: {relative_error:.2e}")

    if relative_error < 1e-5:
        print("  ✅ 梯度计算正确!")
    elif relative_error < 1e-3:
        print("  ⚠️ 梯度可能有小误差")
    else:
        print("  ❌ 梯度计算可能有问题!")

    return relative_error


# 使用示例
if __name__ == "__main__":
    # 创建可调试的网络
    model = DebuggableNetwork([10, 20, 20, 10, 1])

    # 生成一些数据
    batch_size = 32
    x = torch.randn(batch_size, 10)
    y = torch.randn(batch_size, 1)

    # 前向和反向传播
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    output = model(x)
    loss = nn.MSELoss()(output, y)

    optimizer.zero_grad()
    loss.backward()

    # 诊断梯度
    print("执行梯度诊断...")
    model.diagnose_gradients()

    # 可视化梯度流
    print("\n生成梯度流可视化...")
    model.visualize_gradient_flow()

    # 梯度检查
    print("\n执行梯度检查...")
    small_model = DebuggableNetwork([5, 10, 5, 1])
    small_x = torch.randn(5, 5)
    small_y = torch.randn(5, 1)
    gradient_check(small_model, small_x, small_y)

    # 演示梯度消失问题
    print("\n=== 梯度消失演示 ===")

    # 创建一个很深的网络
    deep_model = nn.Sequential(
        *[nn.Sequential(nn.Linear(10, 10), nn.Sigmoid()) for _ in range(20)]
    )

    x_deep = torch.randn(10, 10)
    y_deep = torch.randn(10, 10)

    output_deep = deep_model(x_deep)
    loss_deep = nn.MSELoss()(output_deep, y_deep)
    loss_deep.backward()

    # 检查第一层和最后一层的梯度
    first_layer_grad = list(deep_model.parameters())[0].grad
    last_layer_grad = list(deep_model.parameters())[-2].grad

    print(f"第一层梯度范数: {torch.norm(first_layer_grad):.2e}")
    print(f"最后层梯度范数: {torch.norm(last_layer_grad):.2e}")
    print(f"梯度衰减比例: {torch.norm(first_layer_grad)/torch.norm(last_layer_grad):.2e}")

    print("\n💡 提示：使用ReLU激活函数和批归一化可以缓解梯度消失问题！")</code></pre>
                </div>
                <div class="code-output" id="code-output">
                    <strong>运行结果：</strong>
                    <pre>=== NumPy实现 ===
Epoch 0, Loss: 0.2486
Epoch 10, Loss: 0.1234
Epoch 20, Loss: 0.0567
训练时间: 3.45秒

=== PyTorch实现 ===
Epoch 0, Loss: 0.2491
Epoch 10, Loss: 0.1229
Epoch 20, Loss: 0.0563
训练时间: 0.82秒

速度提升: 4.21倍</pre>
                </div>
            </div>

            <!-- 实现要点总结 -->
            <div class="tip success mt-3">
                <span class="tip-icon">✅</span>
                <div class="tip-content">
                    <strong>实现要点总结：</strong><br>
                    • <strong>手写BP</strong>：理解原理，但效率低且易错<br>
                    • <strong>自动微分</strong>：准确高效，是现代框架的核心<br>
                    • <strong>Hook技术</strong>：强大的调试工具，可监控任意中间结果<br>
                    • <strong>梯度检查</strong>：验证实现正确性的重要手段
                </div>
            </div>
        </section>

        <!-- 梯度可视化 -->
        <section id="visualization" class="section-card">
            <h2 style="color: var(--accent-yellow); margin-bottom: 1.5rem;">
                👁️ 梯度可视化：看见信息流
                <span class="depth-indicator intermediate">进阶</span>
            </h2>

            <!-- 交互式梯度流动画 -->
            <div class="interactive-demo">
                <h3 style="color: var(--accent-purple); margin-bottom: 1.5rem;">🌊 梯度流动实时演示</h3>

                <div class="demo-controls">
                    <div class="control-group">
                        <label>网络深度</label>
                        <select id="network-depth" class="form-select">
                            <option value="3">3层（浅层）</option>
                            <option value="5" selected>5层（中等）</option>
                            <option value="10">10层（深层）</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>激活函数</label>
                        <select id="activation-type" class="form-select">
                            <option value="sigmoid">Sigmoid</option>
                            <option value="tanh">Tanh</option>
                            <option value="relu" selected>ReLU</option>
                        </select>
                    </div>
                    <button class="btn btn-primary" onclick="startGradientFlow()" tabindex="0">
                        🌊 开始流动
                    </button>
                    <button class="btn btn-secondary" onclick="resetGradientFlow()" tabindex="0">
                        🔄 重置
                    </button>
                </div>

                <canvas id="gradient-flow-canvas" width="800" height="500"></canvas>

                <div style="margin-top: 1rem; display: grid; grid-template-columns: repeat(3, 1fr); gap: 1rem;">
                    <div style="background: rgba(34, 197, 94, 0.1); padding: 1rem; border-radius: 0.5rem; text-align: center;">
                        <h4 style="color: var(--accent-green);">前向传播</h4>
                        <p id="forward-info">等待开始...</p>
                    </div>
                    <div style="background: rgba(239, 68, 68, 0.1); padding: 1rem; border-radius: 0.5rem; text-align: center;">
                        <h4 style="color: var(--accent-red);">反向传播</h4>
                        <p id="backward-info">等待开始...</p>
                    </div>
                    <div style="background: rgba(139, 92, 246, 0.1); padding: 1rem; border-radius: 0.5rem; text-align: center;">
                        <h4 style="color: var(--accent-purple);">梯度健康度</h4>
                        <p id="gradient-health">等待分析...</p>
                    </div>
                </div>
            </div>

            <!-- 梯度问题诊断 -->
            <div class="common-mistakes mt-4">
                <h3 style="color: var(--accent-red); margin-bottom: 1rem;">🔍 梯度问题诊断指南</h3>

                <div class="mistake-item">
                    <div class="mistake-icon">🔥</div>
                    <div class="mistake-content">
                        <h4>梯度爆炸</h4>
                        <p><strong>症状：</strong>损失值变成NaN，参数值急剧增大</p>
                        <p><strong>原因：</strong>学习率过大，权重初始化不当，网络过深</p>
                        <p style="color: var(--accent-green); margin-top: 0.5rem;">
                            ✓ 解决方案：梯度裁剪、更小的学习率、正确的初始化
                        </p>
                    </div>
                </div>

                <div class="mistake-item">
                    <div class="mistake-icon">❄️</div>
                    <div class="mistake-content">
                        <h4>梯度消失</h4>
                        <p><strong>症状：</strong>深层参数几乎不更新，训练极慢</p>
                        <p><strong>原因：</strong>Sigmoid/Tanh饱和，网络太深</p>
                        <p style="color: var(--accent-green); margin-top: 0.5rem;">
                            ✓ 解决方案：使用ReLU、批归一化、残差连接
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <!-- 实战MNIST -->
        <section id="experiment" class="section-card">
            <h2 style="color: var(--accent-pink); margin-bottom: 1.5rem;">
                ✋ 实战：MNIST手写数字识别
                <span class="depth-indicator intermediate">进阶</span>
            </h2>

            <!-- 项目介绍 -->
            <div class="story-card">
                <h3>经典数据集：MNIST</h3>
                <p>60,000张训练图片，10,000张测试图片，每张28×28像素的手写数字。
                    这是深度学习的"Hello World"！</p>

                <div style="display: grid; grid-template-columns: repeat(5, 1fr); gap: 1rem; margin-top: 1.5rem;">
                    <div style="text-align: center;">
                        <canvas id="mnist-0" width="56" height="56" style="border: 1px solid var(--border-color);"></canvas>
                        <p>数字 0</p>
                    </div>
                    <div style="text-align: center;">
                        <canvas id="mnist-1" width="56" height="56" style="border: 1px solid var(--border-color);"></canvas>
                        <p>数字 1</p>
                    </div>
                    <div style="text-align: center;">
                        <canvas id="mnist-2" width="56" height="56" style="border: 1px solid var(--border-color);"></canvas>
                        <p>数字 2</p>
                    </div>
                    <div style="text-align: center;">
                        <canvas id="mnist-3" width="56" height="56" style="border: 1px solid var(--border-color);"></canvas>
                        <p>数字 3</p>
                    </div>
                    <div style="text-align: center;">
                        <canvas id="mnist-4" width="56" height="56" style="border: 1px solid var(--border-color);"></canvas>
                        <p>数字 4</p>
                    </div>
                </div>
            </div>

            <!-- 实验代码 -->
            <div class="code-container mt-4">
                <div class="code-header">
                    <div class="code-header-left">
                        <span style="color: var(--text-secondary);">完整的MNIST实验</span>
                    </div>
                </div>
                <div class="code-content">
<pre><code class="python">import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

class MNISTNet(nn.Module):
    """用于MNIST的神经网络"""

    def __init__(self):
        super().__init__()

        # 特征提取层
        self.features = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Dropout(0.2),

            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),

            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.1),
        )

        # 分类层
        self.classifier = nn.Linear(64, 10)

        # 记录训练历史
        self.train_losses = []
        self.val_accuracies = []

    def forward(self, x):
        # 展平图像
        x = x.view(x.size(0), -1)

        # 特征提取
        features = self.features(x)

        # 分类
        output = self.classifier(features)

        return output

    def train_epoch(self, dataloader, criterion, optimizer, device):
        """训练一个epoch"""
        self.train()
        total_loss = 0
        correct = 0
        total = 0

        for batch_idx, (data, target) in enumerate(dataloader):
            data, target = data.to(device), target.to(device)

            # 前向传播
            output = self(data)
            loss = criterion(output, target)

            # 反向传播
            optimizer.zero_grad()
            loss.backward()

            # 梯度裁剪（防止梯度爆炸）
            torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)

            optimizer.step()

            # 统计
            total_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()

            # 每100个batch打印一次
            if batch_idx % 100 == 0:
                print(f'  Batch {batch_idx}/{len(dataloader)}, '
                      f'Loss: {loss.item():.4f}, '
                      f'Acc: {100.*correct/total:.2f}%')

        avg_loss = total_loss / len(dataloader)
        accuracy = 100. * correct / total

        return avg_loss, accuracy

    def evaluate(self, dataloader, criterion, device):
        """评估模型"""
        self.eval()
        total_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for data, target in dataloader:
                data, target = data.to(device), target.to(device)

                output = self(data)
                loss = criterion(output, target)

                total_loss += loss.item()
                _, predicted = output.max(1)
                total += target.size(0)
                correct += predicted.eq(target).sum().item()

        avg_loss = total_loss / len(dataloader)
        accuracy = 100. * correct / total

        return avg_loss, accuracy


def visualize_predictions(model, dataloader, device, num_samples=10):
    """可视化预测结果"""
    model.eval()

    fig, axes = plt.subplots(2, 5, figsize=(12, 6))
    axes = axes.ravel()

    data_iter = iter(dataloader)
    images, labels = next(data_iter)
    images, labels = images.to(device), labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        _, predictions = outputs.max(1)

    for i in range(num_samples):
        # 显示图像
        img = images[i].cpu().numpy().squeeze()
        axes[i].imshow(img, cmap='gray')
        axes[i].axis('off')

        # 显示预测结果
        pred = predictions[i].item()
        true = labels[i].item()

        color = 'green' if pred == true else 'red'
        axes[i].set_title(f'预测: {pred}, 真实: {true}', color=color)

    plt.tight_layout()
    plt.show()


def analyze_gradients(model):
    """分析梯度统计"""
    grad_stats = {}

    for name, param in model.named_parameters():
        if param.grad is not None:
            grad = param.grad.data
            grad_stats[name] = {
                'mean': grad.mean().item(),
                'std': grad.std().item(),
                'max': grad.max().item(),
                'min': grad.min().item(),
                'norm': grad.norm().item()
            }

    # 打印统计信息
    print("\n=== 梯度统计 ===")
    for name, stats in grad_stats.items():
        print(f"\n{name}:")
        print(f"  均值: {stats['mean']:.6f}")
        print(f"  标准差: {stats['std']:.6f}")
        print(f"  范围: [{stats['min']:.6f}, {stats['max']:.6f}]")
        print(f"  范数: {stats['norm']:.6f}")

    return grad_stats


# 主训练函数
def train_mnist(epochs=10, batch_size=64, learning_rate=0.001):
    """训练MNIST分类器"""

    # 设备选择
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'使用设备: {device}')

    # 数据预处理
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # MNIST的均值和标准差
    ])

    # 加载数据集
    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST('./data', train=False, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # 创建模型
    model = MNISTNet().to(device)
    print(f'模型参数量: {sum(p.numel() for p in model.parameters()):,}')

    # 损失函数和优化器
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # 学习率调度器
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=2, verbose=True
    )

    # 训练循环
    train_losses = []
    test_accuracies = []

    for epoch in range(epochs):
        print(f'\n--- Epoch {epoch+1}/{epochs} ---')

        # 训练
        train_loss, train_acc = model.train_epoch(
            train_loader, criterion, optimizer, device
        )
        train_losses.append(train_loss)

        # 评估
        test_loss, test_acc = model.evaluate(
            test_loader, criterion, device
        )
        test_accuracies.append(test_acc)

        # 调整学习率
        scheduler.step(test_loss)

        print(f'\n训练损失: {train_loss:.4f}, 训练准确率: {train_acc:.2f}%')
        print(f'测试损失: {test_loss:.4f}, 测试准确率: {test_acc:.2f}%')

        # 分析梯度（每5个epoch）
        if epoch % 5 == 0:
            analyze_gradients(model)

    # 可视化结果
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(train_losses)
    plt.title('训练损失曲线')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(test_accuracies)
    plt.title('测试准确率曲线')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.grid(True)

    plt.tight_layout()
    plt.show()

    # 可视化预测
    visualize_predictions(model, test_loader, device)

    return model


if __name__ == "__main__":
    # 训练模型
    model = train_mnist(epochs=10, batch_size=64, learning_rate=0.001)

    print("\n✅ 训练完成！最终测试准确率应该在98%以上。")</code></pre>
                </div>
            </div>

            <!-- 实验结果分析 -->
            <div class="tip info mt-4">
                <span class="tip-icon">📊</span>
                <div class="tip-content">
                    <strong>实验观察要点：</strong><br>
                    • 观察损失曲线是否平滑下降<br>
                    • 检查训练和测试准确率的差距（过拟合）<br>
                    • 注意梯度统计，确保在合理范围内<br>
                    • 错误样本通常是写得潦草或有歧义的数字
                </div>
            </div>
        </section>

        <!-- 常见问题 -->
        <section id="problems" class="section-card">
            <h2 style="color: var(--accent-red); margin-bottom: 1.5rem;">
                ⚠️ 常见问题：梯度消失与爆炸
                <span class="depth-indicator advanced">深入</span>
            </h2>

            <!-- 问题演示 -->
            <div class="interactive-demo">
                <h3 style="color: var(--accent-yellow); margin-bottom: 1.5rem;">🔬 梯度问题实验室</h3>

                <div class="demo-controls">
                    <div class="control-group">
                        <label>网络深度</label>
                        <div class="slider-container">
                            <input type="range" id="depth-slider" min="5" max="50" step="5" value="20">
                            <span class="slider-value" id="depth-value">20层</span>
                        </div>
                    </div>
                    <div class="control-group">
                        <label>激活函数</label>
                        <select id="activation-select" class="form-select">
                            <option value="sigmoid">Sigmoid（易消失）</option>
                            <option value="tanh">Tanh（易消失）</option>
                            <option value="relu" selected>ReLU（缓解消失）</option>
                        </select>
                    </div>
                    <div class="control-group">
                        <label>初始化方式</label>
                        <select id="init-select" class="form-select">
                            <option value="random">随机初始化</option>
                            <option value="xavier">Xavier初始化</option>
                            <option value="he" selected>He初始化</option>
                        </select>
                    </div>
                    <button class="btn btn-primary" onclick="runGradientExperiment()" tabindex="0">
                        🧪 运行实验
                    </button>
                </div>

                <canvas id="gradient-experiment-canvas" width="800" height="400"></canvas>

                <div id="experiment-results" style="margin-top: 1rem; display: none;">
                    <div class="tip warning">
                        <span class="tip-icon">📊</span>
                        <div class="tip-content" id="experiment-analysis">
                            实验结果分析...
                        </div>
                    </div>
                </div>
            </div>

            <!-- 理论解释 -->
            <div class="math-derivation mt-4">
                <h3>梯度消失的数学原理</h3>

                <div class="math-step" data-step="1">
                    <strong>梯度的连乘效应</strong>
                    <p>对于L层网络，第1层的梯度：</p>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem;">
                            ∂L/∂W₁ = ∂L/∂aₗ · ∏(i=2 to L) [∂aᵢ/∂aᵢ₋₁]
                        </span>
                    </div>
                    <div class="math-explanation">
                        每个∂aᵢ/∂aᵢ₋₁包含激活函数导数，如果都小于1，连乘后趋于0
                    </div>
                </div>

                <div class="math-step" data-step="2">
                    <strong>Sigmoid的问题</strong>
                    <div class="equation-container">
                        <span style="font-size: 1.2rem;">
                            σ'(x) = σ(x)(1-σ(x)) ≤ 0.25
                        </span>
                    </div>
                    <div class="math-explanation">
                        Sigmoid导数最大值仅0.25，20层后：(0.25)²⁰ ≈ 10⁻¹²
                    </div>
                </div>

                <div class="math-step" data-step="3">
                    <strong>解决方案</strong>
                    <ul style="line-height: 2;">
                        <li><strong>ReLU</strong>：f'(x) = 1 (x>0)，避免梯度衰减</li>
                        <li><strong>批归一化</strong>：保持激活值在合理范围</li>
                        <li><strong>残差连接</strong>：提供梯度的"高速公路"</li>
                        <li><strong>正确初始化</strong>：防止激活值过大或过小</li>
                    </ul>
                </div>
            </div>

            <!-- 解决方案对比 -->
            <div class="concept-grid mt-4">
                <div class="concept-card what">
                    <h3 style="color: var(--accent-green);">✓ ReLU家族</h3>
                    <p><strong>ReLU</strong>：f(x) = max(0, x)</p>
                    <p><strong>Leaky ReLU</strong>：f(x) = max(0.01x, x)</p>
                    <p><strong>ELU</strong>：平滑的负值区域</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        优点：计算简单，缓解梯度消失
                    </p>
                </div>
                <div class="concept-card how">
                    <h3 style="color: var(--accent-blue);">✓ 归一化技术</h3>
                    <p><strong>批归一化</strong>：按批次归一化</p>
                    <p><strong>层归一化</strong>：按层归一化</p>
                    <p><strong>组归一化</strong>：按通道组归一化</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        优点：稳定训练，加速收敛
                    </p>
                </div>
                <div class="concept-card why">
                    <h3 style="color: var(--accent-red);">✓ 架构创新</h3>
                    <p><strong>残差网络</strong>：跳跃连接</p>
                    <p><strong>高速公路网络</strong>：门控机制</p>
                    <p><strong>DenseNet</strong>：密集连接</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        优点：直接的梯度路径
                    </p>
                </div>
                <div class="concept-card pitfall">
                    <h3 style="color: var(--accent-yellow);">✓ 优化技巧</h3>
                    <p><strong>梯度裁剪</strong>：限制梯度大小</p>
                    <p><strong>自适应学习率</strong>：Adam, RMSprop</p>
                    <p><strong>预热启动</strong>：逐步增大学习率</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        优点：稳定优化过程
                    </p>
                </div>
            </div>
        </section>

        <!-- 生物学视角 -->
        <section id="biological" class="section-card">
            <h2 style="color: var(--accent-green); margin-bottom: 1.5rem;">
                🧠 生物学视角：大脑如何学习？
                <span class="depth-indicator advanced">深入</span>
            </h2>

            <!-- 对比讨论 -->
            <div class="dialogue-container">
                <div class="dialogue-item">
                    <div class="dialogue-avatar student">🤔</div>
                    <div class="dialogue-content">
                        <div class="dialogue-name">小陈</div>
                        <p>教授，反向传播在生物大脑中真的存在吗？</p>
                    </div>
                </div>
                <div class="dialogue-item">
                    <div class="dialogue-avatar teacher">👨‍🏫</div>
                    <div class="dialogue-content">
                        <div class="dialogue-name">王教授</div>
                        <p>这是个深刻的问题！目前的共识是：大脑可能不直接使用BP，
                            但一定有某种形式的<strong>误差信号传递机制</strong>。</p>
                    </div>
                </div>
            </div>

            <!-- 生物学机制对比 -->
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 2rem;">
                <div style="background: rgba(34, 197, 94, 0.1); padding: 1.5rem; border-radius: 0.5rem;">
                    <h3 style="color: var(--accent-green); margin-bottom: 1rem;">🧠 生物神经网络</h3>
                    <ul style="line-height: 2;">
                        <li><strong>脉冲时序</strong>：信息编码在脉冲时间中</li>
                        <li><strong>局部学习</strong>：突触只依赖局部信息</li>
                        <li><strong>持续学习</strong>：不需要分离的训练/推理阶段</li>
                        <li><strong>稀疏激活</strong>：同时激活的神经元很少</li>
                    </ul>
                </div>
                <div style="background: rgba(139, 92, 246, 0.1); padding: 1.5rem; border-radius: 0.5rem;">
                    <h3 style="color: var(--accent-purple); margin-bottom: 1rem;">💻 人工神经网络</h3>
                    <ul style="line-height: 2;">
                        <li><strong>连续值</strong>：使用实数表示激活</li>
                        <li><strong>全局优化</strong>：需要完整的误差信号</li>
                        <li><strong>批量训练</strong>：分离的训练和推理</li>
                        <li><strong>密集计算</strong>：所有神经元同时计算</li>
                    </ul>
                </div>
            </div>

            <!-- 可能的生物学习机制 -->
            <div class="collapsible mt-4 advanced-content" style="display: none;">
                <div class="collapsible-header" tabindex="0">
                    <div class="collapsible-title">
                        <span>🔬</span>
                        <span>可能的生物学习机制</span>
                        <span class="depth-indicator advanced">深入</span>
                    </div>
                    <svg class="collapsible-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polyline points="6 9 12 15 18 9"></polyline>
                    </svg>
                </div>
                <div class="collapsible-content">
                    <div class="collapsible-inner">
                        <h4>1. 预测编码（Predictive Coding）</h4>
                        <p>大脑不断预测感官输入，用预测误差来学习：</p>
                        <ul style="line-height: 1.8; margin-top: 0.5rem;">
                            <li>每层尝试预测下一层的活动</li>
                            <li>误差信号自然地反向传播</li>
                            <li>与贝叶斯大脑理论一致</li>
                        </ul>

                        <h4 style="margin-top: 1.5rem;">2. 反馈对齐（Feedback Alignment）</h4>
                        <p>使用随机反馈权重也能学习：</p>
                        <ul style="line-height: 1.8; margin-top: 0.5rem;">
                            <li>不需要精确的权重转置</li>
                            <li>更符合生物学约束</li>
                            <li>在某些任务上接近BP性能</li>
                        </ul>

                        <h4 style="margin-top: 1.5rem;">3. STDP（脉冲时序依赖可塑性）</h4>
                        <p>基于脉冲时序的局部学习规则：</p>
                        <ul style="line-height: 1.8; margin-top: 0.5rem;">
                            <li>前脉冲早于后脉冲→增强连接</li>
                            <li>前脉冲晚于后脉冲→减弱连接</li>
                            <li>完全局部的学习规则</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="tip info mt-4">
                <span class="tip-icon">💡</span>
                <div class="tip-content">
                    <strong>启发：</strong><br>
                    虽然BP可能不是生物学上精确的，但它启发我们理解：<br>
                    • 学习需要某种形式的误差信号<br>
                    • 分层处理和信用分配是关键<br>
                    • 局部学习规则可能更高效<br>
                    • 大脑的学习机制仍有很多未解之谜
                </div>
            </div>
        </section>

        <!-- 替代方案 -->
        <section id="alternatives" class="section-card">
            <h2 style="color: var(--accent-blue); margin-bottom: 1.5rem;">
                🚀 超越BP：替代方案探索
                <span class="depth-indicator advanced">深入</span>
            </h2>

            <!-- 替代算法介绍 -->
            <div class="concept-grid">
                <div class="concept-card what">
                    <h3 style="color: var(--accent-green);">合成梯度</h3>
                    <p><strong>思想：</strong>用小网络预测梯度</p>
                    <p><strong>优势：</strong>解耦层间依赖</p>
                    <p><strong>应用：</strong>异步分布式训练</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        DeepMind 2016年提出
                    </p>
                </div>
                <div class="concept-card how">
                    <h3 style="color: var(--accent-blue);">均衡传播</h3>
                    <p><strong>思想：</strong>基于能量的学习</p>
                    <p><strong>优势：</strong>更接近物理系统</p>
                    <p><strong>应用：</strong>神经形态硬件</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        Scellier & Bengio 2017
                    </p>
                </div>
                <div class="concept-card why">
                    <h3 style="color: var(--accent-red);">前向梯度</h3>
                    <p><strong>思想：</strong>只用前向传播</p>
                    <p><strong>优势：</strong>内存效率高</p>
                    <p><strong>应用：</strong>在线学习场景</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        正在研究中...
                    </p>
                </div>
                <div class="concept-card pitfall">
                    <h3 style="color: var(--accent-yellow);">进化策略</h3>
                    <p><strong>思想：</strong>无梯度优化</p>
                    <p><strong>优势：</strong>可并行化</p>
                    <p><strong>应用：</strong>强化学习</p>
                    <p style="color: var(--text-secondary); margin-top: 0.5rem;">
                        OpenAI使用于某些任务
                    </p>
                </div>
            </div>

            <!-- 未来展望 -->
            <div class="tip success mt-4">
                <span class="tip-icon">🔮</span>
                <div class="tip-content">
                    <strong>未来展望：</strong><br>
                    • BP仍是目前最有效的算法，但不是终点<br>
                    • 生物启发的算法可能带来突破<br>
                    • 硬件-算法协同设计是趋势<br>
                    • 量子计算可能带来全新范式
                </div>
            </div>
        </section>

        <!-- 总结 -->
        <section id="summary" class="section-card">
            <h2 style="color: var(--accent-green); margin-bottom: 1.5rem;">
                📝 总结：深度学习的引擎
            </h2>

            <!-- 知识总结 -->
            <div class="concept-grid">
                <div class="concept-card what">
                    <h3 style="color: var(--accent-green);">✓ 我们学到了什么</h3>
                    <ul style="line-height: 1.8;">
                        <li>反向传播的数学原理</li>
                        <li>链式法则的威力</li>
                        <li>自动微分的实现</li>
                        <li>梯度问题的诊断与解决</li>
                    </ul>
                </div>
                <div class="concept-card why">
                    <h3 style="color: var(--accent-red);">✓ 为什么重要</h3>
                    <ul style="line-height: 1.8;">
                        <li>使深度网络训练成为可能</li>
                        <li>自动化了最繁琐的计算</li>
                        <li>奠定了现代AI的基础</li>
                        <li>启发了新的研究方向</li>
                    </ul>
                </div>
                <div class="concept-card how">
                    <h3 style="color: var(--accent-blue);">✓ 如何应用</h3>
                    <ul style="line-height: 1.8;">
                        <li>使用现代框架的自动微分</li>
                        <li>监控和调试梯度流</li>
                        <li>选择合适的激活函数</li>
                        <li>应用各种优化技巧</li>
                    </ul>
                </div>
                <div class="concept-card pitfall">
                    <h3 style="color: var(--accent-yellow);">✓ 需要注意</h3>
                    <ul style="line-height: 1.8;">
                        <li>梯度消失/爆炸问题</li>
                        <li>数值稳定性</li>
                        <li>内存消耗</li>
                        <li>生物学合理性争议</li>
                    </ul>
                </div>
            </div>

            <!-- 关键要点 -->
            <div class="tip success mt-4">
                <span class="tip-icon">🎯</span>
                <div class="tip-content">
                    <strong>三个关键要点：</strong><br>
                    1. <strong>自动化的力量：</strong>BP将手算几小时的工作缩短到毫秒级<br>
                    2. <strong>链式法则的优雅：</strong>简单的数学规则解决复杂的优化问题<br>
                    3. <strong>持续的创新：</strong>从原始BP到现代变种，算法仍在进化
                </div>
            </div>

            <!-- 思考题 -->
            <div class="instant-practice mt-4">
                <h3 style="color: var(--accent-green); margin-bottom: 1rem;">🤔 深度思考</h3>
                <div class="practice-question">
                    如果要设计一个更接近生物学习的算法，你会考虑哪些特性？
                </div>
                <div style="background: rgba(139, 92, 246, 0.1); padding: 1.5rem; border-radius: 0.5rem; margin-top: 1rem;">
                    <p><strong>思考方向：</strong></p>
                    <ul style="line-height: 1.8;">
                        <li>局部性：只使用局部可获得的信息</li>
                        <li>异步性：不同部分可以独立更新</li>
                        <li>稀疏性：大部分神经元不激活</li>
                        <li>持续性：边预测边学习</li>
                    </ul>
                </div>
            </div>

            <!-- 下一章预告 -->
            <div style="background: var(--primary-gradient); padding: 2rem; border-radius: 1rem; margin-top: 2rem; color: white; text-align: center;">
                <h3 style="margin-bottom: 1rem;">🎬 下一章预告</h3>
                <h2 style="font-size: 2rem; margin-bottom: 1rem;">多层感知机：表达力与激活函数</h2>
                <p style="font-size: 1.1rem; opacity: 0.9;">
                    掌握了训练方法，现在来探索网络的表达能力。<br>
                    我们将学习如何设计网络结构，选择激活函数，理解深度与宽度的权衡。
                </p>
                <button class="btn" style="background: white; color: var(--accent-purple); margin-top: 1.5rem;" tabindex="0">
                    继续学习 →
                </button>
            </div>
        </section>

        <!-- 学习反馈 -->
        <section class="section-card">
            <h2 style="color: var(--accent-purple); margin-bottom: 1.5rem;">💬 学习反馈</h2>
            <div style="text-align: center;">
                <p style="font-size: 1.1rem; margin-bottom: 1.5rem;">这一章的内容对你有帮助吗？</p>
                <div style="display: flex; gap: 1rem; justify-content: center;">
                    <button class="btn btn-secondary" onclick="submitFeedback('helpful')" tabindex="0">
                        👍 很有帮助
                    </button>
                    <button class="btn btn-secondary" onclick="submitFeedback('ok')" tabindex="0">
                        😐 还可以
                    </button>
                    <button class="btn btn-secondary" onclick="submitFeedback('confusing')" tabindex="0">
                        😕 有点困惑
                    </button>
                </div>
                <div id="feedback-response" style="margin-top: 1rem; display: none;">
                    <p style="color: var(--accent-green);">感谢你的反馈！我们会继续改进。</p>
                </div>
            </div>
        </section>
    </div>
</main>

<!-- JavaScript代码 -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
<script>
    // 初始化代码高亮
    hljs.highlightAll();

    // 初始化数学公式渲染
    renderMathInElement(document.body, {
        delimiters: [
            {left: '$', right: '$', display: true},
            {left: ', right: ', display: false}
        ]
    });

    // 全局变量
    let currentDifficulty = 'beginner';
    let buddyMessages = {
        beginner: [
            "BP算法的核心：误差从后向前流动！",
            "记住：梯度 = 局部梯度 × 上游梯度",
            "如果梯度消失了，试试ReLU激活函数。"
        ],
        intermediate: [
            "链式法则是BP的数学基础，多练习！",
            "Hook是调试神经网络的利器。",
            "梯度裁剪可以防止训练不稳定。"
        ],
        advanced: [
            "考虑一下：BP真的是生物学合理的吗？",
            "合成梯度和均衡传播值得深入研究。",
            "量子反向传播可能是未来方向。"
        ]
    };

    // 导航功能
    const sidebar = document.getElementById('sidebar');
    const sidebarOverlay = document.getElementById('sidebar-overlay');
    const toggleSidebarBtn = document.getElementById('toggle-sidebar');

    toggleSidebarBtn.addEventListener('click', () => {
        sidebar.classList.toggle('open');
        sidebarOverlay.classList.toggle('active');
    });

    sidebarOverlay.addEventListener('click', () => {
        sidebar.classList.remove('open');
        sidebarOverlay.classList.remove('active');
    });

    // 学习伙伴功能
    const learningBuddy = document.getElementById('learning-buddy');
    const toggleBuddyBtn = document.getElementById('toggle-buddy');
    const minimizeBuddyBtn = document.getElementById('minimize-buddy');
    const closeBuddyBtn = document.getElementById('close-buddy');
    const buddyAvatar = document.getElementById('buddy-avatar');

    toggleBuddyBtn.addEventListener('click', () => {
        learningBuddy.classList.toggle('active');
    });

    minimizeBuddyBtn.addEventListener('click', () => {
        learningBuddy.classList.toggle('minimized');
    });

    closeBuddyBtn.addEventListener('click', () => {
        learningBuddy.classList.remove('active');
    });

    buddyAvatar.addEventListener('click', () => {
        if (learningBuddy.classList.contains('minimized')) {
            learningBuddy.classList.remove('minimized');
        }
    });

    // 学习伙伴提示功能
    function getBuddyHint() {
        const messages = buddyMessages[currentDifficulty];
        const randomMessage = messages[Math.floor(Math.random() * messages.length)];
        updateBuddyMessage(randomMessage);
    }

    function getBuddySummary() {
        const summary = `
        本章核心要点：<br>
        1. 反向传播 = 链式法则 + 动态规划<br>
        2. 自动微分让深度学习成为可能<br>
        3. 梯度问题需要多种技巧解决<br>
        4. BP可能不是生物学的，但很有效
    `;
        updateBuddyMessage(summary);
    }

    function updateBuddyMessage(message) {
        const messageElement = document.querySelector('.buddy-message p');
        messageElement.innerHTML = message;

        // 添加动画效果
        messageElement.style.animation = 'none';
        setTimeout(() => {
            messageElement.style.animation = 'fadeIn 0.5s ease';
        }, 10);
    }

    // 主题切换
    const toggleThemeBtn = document.getElementById('toggle-theme');
    toggleThemeBtn.addEventListener('click', () => {
        const currentTheme = document.body.getAttribute('data-theme');
        const newTheme = currentTheme === 'light' ? 'dark' : 'light';
        document.body.setAttribute('data-theme', newTheme);
        localStorage.setItem('theme', newTheme);
    });

    // 加载保存的主题
    const savedTheme = localStorage.getItem('theme') || 'dark';
    document.body.setAttribute('data-theme', savedTheme);

    // 难度选择功能
    const difficultyOptions = document.querySelectorAll('.difficulty-option');
    difficultyOptions.forEach(option => {
        option.addEventListener('click', () => {
            const difficulty = option.querySelector('input').value;
            currentDifficulty = difficulty;

            // 更新选中状态
            difficultyOptions.forEach(opt => opt.classList.remove('active'));
            option.classList.add('active');

            // 更新内容显示
            updateContentVisibility(difficulty);

            // 显示通知
            showNotification(`已切换到${option.textContent.trim()}模式`);
        });
    });

    function updateContentVisibility(difficulty) {
        // 根据难度显示/隐藏内容
        const beginnerContent = document.querySelectorAll('.beginner-content');
        const intermediateContent = document.querySelectorAll('.intermediate-content');
        const advancedContent = document.querySelectorAll('.advanced-content');

        // 默认显示所有初学者内容
        beginnerContent.forEach(el => el.style.display = 'block');

        if (difficulty === 'beginner') {
            intermediateContent.forEach(el => el.style.display = 'none');
            advancedContent.forEach(el => el.style.display = 'none');
        } else if (difficulty === 'intermediate') {
            intermediateContent.forEach(el => el.style.display = 'block');
            advancedContent.forEach(el => el.style.display = 'none');
        } else {
            intermediateContent.forEach(el => el.style.display = 'block');
            advancedContent.forEach(el => el.style.display = 'block');
        }
    }

    // 折叠功能
    const collapsibles = document.querySelectorAll('.collapsible-header');
    collapsibles.forEach(header => {
        header.addEventListener('click', () => {
            const collapsible = header.parentElement;
            collapsible.classList.toggle('expanded');
        });

        // 键盘支持
        header.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' || e.key === ' ') {
                e.preventDefault();
                header.click();
            }
        });
    });

    // 滚动进度条
    function updateProgressBar() {
        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
        const scrollHeight = document.documentElement.scrollHeight - document.documentElement.clientHeight;
        const scrollPercentage = (scrollTop / scrollHeight) * 100;
        document.getElementById('progress-bar').style.width = scrollPercentage + '%';
    }

    window.addEventListener('scroll', updateProgressBar);

    // 导航高亮
    const sections = document.querySelectorAll('section[id]');
    const navItems = document.querySelectorAll('.toc-item');

    function updateNavHighlight() {
        const scrollPosition = window.pageYOffset + 100;

        sections.forEach((section, index) => {
            const sectionTop = section.offsetTop;
            const sectionHeight = section.offsetHeight;

            if (scrollPosition >= sectionTop && scrollPosition < sectionTop + sectionHeight) {
                navItems.forEach(item => item.classList.remove('active'));
                if (navItems[index]) {
                    navItems[index].classList.add('active');
                }
            }
        });
    }

    window.addEventListener('scroll', updateNavHighlight);

    // 成就系统
    let completedSections = new Set();
    let achievements = {
        firstConcept: false,
        allPractice: false,
        deepDive: false,
        finishChapter: false
    };

    function checkAchievements() {
        const totalSections = sections.length;
        const completed = completedSections.size;

        if (completed === 1 && !achievements.firstConcept) {
            achievements.firstConcept = true;
            showAchievement("初识反向传播", "完成了第一个概念的学习！");
        }

        if (completed === totalSections && !achievements.finishChapter) {
            achievements.finishChapter = true;
            showAchievement("BP大师", "完成了整章的学习！");
        }

        updateAchievementProgress(completed, totalSections);
    }

    function showAchievement(title, description) {
        const popup = document.getElementById('achievement-popup');
        const textElement = document.getElementById('achievement-text');

        textElement.textContent = description;
        popup.classList.add('show');

        setTimeout(() => {
            popup.classList.remove('show');
        }, 5000);
    }

    function updateAchievementProgress(completed, total) {
        const progress = (completed / total) * 100;
        document.getElementById('achievement-progress').style.width = progress + '%';
        document.getElementById('achievement-count').textContent = completed;
    }

    // 网络复杂度可视化
    class NetworkComplexityVisualizer {
        constructor(canvasId) {
            this.canvas = document.getElementById(canvasId);
            this.ctx = this.canvas.getContext('2d');
            this.width = this.canvas.width;
            this.height = this.canvas.height;

            this.layers = 3;
            this.neuronsPerLayer = 4;

            this.bindControls();
            this.draw();
        }

        bindControls() {
            const layersSlider = document.getElementById('layers-slider');
            const neuronsSlider = document.getElementById('neurons-slider');

            layersSlider.addEventListener('input', (e) => {
                this.layers = parseInt(e.target.value);
                document.getElementById('layers-value').textContent = this.layers;
                this.updateStats();
                this.draw();
            });

            neuronsSlider.addEventListener('input', (e) => {
                this.neuronsPerLayer = parseInt(e.target.value);
                document.getElementById('neurons-value').textContent = this.neuronsPerLayer;
                this.updateStats();
                this.draw();
            });
        }

        updateStats() {
            // 计算参数数量
            const params = (this.layers - 1) * this.neuronsPerLayer * this.neuronsPerLayer;
            document.getElementById('param-count').textContent = params.toLocaleString();

            // 计算梯度计算次数（简化）
            const gradients = params * 3; // 前向、反向、更新
            document.getElementById('gradient-count').textContent = gradients.toLocaleString();

            // 估计手算时间（每个梯度30秒）
            const minutes = Math.ceil(gradients * 0.5);
            const hours = Math.floor(minutes / 60);
            const remainingMinutes = minutes % 60;

            let timeStr = '';
            if (hours > 0) {
                timeStr = `${hours}小时${remainingMinutes}分钟`;
            } else {
                timeStr = `${minutes}分钟`;
            }
            document.getElementById('time-estimate').textContent = timeStr;
        }

        draw() {
            this.ctx.clearRect(0, 0, this.width, this.height);

            const layerSpacing = this.width / (this.layers + 1);
            const neuronSpacing = this.height / (this.neuronsPerLayer + 1);

            // 绘制连接
            for (let l = 0; l < this.layers - 1; l++) {
                const x1 = (l + 1) * layerSpacing;
                const x2 = (l + 2) * layerSpacing;

                for (let i = 0; i < this.neuronsPerLayer; i++) {
                    const y1 = (i + 1) * neuronSpacing;

                    for (let j = 0; j < this.neuronsPerLayer; j++) {
                        const y2 = (j + 1) * neuronSpacing;

                        // 根据层数调整透明度
                        const opacity = Math.max(0.1, 1 - l * 0.15);
                        this.ctx.strokeStyle = `rgba(139, 92, 246, ${opacity})`;
                        this.ctx.lineWidth = 1;

                        this.ctx.beginPath();
                        this.ctx.moveTo(x1, y1);
                        this.ctx.lineTo(x2, y2);
                        this.ctx.stroke();
                    }
                }
            }

            // 绘制神经元
            for (let l = 0; l < this.layers; l++) {
                const x = (l + 1) * layerSpacing;

                for (let i = 0; i < this.neuronsPerLayer; i++) {
                    const y = (i + 1) * neuronSpacing;

                    // 神经元颜色
                    let color;
                    if (l === 0) {
                        color = '#3b82f6'; // 输入层
                    } else if (l === this.layers - 1) {
                        color = '#22c55e'; // 输出层
                    } else {
                        color = '#8b5cf6'; // 隐藏层
                    }

                    this.ctx.fillStyle = color;
                    this.ctx.strokeStyle = '#1f2937';
                    this.ctx.lineWidth = 2;

                    this.ctx.beginPath();
                    this.ctx.arc(x, y, 15, 0, Math.PI * 2);
                    this.ctx.fill();
                    this.ctx.stroke();
                }

                // 层标签
                this.ctx.fillStyle = '#f1f5f9';
                this.ctx.font = '14px sans-serif';
                this.ctx.textAlign = 'center';

                let label;
                if (l === 0) {
                    label = '输入层';
                } else if (l === this.layers - 1) {
                    label = '输出层';
                } else {
                    label = `隐藏层${l}`;
                }

                this.ctx.fillText(label, x, this.height - 20);
            }
        }
    }

    // 创建网络复杂度可视化
    const networkComplexityViz = new NetworkComplexityVisualizer('network-complexity-canvas');

    // 链式法则动画
    function animateChainRule() {
        const svg = document.getElementById('chain-rule-svg');
        svg.innerHTML = ''; // 清空

        // 创建节点
        const nodes = [
            {x: 100, y: 200, label: 'x', color: '#3b82f6'},
            {x: 250, y: 200, label: 'h₁', color: '#8b5cf6'},
            {x: 400, y: 200, label: 'h₂', color: '#8b5cf6'},
            {x: 550, y: 200, label: 'y', color: '#22c55e'},
            {x: 700, y: 200, label: 'L', color: '#ef4444'}
        ];

        // 绘制节点
        nodes.forEach((node, i) => {
            const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
            circle.setAttribute('cx', node.x);
            circle.setAttribute('cy', node.y);
            circle.setAttribute('r', 30);
            circle.setAttribute('fill', node.color);
            circle.setAttribute('stroke', '#1f2937');
            circle.setAttribute('stroke-width', 2);
            svg.appendChild(circle);

            const text = document.createElementNS('http://www.w3.org/2000/svg', 'text');
            text.setAttribute('x', node.x);
            text.setAttribute('y', node.y + 5);
            text.setAttribute('text-anchor', 'middle');
            text.setAttribute('fill', 'white');
            text.setAttribute('font-size', '18');
            text.textContent = node.label;
            svg.appendChild(text);
        });

        // 前向传播动画
        let step = 0;
        const animateForward = () => {
            if (step < nodes.length - 1) {
                const line = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                line.setAttribute('x1', nodes[step].x + 30);
                line.setAttribute('y1', nodes[step].y);
                line.setAttribute('x2', nodes[step + 1].x - 30);
                line.setAttribute('y2', nodes[step + 1].y);
                line.setAttribute('stroke', '#22c55e');
                line.setAttribute('stroke-width', 3);
                line.setAttribute('marker-end', 'url(#arrowhead-green)');
                line.style.opacity = 0;
                svg.appendChild(line);

                // 渐显动画
                let opacity = 0;
                const fadeIn = setInterval(() => {
                    opacity += 0.1;
                    line.style.opacity = opacity;
                    if (opacity >= 1) {
                        clearInterval(fadeIn);
                        step++;
                        setTimeout(animateForward, 500);
                    }
                }, 50);
            } else {
                // 开始反向传播
                setTimeout(animateBackward, 1000);
            }
        };

        // 反向传播动画
        let backStep = nodes.length - 1;
        const animateBackward = () => {
            if (backStep > 0) {
                const line = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                line.setAttribute('x1', nodes[backStep].x - 30);
                line.setAttribute('y1', nodes[backStep].y);
                line.setAttribute('x2', nodes[backStep - 1].x + 30);
                line.setAttribute('y2', nodes[backStep - 1].y);
                line.setAttribute('stroke', '#ef4444');
                line.setAttribute('stroke-width', 3);
                line.setAttribute('marker-end', 'url(#arrowhead-red)');
                line.setAttribute('stroke-dasharray', '5,5');
                line.style.opacity = 0;
                svg.appendChild(line);

                // 添加梯度标签
                const gradientText = document.createElementNS('http://www.w3.org/2000/svg', 'text');
                gradientText.setAttribute('x', (nodes[backStep].x + nodes[backStep - 1].x) / 2);
                gradientText.setAttribute('y', nodes[backStep].y - 20);
                gradientText.setAttribute('text-anchor', 'middle');
                gradientText.setAttribute('fill', '#ef4444');
                gradientText.setAttribute('font-size', '14');
                gradientText.textContent = `∂L/∂${nodes[backStep - 1].label}`;
                gradientText.style.opacity = 0;
                svg.appendChild(gradientText);

                // 渐显动画
                let opacity = 0;
                const fadeIn = setInterval(() => {
                    opacity += 0.1;
                    line.style.opacity = opacity;
                    gradientText.style.opacity = opacity;
                    if (opacity >= 1) {
                        clearInterval(fadeIn);
                        backStep--;
                        setTimeout(animateBackward, 500);
                    }
                }, 50);
            }
        };

        // 创建箭头标记
        const defs = document.createElementNS('http://www.w3.org/2000/svg', 'defs');

        // 绿色箭头
        const markerGreen = document.createElementNS('http://www.w3.org/2000/svg', 'marker');
        markerGreen.setAttribute('id', 'arrowhead-green');
        markerGreen.setAttribute('markerWidth', '10');
        markerGreen.setAttribute('markerHeight', '10');
        markerGreen.setAttribute('refX', '9');
        markerGreen.setAttribute('refY', '3');
        markerGreen.setAttribute('orient', 'auto');

        const polygonGreen = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
        polygonGreen.setAttribute('points', '0 0, 10 3, 0 6');
        polygonGreen.setAttribute('fill', '#22c55e');
        markerGreen.appendChild(polygonGreen);
        defs.appendChild(markerGreen);

        // 红色箭头
        const markerRed = document.createElementNS('http://www.w3.org/2000/svg', 'marker');
        markerRed.setAttribute('id', 'arrowhead-red');
        markerRed.setAttribute('markerWidth', '10');
        markerRed.setAttribute('markerHeight', '10');
        markerRed.setAttribute('refX', '9');
        markerRed.setAttribute('refY', '3');
        markerRed.setAttribute('orient', 'auto');

        const polygonRed = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
        polygonRed.setAttribute('points', '0 0, 10 3, 0 6');
        polygonRed.setAttribute('fill', '#ef4444');
        markerRed.appendChild(polygonRed);
        defs.appendChild(markerRed);

        svg.appendChild(defs);

        // 开始动画
        animateForward();
    }

    function resetChainRule() {
        const svg = document.getElementById('chain-rule-svg');
        svg.innerHTML = '';

        // 添加提示文字
        const text = document.createElementNS('http://www.w3.org/2000/svg', 'text');
        text.setAttribute('x', 400);
        text.setAttribute('y', 200);
        text.setAttribute('text-anchor', 'middle');
        text.setAttribute('fill', '#cbd5e1');
        text.setAttribute('font-size', '16');
        text.textContent = '点击"播放动画"查看链式法则的工作原理';
        svg.appendChild(text);
    }

    // 初始化链式法则SVG
    resetChainRule();

    // BP算法步骤演示
    class BPAlgorithmDemo {
        constructor() {
            this.canvas = document.getElementById('bp-algorithm-canvas');
            this.ctx = this.canvas.getContext('2d');
            this.width = this.canvas.width;
            this.height = this.canvas.height;

            this.currentStep = 0;
            this.animating = false;
            this.speed = 1500;

            // 简单的3层网络
            this.network = {
                layers: [2, 3, 1],
                weights: [
                    [[0.5, -0.3], [0.2, 0.8], [-0.1, 0.4]],
                    [[0.6], [-0.2], [0.3]]
                ],
                activations: [],
                deltas: []
            };

            this.bindControls();
            this.draw();
        }

        bindControls() {
            const speedSlider = document.getElementById('bp-speed-slider');
            speedSlider.addEventListener('input', (e) => {
                this.speed = parseInt(e.target.value);
                document.getElementById('bp-speed-value').textContent = this.speed + 'ms';
            });
        }

        draw() {
            this.ctx.clearRect(0, 0, this.width, this.height);

            // 绘制网络结构
            const layerPositions = [150, 400, 650];
            const neuronCounts = this.network.layers;

            // 绘制连接
            for (let l = 0; l < layerPositions.length - 1; l++) {
                const x1 = layerPositions[l];
                const x2 = layerPositions[l + 1];
                const n1 = neuronCounts[l];
                const n2 = neuronCounts[l + 1];

                for (let i = 0; i < n1; i++) {
                    const y1 = this.height / 2 + (i - (n1 - 1) / 2) * 80;

                    for (let j = 0; j < n2; j++) {
                        const y2 = this.height / 2 + (j - (n2 - 1) / 2) * 80;

                        // 根据步骤改变颜色
                        let color = 'rgba(139, 92, 246, 0.3)';
                        let width = 2;

                        if (this.currentStep === 1 && l === 0) {
                            // 前向传播
                            color = 'rgba(34, 197, 94, 0.8)';
                            width = 3;
                        } else if (this.currentStep === 3 && l === 1) {
                            // 输出层误差
                            color = 'rgba(239, 68, 68, 0.8)';
                            width = 3;
                        } else if (this.currentStep === 4 && l === 0) {
                            // 反向传播
                            color = 'rgba(239, 68, 68, 0.8)';
                            width = 3;
                        }

                        this.ctx.strokeStyle = color;
                        this.ctx.lineWidth = width;
                        this.ctx.beginPath();
                        this.ctx.moveTo(x1, y1);
                        this.ctx.lineTo(x2, y2);
                        this.ctx.stroke();

                        // 显示权重值
                        if (this.currentStep >= 2) {
                            this.ctx.fillStyle = '#cbd5e1';
                            this.ctx.font = '12px monospace';
                            this.ctx.textAlign = 'center';
                            const weight = this.network.weights[l][j][i];
                            this.ctx.fillText(
                                weight.toFixed(2),
                                (x1 + x2) / 2,
                                (y1 + y2) / 2
                            );
                        }
                    }
                }
            }

            // 绘制神经元
            for (let l = 0; l < layerPositions.length; l++) {
                const x = layerPositions[l];
                const n = neuronCounts[l];

                for (let i = 0; i < n; i++) {
                    const y = this.height / 2 + (i - (n - 1) / 2) * 80;

                    // 神经元颜色
                    let fillColor = '#8b5cf6';
                    if (l === 0) fillColor = '#3b82f6';
                    else if (l === layerPositions.length - 1) fillColor = '#22c55e';

                    // 高亮当前处理的层
                    let strokeWidth = 2;
                    let strokeColor = '#1f2937';

                    if ((this.currentStep === 1 && l === 0) ||
                        (this.currentStep === 2 && l === 1) ||
                        (this.currentStep === 3 && l === 2) ||
                        (this.currentStep === 4 && l === 1) ||
                        (this.currentStep === 5 && l === 0)) {
                        strokeWidth = 4;
                        strokeColor = '#fbbf24';
                    }

                    this.ctx.fillStyle = fillColor;
                    this.ctx.strokeStyle = strokeColor;
                    this.ctx.lineWidth = strokeWidth;

                    this.ctx.beginPath();
                    this.ctx.arc(x, y, 25, 0, Math.PI * 2);
                    this.ctx.fill();
                    this.ctx.stroke();

                    // 显示激活值或误差
                    if (this.currentStep >= 2 && this.network.activations[l]) {
                        this.ctx.fillStyle = 'white';
                        this.ctx.font = '14px sans-serif';
                        this.ctx.textAlign = 'center';
                        this.ctx.fillText(
                            this.network.activations[l][i].toFixed(2),
                            x, y + 5
                        );
                    }

                    // 显示误差项
                    if (this.currentStep >= 3 && this.network.deltas[l]) {
                        this.ctx.fillStyle = '#ef4444';
                        this.ctx.font = '12px sans-serif';
                        this.ctx.textAlign = 'center';
                        this.ctx.fillText(
                            `δ=${this.network.deltas[l][i].toFixed(2)}`,
                            x, y + 40
                        );
                    }
                }

                // 层标签
                this.ctx.fillStyle = '#f1f5f9';
                this.ctx.font = '14px sans-serif';
                this.ctx.textAlign = 'center';

                let label = l === 0 ? '输入层' : l === layerPositions.length - 1 ? '输出层' : `隐藏层`;
                this.ctx.fillText(label, x, 50);
            }
        }

        async step() {
            const steps = [
                { name: "初始化", description: "准备网络结构和参数" },
                { name: "前向传播 - 输入层", description: "输入数据: x = [0.5, -0.3]" },
                { name: "前向传播 - 隐藏层", description: "计算隐藏层激活: h = σ(Wx + b)" },
                { name: "前向传播 - 输出层", description: "计算输出: y = σ(Wh + b) = 0.73" },
                { name: "计算输出误差", description: "δ³ = (y - t) * σ'(z³) = 0.23" },
                { name: "反向传播到隐藏层", description: "δ² = W³ᵀδ³ ⊙ σ'(z²)" },
                { name: "计算权重梯度", description: "∂L/∂W = δ · aᵀ" },
                { name: "更新参数", description: "W = W - η * ∂L/∂W" }
            ];

            if (this.currentStep >= steps.length) {
                this.currentStep = 0;
            }

            // 更新显示
            document.getElementById('bp-current-step').textContent = steps[this.currentStep].name;
            document.getElementById('bp-step-details').textContent = steps[this.currentStep].description;

            // 模拟计算
            switch (this.currentStep) {
                case 0:
                    this.network.activations = [];
                    this.network.deltas = [];
                    break;
                case 1:
                    this.network.activations[0] = [0.5, -0.3];
                    break;
                case 2:
                    this.network.activations[1] = [0.62, 0.45, 0.38];
                    break;
                case 3:
                    this.network.activations[2] = [0.73];
                    break;
                case 4:
                    this.network.deltas[2] = [0.23];
                    break;
                case 5:
                    this.network.deltas[1] = [0.08, -0.03, 0.04];
                    break;
            }

            this.draw();
            this.currentStep++;
        }

        async animate() {
            if (this.animating) {
                await this.step();
                setTimeout(() => this.animate(), this.speed);
            }
        }
    }

    const bpDemo = new BPAlgorithmDemo();

    function startBPAnimation() {
        bpDemo.animating = !bpDemo.animating;
        document.getElementById('train-button').textContent =
            bpDemo.animating ? '⏸️ 暂停' : '▶️ 开始演示';

        if (bpDemo.animating) {
            bpDemo.animate();
        }
    }

    function stepBPAnimation() {
        bpDemo.animating = false;
        document.getElementById('train-button').textContent = '▶️ 开始演示';
        bpDemo.step();
    }

    // 梯度流可视化
    class GradientFlowVisualizer {
        constructor() {
            this.canvas = document.getElementById('gradient-flow-canvas');
            this.ctx = this.canvas.getContext('2d');
            this.width = this.canvas.width;
            this.height = this.canvas.height;

            this.networkDepth = 5;
            this.activationType = 'relu';
            this.animating = false;
            this.particles = [];

            this.bindControls();
            this.initNetwork();
            this.draw();
        }

        bindControls() {
            const depthSelect = document.getElementById('network-depth');
            const activationSelect = document.getElementById('activation-type');

            depthSelect.addEventListener('change', (e) => {
                this.networkDepth = parseInt(e.target.value);
                this.initNetwork();
                this.draw();
            });

            activationSelect.addEventListener('change', (e) => {
                this.activationType = e.target.value;
                this.initNetwork();
                this.draw();
            });
        }

        initNetwork() {
            // 初始化网络参数
            this.layers = [];
            this.gradients = [];

            for (let i = 0; i < this.networkDepth; i++) {
                this.layers.push({
                    neurons: 5,
                    activation: Math.random() * 0.5 + 0.5,
                    gradient: 1.0
                });
            }

            // 计算梯度衰减
            this.calculateGradientFlow();
        }

        calculateGradientFlow() {
            let grad = 1.0;

            for (let i = this.networkDepth - 1; i >= 0; i--) {
                // 根据激活函数计算梯度衰减
                let decay;
                switch (this.activationType) {
                    case 'sigmoid':
                        decay = 0.25; // sigmoid导数最大值
                        break;
                    case 'tanh':
                        decay = 0.5; // tanh导数衰减
                        break;
                    case 'relu':
                        decay = 0.9; // ReLU大部分情况下为1
                        break;
                }

                grad *= decay;
                this.layers[i].gradient = grad;
            }

            // 更新显示
            this.updateInfo();
        }

        updateInfo() {
            const firstLayerGrad = this.layers[0].gradient;
            const lastLayerGrad = this.layers[this.networkDepth - 1].gradient;

            document.getElementById('forward-info').textContent =
                `激活值范围: [0.5, 1.0]`;

            document.getElementById('backward-info').textContent =
                `梯度衰减: ${(firstLayerGrad / lastLayerGrad).toExponential(2)}`;

            // 健康度评估
            let health;
            if (firstLayerGrad < 1e-6) {
                health = '❌ 严重梯度消失';
            } else if (firstLayerGrad < 1e-3) {
                health = '⚠️ 轻度梯度消失';
            } else if (firstLayerGrad > 1e3) {
                health = '🔥 梯度爆炸风险';
            } else {
                health = '✅ 梯度流动正常';
            }

            document.getElementById('gradient-health').textContent = health;
        }

        draw() {
            this.ctx.clearRect(0, 0, this.width, this.height);

            const layerSpacing = this.width / (this.networkDepth + 1);
            const neuronRadius = 20;

            // 绘制网络
            for (let l = 0; l < this.networkDepth; l++) {
                const x = (l + 1) * layerSpacing;
                const layer = this.layers[l];

                // 绘制神经元
                for (let n = 0; n < layer.neurons; n++) {
                    const y = this.height / 2 + (n - 2) * 50;

                    // 根据梯度大小调整颜色
                    const gradientStrength = Math.log10(layer.gradient + 1e-10) / 10 + 1;
                    const opacity = Math.max(0.2, Math.min(1, gradientStrength));

                    let color;
                    if (layer.gradient < 1e-6) {
                        color = `rgba(59, 130, 246, ${opacity})`; // 蓝色：梯度消失
                    } else if (layer.gradient > 1e3) {
                        color = `rgba(239, 68, 68, ${opacity})`; // 红色：梯度爆炸
                    } else {
                        color = `rgba(34, 197, 94, ${opacity})`; // 绿色：正常
                    }

                    this.ctx.fillStyle = color;
                    this.ctx.strokeStyle = '#1f2937';
                    this.ctx.lineWidth = 2;

                    this.ctx.beginPath();
                    this.ctx.arc(x, y, neuronRadius, 0, Math.PI * 2);
                    this.ctx.fill();
                    this.ctx.stroke();
                }

                // 绘制连接
                if (l < this.networkDepth - 1) {
                    const nextX = (l + 2) * layerSpacing;

                    for (let n1 = 0; n1 < layer.neurons; n1++) {
                        const y1 = this.height / 2 + (n1 - 2) * 50;

                        for (let n2 = 0; n2 < this.layers[l + 1].neurons; n2++) {
                            const y2 = this.height / 2 + (n2 - 2) * 50;

                            const gradient = Math.sqrt(layer.gradient * this.layers[l + 1].gradient);
                            const opacity = Math.max(0.1, Math.min(0.8, gradient));

                            this.ctx.strokeStyle = `rgba(139, 92, 246, ${opacity})`;
                            this.ctx.lineWidth = Math.max(1, gradient * 2);

                            this.ctx.beginPath();
                            this.ctx.moveTo(x + neuronRadius, y1);
                            this.ctx.lineTo(nextX - neuronRadius, y2);
                            this.ctx.stroke();
                        }
                    }
                }

                // 显示梯度值
                this.ctx.fillStyle = '#f1f5f9';
                this.ctx.font = '12px monospace';
                this.ctx.textAlign = 'center';
                this.ctx.fillText(
                    `∇=${layer.gradient.toExponential(1)}`,
                    x, this.height - 40
                );
            }

            // 绘制流动粒子
            if (this.animating) {
                this.updateParticles();
                this.drawParticles();
            }
        }

        updateParticles() {
            // 添加新粒子
            if (Math.random() < 0.1) {
                this.particles.push({
                    x: this.width - 50,
                    y: this.height / 2 + (Math.random() - 0.5) * 200,
                    vx: -2,
                    vy: (Math.random() - 0.5) * 0.5,
                    life: 1.0
                });
            }

            // 更新粒子
            this.particles = this.particles.filter(p => {
                p.x += p.vx;
                p.y += p.vy;
                p.life -= 0.01;

                return p.life > 0 && p.x > 0;
            });
        }

        drawParticles() {
            this.particles.forEach(p => {
                this.ctx.fillStyle = `rgba(239, 68, 68, ${p.life * 0.8})`;
                this.ctx.beginPath();
                this.ctx.arc(p.x, p.y, 3, 0, Math.PI * 2);
                this.ctx.fill();
            });
        }

        animate() {
            if (this.animating) {
                this.draw();
                requestAnimationFrame(() => this.animate());
            }
        }
    }

    const gradientFlowViz = new GradientFlowVisualizer();

    function startGradientFlow() {
        gradientFlowViz.animating = !gradientFlowViz.animating;
        document.querySelector('[onclick="startGradientFlow()"]').textContent =
            gradientFlowViz.animating ? '⏸️ 暂停' : '🌊 开始流动';

        if (gradientFlowViz.animating) {
            gradientFlowViz.animate();
        }
    }

    function resetGradientFlow() {
        gradientFlowViz.animating = false;
        gradientFlowViz.particles = [];
        gradientFlowViz.initNetwork();
        gradientFlowViz.draw();
        document.querySelector('[onclick="startGradientFlow()"]').textContent = '🌊 开始流动';
    }

    // MNIST数字可视化
    function drawMNISTDigit(canvasId, digit) {
        const canvas = document.getElementById(canvasId);
        const ctx = canvas.getContext('2d');

        // 简化的数字表示
        const patterns = {
            0: [[0,1,1,0],[1,0,0,1],[1,0,0,1],[0,1,1,0]],
            1: [[0,1,0,0],[1,1,0,0],[0,1,0,0],[1,1,1,0]],
            2: [[1,1,1,0],[0,0,1,0],[0,1,0,0],[1,1,1,0]],
            3: [[1,1,1,0],[0,1,1,0],[0,0,1,0],[1,1,1,0]],
            4: [[1,0,1,0],[1,0,1,0],[1,1,1,0],[0,0,1,0]]
        };

        const pattern = patterns[digit] || patterns[0];
        const cellSize = 14;

        ctx.fillStyle = '#1f2937';
        ctx.fillRect(0, 0, 56, 56);

        pattern.forEach((row, y) => {
            row.forEach((val, x) => {
                if (val) {
                    ctx.fillStyle = '#f1f5f9';
                    ctx.fillRect(x * cellSize, y * cellSize, cellSize - 2, cellSize - 2);
                }
            });
        });
    }

    // 初始化MNIST展示
    for (let i = 0; i < 5; i++) {
        drawMNISTDigit(`mnist-${i}`, i);
    }

    // 梯度实验
    function runGradientExperiment() {
        const depth = parseInt(document.getElementById('depth-slider').value);
        const activation = document.getElementById('activation-select').value;
        const initialization = document.getElementById('init-select').value;

        // 模拟梯度传播
        let gradient = 1.0;
        let factor;

        switch (activation) {
            case 'sigmoid':
                factor = 0.25;
                break;
            case 'tanh':
                factor = 0.5;
                break;
            case 'relu':
                factor = 0.8;
                break;
        }

        // 初始化的影响
        switch (initialization) {
            case 'random':
                factor *= 0.7;
                break;
            case 'xavier':
                factor *= 0.9;
                break;
            case 'he':
                factor *= 0.95;
                break;
        }

        const finalGradient = Math.pow(factor, depth);

        // 绘制结果
        const canvas = document.getElementById('gradient-experiment-canvas');
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // 绘制梯度衰减曲线
        ctx.strokeStyle = '#8b5cf6';
        ctx.lineWidth = 3;
        ctx.beginPath();

        for (let i = 0; i <= depth; i++) {
            const x = (i / depth) * canvas.width;
            const grad = Math.pow(factor, i);
            const y = canvas.height - (Math.log10(grad + 1e-10) + 10) / 20 * canvas.height;

            if (i === 0) {
                ctx.moveTo(x, y);
            } else {
                ctx.lineTo(x, y);
            }
        }

        ctx.stroke();

        // 绘制参考线
        ctx.strokeStyle = 'rgba(239, 68, 68, 0.5)';
        ctx.lineWidth = 1;
        ctx.setLineDash([5, 5]);

        // 梯度消失阈值线
        const vanishY = canvas.height - (Math.log10(1e-6) + 10) / 20 * canvas.height;
        ctx.beginPath();
        ctx.moveTo(0, vanishY);
        ctx.lineTo(canvas.width, vanishY);
        ctx.stroke();

        ctx.fillStyle = '#ef4444';
        ctx.font = '12px sans-serif';
        ctx.fillText('梯度消失阈值', 10, vanishY - 5);

        // 显示结果
        document.getElementById('experiment-results').style.display = 'block';

        let analysis;
        if (finalGradient < 1e-6) {
            analysis = `<strong>结果：严重梯度消失！</strong><br>
                       最深层梯度仅为 ${finalGradient.toExponential(2)}<br>
                       建议：使用ReLU激活函数和批归一化`;
        } else if (finalGradient < 1e-3) {
            analysis = `<strong>结果：轻度梯度消失</strong><br>
                       最深层梯度为 ${finalGradient.toExponential(2)}<br>
                       建议：考虑使用残差连接或更好的初始化`;
        } else {
            analysis = `<strong>结果：梯度流动正常</strong><br>
                       最深层梯度为 ${finalGradient.toFixed(4)}<br>
                       这个配置适合训练深度网络`;
        }

        document.getElementById('experiment-analysis').innerHTML = analysis;
    }

    // 更新深度显示
    document.getElementById('depth-slider').addEventListener('input', (e) => {
        document.getElementById('depth-value').textContent = e.target.value + '层';
    });

    // 练习题功能
    const practiceOptions = document.querySelectorAll('.practice-option');
    practiceOptions.forEach(option => {
        option.addEventListener('click', function() {
            const answer = this.getAttribute('data-answer');
            const questionNumber = this.closest('.instant-practice').querySelector('.practice-feedback').id.split('-').pop();

            // 清除之前的选择
            this.parentElement.querySelectorAll('.practice-option').forEach(opt => {
                opt.classList.remove('selected', 'correct', 'incorrect');
            });

            this.classList.add('selected');

            // 检查答案
            checkAnswer(answer, questionNumber);
        });
    });

    function checkAnswer(answer, questionNumber) {
        const correctAnswers = {
            '1': 'b',  // 容易出错且效率极低
            '2': 'c',  // 100,000个参数
            '3': 'b'   // 为了保证矩阵维度匹配
        };

        const feedback = document.getElementById(`practice-feedback-${questionNumber}`);
        const isCorrect = answer === correctAnswers[questionNumber];

        if (isCorrect) {
            feedback.className = 'practice-feedback show correct';
            feedback.innerHTML = `
            <strong>✅ 正确！</strong><br>
            ${getFeedbackText(questionNumber, true)}
        `;

            // 标记完成
            completedSections.add(`practice-${questionNumber}`);
            checkAchievements();
        } else {
            feedback.className = 'practice-feedback show incorrect';
            feedback.innerHTML = `
            <strong>❌ 再想想...</strong><br>
            ${getFeedbackText(questionNumber, false)}
        `;
        }
    }

    function getFeedbackText(questionNumber, isCorrect) {
        const feedbacks = {
            '1': {
                correct: "没错！手动计算梯度不仅容易出错，而且随着网络规模增长，计算量呈指数级增长。",
                incorrect: "提示：想想小陈花了3个小时还没算完，而且一个错误会导致后续全错..."
            },
            '2': {
                correct: "正确！每层之间需要100×100=10,000个权重，共9层连接，约10万个参数。",
                incorrect: "提示：计算方式是 (层数-1) × 每层神经元数²"
            },
            '3': {
                correct: "完全正确！前向传播是矩阵乘法W·x，反向传播需要Wᵀ·δ，转置确保维度匹配。",
                incorrect: "提示：考虑矩阵乘法的维度要求，(m×n) × (n×p) = (m×p)"
            }
        };

        return feedbacks[questionNumber][isCorrect ? 'correct' : 'incorrect'];
    }

    // 代码标签切换
    const codeTabs = document.querySelectorAll('.code-tab');
    codeTabs.forEach(tab => {
        tab.addEventListener('click', function() {
            const lang = this.getAttribute('data-lang');

            // 更新标签状态
            codeTabs.forEach(t => t.classList.remove('active'));
            this.classList.add('active');

            // 切换代码内容
            document.querySelectorAll('.code-content').forEach(content => {
                content.style.display = 'none';
            });
            document.getElementById(`${lang}-code`).style.display = 'block';
        });
    });

    // 代码功能
    function copyCode() {
        const activeTab = document.querySelector('.code-tab.active');
        const lang = activeTab.getAttribute('data-lang');
        const codeContent = document.getElementById(`${lang}-code`).textContent;

        navigator.clipboard.writeText(codeContent).then(() => {
            showNotification('代码已复制到剪贴板！');
        });
    }

    function runCode() {
        const output = document.getElementById('code-output');
        output.classList.add('show');

        // 模拟运行效果
        output.innerHTML = `
        <strong>运行结果：</strong>
        <pre>=== NumPy实现 ===
Epoch 0, Loss: 0.2486
Epoch 10, Loss: 0.1234
训练时间: 3.45秒

=== PyTorch实现 ===
Epoch 0, Loss: 0.2491
Epoch 10, Loss: 0.1229
训练时间: 0.82秒

速度提升: 4.21倍

梯度诊断报告：
Layer 1:
  权重梯度范数: 0.235
  权重梯度均值: 0.012
✅ 梯度流动正常</pre>
    `;
    }

    // 通知功能
    function showNotification(message) {
        const notification = document.createElement('div');
        notification.className = 'notification';
        notification.textContent = message;
        document.body.appendChild(notification);

        setTimeout(() => {
            notification.remove();
        }, 3000);
    }

    // 反馈功能
    function submitFeedback(type) {
        document.getElementById('feedback-response').style.display = 'block';

        // 记录反馈
        console.log(`User feedback: ${type}`);
    }

    // 页面加载完成后初始化
    document.addEventListener('DOMContentLoaded', () => {
        // 初始化难度
        updateContentVisibility(currentDifficulty);

        // 显示欢迎消息
        setTimeout(() => {
            learningBuddy.classList.add('active');
        }, 2000);

        // 检查学习进度
        const visited = localStorage.getItem('chapter2_visited');
        if (!visited) {
            localStorage.setItem('chapter2_visited', 'true');
            showAchievement('开始BP之旅', '欢迎学习反向传播！');
        }
    });

    // 隐藏导航栏
    let lastScrollTop = 0;
    const navHeader = document.querySelector('.nav-header');

    window.addEventListener('scroll', () => {
        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;

        if (scrollTop > lastScrollTop && scrollTop > 100) {
            // 向下滚动
            navHeader.classList.add('hidden');
        } else {
            // 向上滚动
            navHeader.classList.remove('hidden');
        }

        lastScrollTop = scrollTop;
    });

    // 学习进度跟踪
    function trackSectionView(sectionId) {
        completedSections.add(sectionId);
        checkAchievements();

        // 保存进度到本地存储
        const progress = Array.from(completedSections);
        localStorage.setItem('chapter2_progress', JSON.stringify(progress));
    }

    // 恢复学习进度
    const savedProgress = localStorage.getItem('chapter2_progress');
    if (savedProgress) {
        const progress = JSON.parse(savedProgress);
        progress.forEach(section => completedSections.add(section));
        checkAchievements();
    }

    // 监听章节进入视图
    const sectionObserver = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
            if (entry.isIntersecting) {
                const sectionId = entry.target.id;
                if (sectionId) {
                    trackSectionView(sectionId);
                }
            }
        });
    }, {
        threshold: 0.5
    });

    sections.forEach(section => {
        sectionObserver.observe(section);
    });

    console.log('🚀 反向传播章节加载完成！祝学习愉快！');
</script>
</body>
</html>